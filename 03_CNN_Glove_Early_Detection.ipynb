{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03.CNN-Glove Early Detection",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zyntonyson/Erisk2017/blob/master/03_CNN_Glove_Early_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f169939-93d7-4217-9bda-1ddbbbd19ca6",
        "_uuid": "04b4fb7875d109f67f8af07bb5c05d46c1f913e4",
        "id": "oBbj8vmhd82Q",
        "colab_type": "text"
      },
      "source": [
        "##  CNN with Glove Embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfdYRoOEdJRh",
        "colab_type": "text"
      },
      "source": [
        "### Cargar datos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FfOHcc5gmJv",
        "colab_type": "code",
        "outputId": "ca407f85-d071-4796-a786-eb64530bbd22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VmHkxDAdZxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "mypath='/content/drive/My Drive/MCE/Participaciones/05.Estancia Jun19/Practicas NLP/Deteccion de depresion/Actualizacion sep 2019'\n",
        "os.chdir( mypath )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxkm-8-ZdeNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_train=pd.read_csv('train_Depression_all_chunks_nosteem.csv')\n",
        "df_train=df_train.replace(np.nan, '', regex=True)\n",
        "df_test=pd.read_csv('test_Depression_all_chunks_nosteem.csv')\n",
        "df_test=df_test.replace(np.nan, '', regex=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OD1wzNRdMFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(df,nchunks=1):\n",
        "  data=df['Chunk_1']\n",
        "  data.rename(columns={'Chunk_1': 'x'})\n",
        "  if nchunks<=1:\n",
        "   pass\n",
        "  else:\n",
        "    for i in range(2,nchunks):\n",
        "      chunk='Chunk_'+str(i)\n",
        "      data+=df[chunk]\n",
        "  return data.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK1Sh0y2dh0V",
        "colab_type": "text"
      },
      "source": [
        "## Cargar Embbeding Pre-entrenado\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvNqNarqgrNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#google word2vec pretrained embedding \n",
        "\n",
        "#!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLRgkHVAhI-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fasttext embedding wikipedia\n",
        "\n",
        "#!wget -P /root/input/ -c \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.bin.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8upwDd9DrGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.geeksforgeeks.org/working-zip-files-python/\n",
        "#from zipfile import ZipFile \n",
        "\n",
        "#zipw=ZipFile('/root/input/wiki-news-300d-1M-subword.bin.zip', 'r')\n",
        "\n",
        "#zipw.extract('wiki-news-300d-1M-subword.bin',path=\"/root/input\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bKEhNGWpt9T",
        "colab_type": "code",
        "outputId": "5d7918e2-3067-44cd-c9e1-0f7c997827bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "# Glove\n",
        "!wget -P /root/input/ -c \"http://nlp.stanford.edu/data/glove.6B.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-13 07:54:32--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-10-13 07:54:33--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-10-13 07:54:33--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘/root/input/glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.98MB/s    in 6m 29s  \n",
            "\n",
            "2019-10-13 08:01:03 (2.11 MB/s) - ‘/root/input/glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feJzwxxd-CHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile \n",
        "\n",
        "zip=ZipFile('/root/input/glove.6B.zip', 'r')\n",
        "\n",
        "zip.extract('glove.6B.100d.txt',path=\"/root/input\")\n",
        "del zip\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTUSR-4lsfbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Glove embbeding\n",
        "# Se crea el diccionario de embbeding con glove\n",
        "\n",
        "embeddings_glove = {}\n",
        "f = open('/root/input/glove.6B.100d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_glove[word] = coefs\n",
        "f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcOX7eX6e0eV",
        "colab_type": "text"
      },
      "source": [
        "## Crear secuencias de los textos y capa de embbeding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFDEgICjpKNK",
        "colab_type": "code",
        "outputId": "703db288-d7da-4b4c-926e-ceb0958329ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYlcI4YGmNtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Crear conteo de términos (Bow)\n",
        "def create_tokenizer(corpus_train):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(corpus_train)\n",
        "\treturn tokenizer\n",
        "\n",
        "# calculate the maximum document length se define la dimensión de las secuencias\n",
        "def max_length(corpus_train):\n",
        "\treturn max([len(s.split()) for s in corpus_train])\n",
        "\n",
        "# encode a list of lines  (crear la secuencia de palabras)\n",
        "def encode_text(tokenizer, lines, length):\n",
        "\t# integer encode\n",
        "\tencoded = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad encoded sequences\n",
        "\tpadded = pad_sequences(encoded, maxlen=length, padding='post')\n",
        "\treturn padded\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3b2c9452-5780-4920-8896-0b9dfa7c562b",
        "_uuid": "e8742cc989f4c71a8c401feef5e54c0e7718865a",
        "id": "_sU9G0nzd822",
        "colab_type": "text"
      },
      "source": [
        "Matriz de peso de los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGljIr7MNV_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embbedingLayer(tokenizer,dictembedding):\n",
        "  dim_emb=len(list(dictembedding.values())[0])\n",
        "\n",
        "  # Creamos un diccionario donde las llaves sean los index por palabra\n",
        "  vocabulary_inv = dict((v, k) for k, v in tokenizer.word_index.items())\n",
        "  vocabulary_inv[0] = \"<PAD/>\"\n",
        "\n",
        "  # Creamos los embedding del vocabulario\n",
        "  embedding_weights = {key: dictembedding[word] if word in dictembedding else\n",
        "                            np.random.uniform(-0.25, 0.25, 100)\n",
        "                      for key, word in vocabulary_inv.items()}\n",
        "  # Convertir capa en un np.array\n",
        "  return np.array([embedding_weights[i] for i in range(len(embedding_weights))]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5C6ZoztNMAu",
        "colab_type": "text"
      },
      "source": [
        "## Definiendo modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "29a8d31b-451e-4427-afb3-fd40cd01bc60",
        "_uuid": "887320b9e2d8efaaa27c3f7913debaf53c37ed52",
        "trusted": true,
        "id": "WjCWKTFLd82W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras.layers import Activation\n",
        "from keras.layers import GlobalMaxPooling1D \n",
        "from keras.utils import plot_model\n",
        "from pickle import load\n",
        "from sklearn.utils import class_weight\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaF3bVAzV0wC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Métricas\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rV4nd6ImLm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the model\n",
        "def define_model(length, weights,seed=1013,num_filters=32):\n",
        "  \n",
        "  #model parameters\n",
        "  vocab_size,embed_dim = weights.shape \n",
        "    \n",
        "  #seed\n",
        "  np.random.seed(seed)\n",
        "  \n",
        "  ### DEFINE LAYERS\n",
        "  \n",
        "  #### Process layers\n",
        "  inputs1 = Input(shape=(length,))\n",
        "  embedding1 = Embedding(vocab_size, embed_dim, weights=[weights], trainable=False)(inputs1)\n",
        "  conv1 = Conv1D(num_filters, 4, activation='relu', padding='same')(embedding1)\n",
        "  maxpool1 = MaxPooling1D(2)(conv1)\n",
        "  conv2 = Conv1D(num_filters, 4, activation='relu', padding='same')(maxpool1)\n",
        "  Gpool1=GlobalMaxPooling1D()(conv2)\n",
        "  drop1 = Dropout(0.5)(Gpool1)\n",
        "  \n",
        "  ### prediction layers\n",
        "  dense1 = Dense(32, activation='relu')(drop1)\n",
        "  outputs = Dense(1, activation='sigmoid')(dense1)\n",
        "  model = Model(inputs=inputs1, outputs=outputs)\n",
        "  \n",
        "  # compile\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "  \n",
        "  # summarize\n",
        "  #print(model.summary())\n",
        "  #plot_model(model, show_shapes=True, to_file=DATA_PATH+'onechannel.png')\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r8jk1tRdl3t5",
        "colab": {}
      },
      "source": [
        "# Modelo completo\n",
        "\n",
        "def CNN_emb(train,test,dictembedding,nChunks=1,epochs=5,batch_size=16,maxlengthseq=None):\n",
        "  \n",
        "  # load data\n",
        "  x_train= generate_data(train,nChunks)\n",
        "  y_train=train['Depress'].values\n",
        "  x_test= generate_data(test,nChunks)\n",
        "  y_test=test['Depress'].values\n",
        "\n",
        "  # Initialite tokenizer\n",
        "  tokenizer = create_tokenizer(x_train)\n",
        "\n",
        "  # calculate max document length\n",
        "  if maxlengthseq ==None:\n",
        "    length = max_length(x_train)+1\n",
        "  else:\n",
        "    length= maxlengthseq\n",
        "  \n",
        "  # calculate vocabulary size\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "  \n",
        "  print('Chunks:{}'.format(nChunks))\n",
        "  print('Max document length: %d' % length)\n",
        "  print('Vocabulary size: %d' % vocab_size)\n",
        "\n",
        "  # Make embbeding layer\n",
        "  weights=embbedingLayer(tokenizer,dictembedding)\n",
        "  \n",
        "  # encode data train\n",
        "  trainX = encode_text(tokenizer, x_train, length)\n",
        "\n",
        "  # encode data test\n",
        "  testX = encode_text(tokenizer, x_test, length)\n",
        "  \n",
        "  # Pesos por clases no balanceadas\n",
        "  # Los datos no son balanceados, se da la información la proporción \n",
        "  class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y_train),\n",
        "                                                 y_train)\n",
        "\n",
        "  # Compile model\n",
        "  model=define_model(length, weights)\n",
        "  # fit model\n",
        "  history=model.fit(trainX, y_train, epochs=epochs, batch_size=batch_size,class_weight=class_weights, verbose=1)\n",
        "  # evaluate the model\n",
        "  loss, accuracy, f1_score, precision, recall = model.evaluate(testX, y_test, verbose=0)\n",
        "  return [nChunks,accuracy, f1_score, precision, recall]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoXIlOZBGHOo",
        "colab_type": "text"
      },
      "source": [
        "## Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ-42rXcEMNP",
        "colab_type": "code",
        "outputId": "3bc43cb6-1926-4098-f7a1-cf36a481578f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import time\n",
        "Chunks=[i for i in range(1,11)]\n",
        "CNNGlove_metrics=np.empty((0,5),float)\n",
        "Chunks\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2oyQITbE94W",
        "colab_type": "code",
        "outputId": "aab006bd-d0a0-4a4a-f1dc-5dfde292906e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "for chunk in Chunks:\n",
        "  tic=time.time()\n",
        "  metrics=CNN_emb(df_train,df_test,dictembedding=embeddings_glove,nChunks=chunk,epochs=80,batch_size=8,maxlengthseq=30000)\n",
        "  CNNGlove_metrics=np.vstack([CNNGlove_metrics,metrics])\n",
        "  print('Chunks:{} Tiempo de procesamiento (secs):{}'.format(chunk,time.time()-tic))\n",
        "  print('Test: \\t Accuracy={}, \\n\\t F1 score={}, \\n\\t Precision={}, \\n\\t Recall={}'.format(metrics[1],metrics[2],metrics[3],metrics[4]))\n",
        "  print('#####################################################################')\n",
        "  print('\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chunks:1\n",
            "Max document length: 30000\n",
            "Vocabulary size: 95025\n",
            "Epoch 1/80\n",
            "486/486 [==============================] - 5s 10ms/step - loss: 0.5408 - acc: 0.7984 - f1_m: 0.0322 - precision_m: 0.0266 - recall_m: 0.0590\n",
            "Epoch 2/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4455 - acc: 0.8292 - f1_m: 0.0110 - precision_m: 0.0165 - recall_m: 0.0082\n",
            "Epoch 3/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4571 - acc: 0.8313 - f1_m: 0.0192 - precision_m: 0.0329 - recall_m: 0.0137\n",
            "Epoch 4/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4140 - acc: 0.8333 - f1_m: 0.0368 - precision_m: 0.0658 - recall_m: 0.0261\n",
            "Epoch 5/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3776 - acc: 0.8457 - f1_m: 0.0933 - precision_m: 0.1276 - recall_m: 0.0802\n",
            "Epoch 6/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3551 - acc: 0.8601 - f1_m: 0.1649 - precision_m: 0.2181 - recall_m: 0.1385\n",
            "Epoch 7/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3202 - acc: 0.8704 - f1_m: 0.2821 - precision_m: 0.3457 - recall_m: 0.2686\n",
            "Epoch 8/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2703 - acc: 0.9012 - f1_m: 0.3944 - precision_m: 0.4609 - recall_m: 0.3608\n",
            "Epoch 9/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2502 - acc: 0.9239 - f1_m: 0.5241 - precision_m: 0.5885 - recall_m: 0.4960\n",
            "Epoch 10/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2115 - acc: 0.9342 - f1_m: 0.4724 - precision_m: 0.5542 - recall_m: 0.4376\n",
            "Epoch 11/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1707 - acc: 0.9465 - f1_m: 0.5394 - precision_m: 0.6173 - recall_m: 0.4993\n",
            "Epoch 12/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1786 - acc: 0.9342 - f1_m: 0.5293 - precision_m: 0.5734 - recall_m: 0.5133\n",
            "Epoch 13/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1625 - acc: 0.9588 - f1_m: 0.6885 - precision_m: 0.7366 - recall_m: 0.6722\n",
            "Epoch 14/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1383 - acc: 0.9547 - f1_m: 0.5997 - precision_m: 0.6626 - recall_m: 0.5701\n",
            "Epoch 15/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1363 - acc: 0.9527 - f1_m: 0.6090 - precision_m: 0.6557 - recall_m: 0.5981\n",
            "Epoch 16/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1307 - acc: 0.9609 - f1_m: 0.5793 - precision_m: 0.6337 - recall_m: 0.5549\n",
            "Epoch 17/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1010 - acc: 0.9712 - f1_m: 0.6805 - precision_m: 0.7119 - recall_m: 0.6667\n",
            "Epoch 18/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0814 - acc: 0.9856 - f1_m: 0.6540 - precision_m: 0.6708 - recall_m: 0.6433\n",
            "Epoch 19/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0896 - acc: 0.9712 - f1_m: 0.6846 - precision_m: 0.7243 - recall_m: 0.6626\n",
            "Epoch 20/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1016 - acc: 0.9650 - f1_m: 0.6258 - precision_m: 0.6626 - recall_m: 0.6104\n",
            "Epoch 21/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0839 - acc: 0.9774 - f1_m: 0.7200 - precision_m: 0.7366 - recall_m: 0.7106\n",
            "Epoch 22/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0635 - acc: 0.9856 - f1_m: 0.7480 - precision_m: 0.7613 - recall_m: 0.7443\n",
            "Epoch 23/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1005 - acc: 0.9733 - f1_m: 0.6455 - precision_m: 0.6790 - recall_m: 0.6324\n",
            "Epoch 24/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0652 - acc: 0.9774 - f1_m: 0.6905 - precision_m: 0.7147 - recall_m: 0.6790\n",
            "Epoch 25/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1105 - acc: 0.9691 - f1_m: 0.7153 - precision_m: 0.7366 - recall_m: 0.7106\n",
            "Epoch 26/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0738 - acc: 0.9794 - f1_m: 0.6861 - precision_m: 0.7119 - recall_m: 0.6763\n",
            "Epoch 27/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0503 - acc: 0.9918 - f1_m: 0.7202 - precision_m: 0.7366 - recall_m: 0.7119\n",
            "Epoch 28/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0461 - acc: 0.9856 - f1_m: 0.6793 - precision_m: 0.6996 - recall_m: 0.6722\n",
            "Epoch 29/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0741 - acc: 0.9815 - f1_m: 0.6854 - precision_m: 0.6922 - recall_m: 0.6872\n",
            "Epoch 30/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0618 - acc: 0.9856 - f1_m: 0.7355 - precision_m: 0.7531 - recall_m: 0.7257\n",
            "Epoch 31/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0738 - acc: 0.9753 - f1_m: 0.7104 - precision_m: 0.7305 - recall_m: 0.7095\n",
            "Epoch 32/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0716 - acc: 0.9815 - f1_m: 0.6473 - precision_m: 0.6749 - recall_m: 0.6324\n",
            "Epoch 33/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0771 - acc: 0.9671 - f1_m: 0.7358 - precision_m: 0.7915 - recall_m: 0.7140\n",
            "Epoch 34/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0334 - acc: 0.9918 - f1_m: 0.7443 - precision_m: 0.7531 - recall_m: 0.7394\n",
            "Epoch 35/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0554 - acc: 0.9835 - f1_m: 0.7498 - precision_m: 0.7695 - recall_m: 0.7394\n",
            "Epoch 36/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0467 - acc: 0.9877 - f1_m: 0.7186 - precision_m: 0.7243 - recall_m: 0.7229\n",
            "Epoch 37/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0450 - acc: 0.9856 - f1_m: 0.7518 - precision_m: 0.7613 - recall_m: 0.7490\n",
            "Epoch 38/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0650 - acc: 0.9794 - f1_m: 0.6192 - precision_m: 0.6406 - recall_m: 0.6132\n",
            "Epoch 39/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0805 - acc: 0.9691 - f1_m: 0.6052 - precision_m: 0.6313 - recall_m: 0.5940\n",
            "Epoch 40/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0663 - acc: 0.9815 - f1_m: 0.7420 - precision_m: 0.7613 - recall_m: 0.7353\n",
            "Epoch 41/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0719 - acc: 0.9774 - f1_m: 0.6970 - precision_m: 0.7119 - recall_m: 0.6914\n",
            "Epoch 42/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0576 - acc: 0.9835 - f1_m: 0.7849 - precision_m: 0.7860 - recall_m: 0.7915\n",
            "Epoch 43/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0499 - acc: 0.9835 - f1_m: 0.7106 - precision_m: 0.7284 - recall_m: 0.7058\n",
            "Epoch 44/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0431 - acc: 0.9918 - f1_m: 0.6872 - precision_m: 0.6872 - recall_m: 0.6872\n",
            "Epoch 45/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0358 - acc: 0.9918 - f1_m: 0.7860 - precision_m: 0.7942 - recall_m: 0.7860\n",
            "Epoch 46/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1009 - acc: 0.9691 - f1_m: 0.7621 - precision_m: 0.7709 - recall_m: 0.7764\n",
            "Epoch 47/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0605 - acc: 0.9856 - f1_m: 0.7473 - precision_m: 0.7599 - recall_m: 0.7462\n",
            "Epoch 48/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0610 - acc: 0.9835 - f1_m: 0.6539 - precision_m: 0.6667 - recall_m: 0.6506\n",
            "Epoch 49/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0473 - acc: 0.9877 - f1_m: 0.7483 - precision_m: 0.7654 - recall_m: 0.7421\n",
            "Epoch 50/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0590 - acc: 0.9794 - f1_m: 0.7365 - precision_m: 0.7558 - recall_m: 0.7325\n",
            "Epoch 51/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0146 - acc: 0.9979 - f1_m: 0.7737 - precision_m: 0.7737 - recall_m: 0.7737\n",
            "Epoch 52/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1110 - acc: 0.9712 - f1_m: 0.6584 - precision_m: 0.6667 - recall_m: 0.6639\n",
            "Epoch 53/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0611 - acc: 0.9856 - f1_m: 0.7937 - precision_m: 0.8107 - recall_m: 0.7888\n",
            "Epoch 54/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0512 - acc: 0.9897 - f1_m: 0.7553 - precision_m: 0.7695 - recall_m: 0.7476\n",
            "Epoch 55/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0401 - acc: 0.9897 - f1_m: 0.7420 - precision_m: 0.7531 - recall_m: 0.7353\n",
            "Epoch 56/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0334 - acc: 0.9835 - f1_m: 0.6308 - precision_m: 0.6420 - recall_m: 0.6241\n",
            "Epoch 57/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0272 - acc: 0.9897 - f1_m: 0.7627 - precision_m: 0.7654 - recall_m: 0.7654\n",
            "Epoch 58/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0363 - acc: 0.9856 - f1_m: 0.7937 - precision_m: 0.8025 - recall_m: 0.7888\n",
            "Epoch 59/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0285 - acc: 0.9897 - f1_m: 0.7572 - precision_m: 0.7572 - recall_m: 0.7572\n",
            "Epoch 60/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0338 - acc: 0.9918 - f1_m: 0.8211 - precision_m: 0.8272 - recall_m: 0.8217\n",
            "Epoch 61/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0179 - acc: 0.9938 - f1_m: 0.6821 - precision_m: 0.6872 - recall_m: 0.6785\n",
            "Epoch 62/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0182 - acc: 0.9938 - f1_m: 0.7782 - precision_m: 0.7860 - recall_m: 0.7737\n",
            "Epoch 63/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0369 - acc: 0.9877 - f1_m: 0.7452 - precision_m: 0.7613 - recall_m: 0.7407\n",
            "Epoch 64/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0149 - acc: 0.9938 - f1_m: 0.7860 - precision_m: 0.7942 - recall_m: 0.7860\n",
            "Epoch 65/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0407 - acc: 0.9794 - f1_m: 0.7103 - precision_m: 0.7284 - recall_m: 0.7037\n",
            "Epoch 66/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0389 - acc: 0.9877 - f1_m: 0.7543 - precision_m: 0.7654 - recall_m: 0.7512\n",
            "Epoch 67/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0458 - acc: 0.9918 - f1_m: 0.7300 - precision_m: 0.7366 - recall_m: 0.7257\n",
            "Epoch 68/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0342 - acc: 0.9856 - f1_m: 0.7363 - precision_m: 0.7490 - recall_m: 0.7320\n",
            "Epoch 69/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0333 - acc: 0.9918 - f1_m: 0.7517 - precision_m: 0.7737 - recall_m: 0.7407\n",
            "Epoch 70/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0278 - acc: 0.9959 - f1_m: 0.7278 - precision_m: 0.7366 - recall_m: 0.7229\n",
            "Epoch 71/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0160 - acc: 0.9938 - f1_m: 0.6990 - precision_m: 0.7078 - recall_m: 0.6941\n",
            "Epoch 72/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0263 - acc: 0.9938 - f1_m: 0.7772 - precision_m: 0.7860 - recall_m: 0.7723\n",
            "Epoch 73/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0269 - acc: 0.9918 - f1_m: 0.7178 - precision_m: 0.7243 - recall_m: 0.7202\n",
            "Epoch 74/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0248 - acc: 0.9897 - f1_m: 0.7804 - precision_m: 0.7860 - recall_m: 0.7764\n",
            "Epoch 75/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0250 - acc: 0.9918 - f1_m: 0.6785 - precision_m: 0.6735 - recall_m: 0.6872\n",
            "Epoch 76/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0663 - acc: 0.9815 - f1_m: 0.7222 - precision_m: 0.7421 - recall_m: 0.7160\n",
            "Epoch 77/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0365 - acc: 0.9897 - f1_m: 0.6802 - precision_m: 0.6914 - recall_m: 0.6735\n",
            "Epoch 78/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0435 - acc: 0.9835 - f1_m: 0.6926 - precision_m: 0.6996 - recall_m: 0.6982\n",
            "Epoch 79/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0129 - acc: 0.9959 - f1_m: 0.6949 - precision_m: 0.7037 - recall_m: 0.6900\n",
            "Epoch 80/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0522 - acc: 0.9835 - f1_m: 0.7529 - precision_m: 0.7778 - recall_m: 0.7435\n",
            "Chunks:1 Tiempo de procesamiento (secs):244.39187622070312\n",
            "Test: \t Accuracy=0.8827930174563591, \n",
            "\t F1 score=0.09035949992420073, \n",
            "\t Precision=0.1596009975062344, \n",
            "\t Recall=0.0633416449339907\n",
            "#####################################################################\n",
            "\n",
            "\n",
            "\n",
            "Chunks:2\n",
            "Max document length: 30000\n",
            "Vocabulary size: 95025\n",
            "Epoch 1/80\n",
            "486/486 [==============================] - 5s 10ms/step - loss: 0.5443 - acc: 0.7901 - f1_m: 0.0322 - precision_m: 0.0266 - recall_m: 0.0590\n",
            "Epoch 2/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4546 - acc: 0.8313 - f1_m: 0.0110 - precision_m: 0.0165 - recall_m: 0.0082\n",
            "Epoch 3/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4524 - acc: 0.8292 - f1_m: 0.0082 - precision_m: 0.0165 - recall_m: 0.0055\n",
            "Epoch 4/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4156 - acc: 0.8395 - f1_m: 0.0532 - precision_m: 0.0823 - recall_m: 0.0425\n",
            "Epoch 5/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3754 - acc: 0.8477 - f1_m: 0.1097 - precision_m: 0.1440 - recall_m: 0.0967\n",
            "Epoch 6/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3563 - acc: 0.8621 - f1_m: 0.1868 - precision_m: 0.2593 - recall_m: 0.1523\n",
            "Epoch 7/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3239 - acc: 0.8642 - f1_m: 0.2466 - precision_m: 0.3052 - recall_m: 0.2254\n",
            "Epoch 8/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2792 - acc: 0.8786 - f1_m: 0.3320 - precision_m: 0.4198 - recall_m: 0.2949\n",
            "Epoch 9/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2465 - acc: 0.8992 - f1_m: 0.3798 - precision_m: 0.4383 - recall_m: 0.3569\n",
            "Epoch 10/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2204 - acc: 0.9280 - f1_m: 0.4371 - precision_m: 0.4966 - recall_m: 0.4156\n",
            "Epoch 11/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1863 - acc: 0.9321 - f1_m: 0.5024 - precision_m: 0.5953 - recall_m: 0.4623\n",
            "Epoch 12/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1809 - acc: 0.9300 - f1_m: 0.4894 - precision_m: 0.5432 - recall_m: 0.4626\n",
            "Epoch 13/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1809 - acc: 0.9486 - f1_m: 0.6274 - precision_m: 0.6872 - recall_m: 0.5995\n",
            "Epoch 14/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1534 - acc: 0.9486 - f1_m: 0.6147 - precision_m: 0.6914 - recall_m: 0.5800\n",
            "Epoch 15/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1291 - acc: 0.9547 - f1_m: 0.6101 - precision_m: 0.6612 - recall_m: 0.5953\n",
            "Epoch 16/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1428 - acc: 0.9568 - f1_m: 0.5307 - precision_m: 0.5844 - recall_m: 0.5062\n",
            "Epoch 17/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1085 - acc: 0.9671 - f1_m: 0.6719 - precision_m: 0.7119 - recall_m: 0.6571\n",
            "Epoch 18/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1007 - acc: 0.9588 - f1_m: 0.5901 - precision_m: 0.6440 - recall_m: 0.5652\n",
            "Epoch 19/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0972 - acc: 0.9733 - f1_m: 0.6909 - precision_m: 0.7407 - recall_m: 0.6626\n",
            "Epoch 20/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1113 - acc: 0.9650 - f1_m: 0.6498 - precision_m: 0.6790 - recall_m: 0.6365\n",
            "Epoch 21/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1284 - acc: 0.9650 - f1_m: 0.6654 - precision_m: 0.6982 - recall_m: 0.6495\n",
            "Epoch 22/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0793 - acc: 0.9733 - f1_m: 0.6894 - precision_m: 0.7106 - recall_m: 0.6848\n",
            "Epoch 23/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1115 - acc: 0.9753 - f1_m: 0.6368 - precision_m: 0.6708 - recall_m: 0.6187\n",
            "Epoch 24/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0698 - acc: 0.9774 - f1_m: 0.6752 - precision_m: 0.6982 - recall_m: 0.6653\n",
            "Epoch 25/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0929 - acc: 0.9712 - f1_m: 0.7075 - precision_m: 0.7325 - recall_m: 0.6941\n",
            "Epoch 26/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0964 - acc: 0.9712 - f1_m: 0.6531 - precision_m: 0.6872 - recall_m: 0.6337\n",
            "Epoch 27/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0526 - acc: 0.9815 - f1_m: 0.6883 - precision_m: 0.7147 - recall_m: 0.6763\n",
            "Epoch 28/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0539 - acc: 0.9835 - f1_m: 0.6954 - precision_m: 0.7202 - recall_m: 0.6818\n",
            "Epoch 29/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0759 - acc: 0.9774 - f1_m: 0.6986 - precision_m: 0.7119 - recall_m: 0.6949\n",
            "Epoch 30/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0860 - acc: 0.9774 - f1_m: 0.7300 - precision_m: 0.7613 - recall_m: 0.7174\n",
            "Epoch 31/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0971 - acc: 0.9712 - f1_m: 0.6918 - precision_m: 0.7250 - recall_m: 0.6771\n",
            "Epoch 32/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0791 - acc: 0.9815 - f1_m: 0.6528 - precision_m: 0.6749 - recall_m: 0.6406\n",
            "Epoch 33/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0943 - acc: 0.9712 - f1_m: 0.7391 - precision_m: 0.7805 - recall_m: 0.7222\n",
            "Epoch 34/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0576 - acc: 0.9835 - f1_m: 0.7136 - precision_m: 0.7284 - recall_m: 0.7092\n",
            "Epoch 35/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0785 - acc: 0.9691 - f1_m: 0.6900 - precision_m: 0.7037 - recall_m: 0.6900\n",
            "Epoch 36/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0692 - acc: 0.9774 - f1_m: 0.6897 - precision_m: 0.7160 - recall_m: 0.6804\n",
            "Epoch 37/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1012 - acc: 0.9568 - f1_m: 0.6263 - precision_m: 0.6392 - recall_m: 0.6337\n",
            "Epoch 38/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0870 - acc: 0.9774 - f1_m: 0.6388 - precision_m: 0.6653 - recall_m: 0.6255\n",
            "Epoch 39/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0503 - acc: 0.9835 - f1_m: 0.6673 - precision_m: 0.6749 - recall_m: 0.6680\n",
            "Epoch 40/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0403 - acc: 0.9856 - f1_m: 0.7498 - precision_m: 0.7531 - recall_m: 0.7558\n",
            "Epoch 41/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0617 - acc: 0.9774 - f1_m: 0.7045 - precision_m: 0.7284 - recall_m: 0.6975\n",
            "Epoch 42/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0795 - acc: 0.9815 - f1_m: 0.7627 - precision_m: 0.7737 - recall_m: 0.7572\n",
            "Epoch 43/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0685 - acc: 0.9794 - f1_m: 0.7191 - precision_m: 0.7476 - recall_m: 0.7064\n",
            "Epoch 44/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0518 - acc: 0.9835 - f1_m: 0.6850 - precision_m: 0.6982 - recall_m: 0.6790\n",
            "Epoch 45/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0796 - acc: 0.9774 - f1_m: 0.7202 - precision_m: 0.7366 - recall_m: 0.7202\n",
            "Epoch 46/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0410 - acc: 0.9897 - f1_m: 0.7901 - precision_m: 0.7984 - recall_m: 0.7901\n",
            "Epoch 47/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0560 - acc: 0.9856 - f1_m: 0.7254 - precision_m: 0.7407 - recall_m: 0.7160\n",
            "Epoch 48/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0614 - acc: 0.9835 - f1_m: 0.6821 - precision_m: 0.7037 - recall_m: 0.6712\n",
            "Epoch 49/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0491 - acc: 0.9877 - f1_m: 0.7488 - precision_m: 0.7737 - recall_m: 0.7366\n",
            "Epoch 50/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0640 - acc: 0.9753 - f1_m: 0.7442 - precision_m: 0.7723 - recall_m: 0.7353\n",
            "Epoch 51/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0380 - acc: 0.9835 - f1_m: 0.7296 - precision_m: 0.7366 - recall_m: 0.7353\n",
            "Epoch 52/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0346 - acc: 0.9918 - f1_m: 0.7599 - precision_m: 0.7654 - recall_m: 0.7572\n",
            "Epoch 53/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0476 - acc: 0.9794 - f1_m: 0.7584 - precision_m: 0.7778 - recall_m: 0.7517\n",
            "Epoch 54/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0503 - acc: 0.9835 - f1_m: 0.7608 - precision_m: 0.7860 - recall_m: 0.7476\n",
            "Epoch 55/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0604 - acc: 0.9815 - f1_m: 0.7447 - precision_m: 0.7778 - recall_m: 0.7325\n",
            "Epoch 56/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0388 - acc: 0.9918 - f1_m: 0.6683 - precision_m: 0.6749 - recall_m: 0.6639\n",
            "Epoch 57/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0571 - acc: 0.9815 - f1_m: 0.7488 - precision_m: 0.7517 - recall_m: 0.7567\n",
            "Epoch 58/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0500 - acc: 0.9877 - f1_m: 0.8047 - precision_m: 0.8189 - recall_m: 0.7970\n",
            "Epoch 59/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0424 - acc: 0.9835 - f1_m: 0.7484 - precision_m: 0.7654 - recall_m: 0.7435\n",
            "Epoch 60/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0569 - acc: 0.9938 - f1_m: 0.8244 - precision_m: 0.8354 - recall_m: 0.8189\n",
            "Epoch 61/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0410 - acc: 0.9918 - f1_m: 0.6916 - precision_m: 0.6982 - recall_m: 0.6900\n",
            "Epoch 62/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0432 - acc: 0.9877 - f1_m: 0.7617 - precision_m: 0.7778 - recall_m: 0.7572\n",
            "Epoch 63/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0327 - acc: 0.9897 - f1_m: 0.7465 - precision_m: 0.7641 - recall_m: 0.7394\n",
            "Epoch 64/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0255 - acc: 0.9897 - f1_m: 0.7700 - precision_m: 0.7747 - recall_m: 0.7723\n",
            "Epoch 65/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0636 - acc: 0.9794 - f1_m: 0.7144 - precision_m: 0.7325 - recall_m: 0.7051\n",
            "Epoch 66/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0719 - acc: 0.9753 - f1_m: 0.7118 - precision_m: 0.7449 - recall_m: 0.7012\n",
            "Epoch 67/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0320 - acc: 0.9897 - f1_m: 0.7224 - precision_m: 0.7284 - recall_m: 0.7229\n",
            "Epoch 68/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0157 - acc: 0.9918 - f1_m: 0.7588 - precision_m: 0.7709 - recall_m: 0.7531\n",
            "Epoch 69/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0355 - acc: 0.9877 - f1_m: 0.7225 - precision_m: 0.7407 - recall_m: 0.7128\n",
            "Epoch 70/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0326 - acc: 0.9897 - f1_m: 0.7037 - precision_m: 0.7202 - recall_m: 0.6955\n",
            "Epoch 71/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0440 - acc: 0.9835 - f1_m: 0.7040 - precision_m: 0.7243 - recall_m: 0.6941\n",
            "Epoch 72/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0352 - acc: 0.9918 - f1_m: 0.7723 - precision_m: 0.7860 - recall_m: 0.7668\n",
            "Epoch 73/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0222 - acc: 0.9959 - f1_m: 0.7147 - precision_m: 0.7202 - recall_m: 0.7119\n",
            "Epoch 74/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0147 - acc: 0.9938 - f1_m: 0.7937 - precision_m: 0.8025 - recall_m: 0.7888\n",
            "Epoch 75/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0830 - acc: 0.9753 - f1_m: 0.6682 - precision_m: 0.6776 - recall_m: 0.6763\n",
            "Epoch 76/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1086 - acc: 0.9733 - f1_m: 0.7186 - precision_m: 0.7449 - recall_m: 0.7160\n",
            "Epoch 77/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0930 - acc: 0.9753 - f1_m: 0.6548 - precision_m: 0.6776 - recall_m: 0.6475\n",
            "Epoch 78/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0447 - acc: 0.9815 - f1_m: 0.6916 - precision_m: 0.7119 - recall_m: 0.6845\n",
            "Epoch 79/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0162 - acc: 0.9938 - f1_m: 0.6949 - precision_m: 0.7037 - recall_m: 0.6900\n",
            "Epoch 80/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0556 - acc: 0.9856 - f1_m: 0.7553 - precision_m: 0.7778 - recall_m: 0.7476\n",
            "Chunks:2 Tiempo de procesamiento (secs):242.5241506099701\n",
            "Test: \t Accuracy=0.8902743142144638, \n",
            "\t F1 score=0.09305888340062929, \n",
            "\t Precision=0.1596009975062344, \n",
            "\t Recall=0.06583541052002562\n",
            "#####################################################################\n",
            "\n",
            "\n",
            "\n",
            "Chunks:3\n",
            "Max document length: 30000\n",
            "Vocabulary size: 95028\n",
            "Epoch 1/80\n",
            "486/486 [==============================] - 5s 10ms/step - loss: 0.5437 - acc: 0.7984 - f1_m: 0.0432 - precision_m: 0.0431 - recall_m: 0.0672\n",
            "Epoch 2/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4493 - acc: 0.8313 - f1_m: 0.0110 - precision_m: 0.0165 - recall_m: 0.0082\n",
            "Epoch 3/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4514 - acc: 0.8313 - f1_m: 0.0082 - precision_m: 0.0165 - recall_m: 0.0055\n",
            "Epoch 4/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4163 - acc: 0.8395 - f1_m: 0.0477 - precision_m: 0.0823 - recall_m: 0.0343\n",
            "Epoch 5/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3886 - acc: 0.8354 - f1_m: 0.0329 - precision_m: 0.0453 - recall_m: 0.0281\n",
            "Epoch 6/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3725 - acc: 0.8498 - f1_m: 0.1023 - precision_m: 0.1440 - recall_m: 0.0837\n",
            "Epoch 7/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3360 - acc: 0.8704 - f1_m: 0.2449 - precision_m: 0.3134 - recall_m: 0.2193\n",
            "Epoch 8/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3091 - acc: 0.8807 - f1_m: 0.3457 - precision_m: 0.4280 - recall_m: 0.3169\n",
            "Epoch 9/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2613 - acc: 0.8971 - f1_m: 0.3970 - precision_m: 0.4753 - recall_m: 0.3693\n",
            "Epoch 10/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2278 - acc: 0.9259 - f1_m: 0.4066 - precision_m: 0.4719 - recall_m: 0.3882\n",
            "Epoch 11/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2049 - acc: 0.9156 - f1_m: 0.4805 - precision_m: 0.5926 - recall_m: 0.4307\n",
            "Epoch 12/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1945 - acc: 0.9321 - f1_m: 0.5102 - precision_m: 0.5652 - recall_m: 0.4872\n",
            "Epoch 13/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1865 - acc: 0.9383 - f1_m: 0.5929 - precision_m: 0.6516 - recall_m: 0.5748\n",
            "Epoch 14/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1723 - acc: 0.9342 - f1_m: 0.5403 - precision_m: 0.6159 - recall_m: 0.5147\n",
            "Epoch 15/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1390 - acc: 0.9547 - f1_m: 0.6103 - precision_m: 0.6461 - recall_m: 0.5953\n",
            "Epoch 16/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1436 - acc: 0.9650 - f1_m: 0.5693 - precision_m: 0.6214 - recall_m: 0.5446\n",
            "Epoch 17/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1018 - acc: 0.9691 - f1_m: 0.6785 - precision_m: 0.7202 - recall_m: 0.6543\n",
            "Epoch 18/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1025 - acc: 0.9671 - f1_m: 0.5980 - precision_m: 0.6337 - recall_m: 0.5789\n",
            "Epoch 19/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0948 - acc: 0.9671 - f1_m: 0.6845 - precision_m: 0.7106 - recall_m: 0.6749\n",
            "Epoch 20/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0990 - acc: 0.9733 - f1_m: 0.6609 - precision_m: 0.6872 - recall_m: 0.6461\n",
            "Epoch 21/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1116 - acc: 0.9630 - f1_m: 0.6705 - precision_m: 0.6955 - recall_m: 0.6598\n",
            "Epoch 22/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0874 - acc: 0.9691 - f1_m: 0.6944 - precision_m: 0.7243 - recall_m: 0.6820\n",
            "Epoch 23/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1236 - acc: 0.9650 - f1_m: 0.6313 - precision_m: 0.6653 - recall_m: 0.6214\n",
            "Epoch 24/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0765 - acc: 0.9712 - f1_m: 0.6699 - precision_m: 0.6941 - recall_m: 0.6612\n",
            "Epoch 25/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1033 - acc: 0.9712 - f1_m: 0.7098 - precision_m: 0.7325 - recall_m: 0.6982\n",
            "Epoch 26/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1128 - acc: 0.9588 - f1_m: 0.6176 - precision_m: 0.6527 - recall_m: 0.6077\n",
            "Epoch 27/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0537 - acc: 0.9856 - f1_m: 0.7026 - precision_m: 0.7147 - recall_m: 0.6982\n",
            "Epoch 28/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0455 - acc: 0.9877 - f1_m: 0.6870 - precision_m: 0.7078 - recall_m: 0.6749\n",
            "Epoch 29/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0712 - acc: 0.9712 - f1_m: 0.6825 - precision_m: 0.7147 - recall_m: 0.6689\n",
            "Epoch 30/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0649 - acc: 0.9733 - f1_m: 0.6785 - precision_m: 0.7119 - recall_m: 0.6653\n",
            "Epoch 31/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0887 - acc: 0.9712 - f1_m: 0.6759 - precision_m: 0.6989 - recall_m: 0.6730\n",
            "Epoch 32/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0979 - acc: 0.9691 - f1_m: 0.6142 - precision_m: 0.6488 - recall_m: 0.5995\n",
            "Epoch 33/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0871 - acc: 0.9671 - f1_m: 0.7309 - precision_m: 0.7750 - recall_m: 0.7167\n",
            "Epoch 34/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0655 - acc: 0.9815 - f1_m: 0.7001 - precision_m: 0.7119 - recall_m: 0.6968\n",
            "Epoch 35/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0694 - acc: 0.9794 - f1_m: 0.7206 - precision_m: 0.7449 - recall_m: 0.7133\n",
            "Epoch 36/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0588 - acc: 0.9774 - f1_m: 0.6801 - precision_m: 0.6968 - recall_m: 0.6722\n",
            "Epoch 37/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0870 - acc: 0.9691 - f1_m: 0.6932 - precision_m: 0.7215 - recall_m: 0.6886\n",
            "Epoch 38/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0988 - acc: 0.9774 - f1_m: 0.6044 - precision_m: 0.6379 - recall_m: 0.5885\n",
            "Epoch 39/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0490 - acc: 0.9877 - f1_m: 0.6840 - precision_m: 0.7037 - recall_m: 0.6735\n",
            "Epoch 40/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0460 - acc: 0.9835 - f1_m: 0.7421 - precision_m: 0.7531 - recall_m: 0.7449\n",
            "Epoch 41/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0417 - acc: 0.9877 - f1_m: 0.7410 - precision_m: 0.7531 - recall_m: 0.7339\n",
            "Epoch 42/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0507 - acc: 0.9897 - f1_m: 0.8230 - precision_m: 0.8395 - recall_m: 0.8148\n",
            "Epoch 43/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0617 - acc: 0.9815 - f1_m: 0.7090 - precision_m: 0.7325 - recall_m: 0.6982\n",
            "Epoch 44/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0512 - acc: 0.9815 - f1_m: 0.6893 - precision_m: 0.7119 - recall_m: 0.6804\n",
            "Epoch 45/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0587 - acc: 0.9897 - f1_m: 0.7586 - precision_m: 0.7695 - recall_m: 0.7531\n",
            "Epoch 46/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0395 - acc: 0.9877 - f1_m: 0.7781 - precision_m: 0.7846 - recall_m: 0.7764\n",
            "Epoch 47/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0436 - acc: 0.9877 - f1_m: 0.7374 - precision_m: 0.7407 - recall_m: 0.7435\n",
            "Epoch 48/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0627 - acc: 0.9794 - f1_m: 0.6729 - precision_m: 0.6914 - recall_m: 0.6657\n",
            "Epoch 49/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0368 - acc: 0.9897 - f1_m: 0.7440 - precision_m: 0.7572 - recall_m: 0.7353\n",
            "Epoch 50/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0866 - acc: 0.9691 - f1_m: 0.6974 - precision_m: 0.7160 - recall_m: 0.6968\n",
            "Epoch 51/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0309 - acc: 0.9897 - f1_m: 0.7539 - precision_m: 0.7572 - recall_m: 0.7599\n",
            "Epoch 52/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0432 - acc: 0.9856 - f1_m: 0.7366 - precision_m: 0.7572 - recall_m: 0.7251\n",
            "Epoch 53/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0455 - acc: 0.9856 - f1_m: 0.7942 - precision_m: 0.8107 - recall_m: 0.7915\n",
            "Epoch 54/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0475 - acc: 0.9856 - f1_m: 0.7443 - precision_m: 0.7613 - recall_m: 0.7394\n",
            "Epoch 55/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0524 - acc: 0.9856 - f1_m: 0.7595 - precision_m: 0.7750 - recall_m: 0.7545\n",
            "Epoch 56/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0386 - acc: 0.9835 - f1_m: 0.6760 - precision_m: 0.6914 - recall_m: 0.6661\n",
            "Epoch 57/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0500 - acc: 0.9877 - f1_m: 0.8037 - precision_m: 0.8176 - recall_m: 0.7978\n",
            "Epoch 58/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0394 - acc: 0.9877 - f1_m: 0.8288 - precision_m: 0.8464 - recall_m: 0.8217\n",
            "Epoch 59/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0540 - acc: 0.9897 - f1_m: 0.7737 - precision_m: 0.7819 - recall_m: 0.7737\n",
            "Epoch 60/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0450 - acc: 0.9897 - f1_m: 0.8080 - precision_m: 0.8107 - recall_m: 0.8107\n",
            "Epoch 61/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0209 - acc: 0.9938 - f1_m: 0.6785 - precision_m: 0.6818 - recall_m: 0.6790\n",
            "Epoch 62/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0359 - acc: 0.9877 - f1_m: 0.7603 - precision_m: 0.7654 - recall_m: 0.7613\n",
            "Epoch 63/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0499 - acc: 0.9897 - f1_m: 0.7355 - precision_m: 0.7476 - recall_m: 0.7311\n",
            "Epoch 64/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0529 - acc: 0.9835 - f1_m: 0.7418 - precision_m: 0.7476 - recall_m: 0.7490\n",
            "Epoch 65/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0640 - acc: 0.9856 - f1_m: 0.7506 - precision_m: 0.7654 - recall_m: 0.7435\n",
            "Epoch 66/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0818 - acc: 0.9774 - f1_m: 0.6912 - precision_m: 0.7188 - recall_m: 0.6798\n",
            "Epoch 67/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0419 - acc: 0.9877 - f1_m: 0.7059 - precision_m: 0.7037 - recall_m: 0.7147\n",
            "Epoch 68/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0176 - acc: 0.9979 - f1_m: 0.7718 - precision_m: 0.7737 - recall_m: 0.7704\n",
            "Epoch 69/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0579 - acc: 0.9753 - f1_m: 0.6793 - precision_m: 0.6996 - recall_m: 0.6722\n",
            "Epoch 70/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0268 - acc: 0.9918 - f1_m: 0.7037 - precision_m: 0.7202 - recall_m: 0.6955\n",
            "Epoch 71/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0167 - acc: 0.9918 - f1_m: 0.6914 - precision_m: 0.6914 - recall_m: 0.6996\n",
            "Epoch 72/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0282 - acc: 0.9918 - f1_m: 0.7849 - precision_m: 0.7888 - recall_m: 0.7888\n",
            "Epoch 73/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0342 - acc: 0.9897 - f1_m: 0.7037 - precision_m: 0.7202 - recall_m: 0.6955\n",
            "Epoch 74/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0248 - acc: 0.9918 - f1_m: 0.7913 - precision_m: 0.7901 - recall_m: 0.7970\n",
            "Epoch 75/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0284 - acc: 0.9897 - f1_m: 0.6925 - precision_m: 0.7023 - recall_m: 0.6886\n",
            "Epoch 76/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0634 - acc: 0.9835 - f1_m: 0.7506 - precision_m: 0.7641 - recall_m: 0.7531\n",
            "Epoch 77/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0422 - acc: 0.9897 - f1_m: 0.6693 - precision_m: 0.6749 - recall_m: 0.6653\n",
            "Epoch 78/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0701 - acc: 0.9753 - f1_m: 0.6688 - precision_m: 0.6900 - recall_m: 0.6634\n",
            "Epoch 79/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0114 - acc: 0.9979 - f1_m: 0.7004 - precision_m: 0.7037 - recall_m: 0.6982\n",
            "Epoch 80/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1012 - acc: 0.9691 - f1_m: 0.7118 - precision_m: 0.7366 - recall_m: 0.7078\n",
            "Chunks:3 Tiempo de procesamiento (secs):248.74175095558167\n",
            "Test: \t Accuracy=0.885286783042394, \n",
            "\t F1 score=0.0764123935651898, \n",
            "\t Precision=0.1596009975062344, \n",
            "\t Recall=0.0503740643622572\n",
            "#####################################################################\n",
            "\n",
            "\n",
            "\n",
            "Chunks:4\n",
            "Max document length: 30000\n",
            "Vocabulary size: 95026\n",
            "Epoch 1/80\n",
            "486/486 [==============================] - 5s 10ms/step - loss: 0.5458 - acc: 0.7942 - f1_m: 0.0322 - precision_m: 0.0266 - recall_m: 0.0590\n",
            "Epoch 2/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4490 - acc: 0.8292 - f1_m: 0.0110 - precision_m: 0.0165 - recall_m: 0.0082\n",
            "Epoch 3/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4523 - acc: 0.8313 - f1_m: 0.0192 - precision_m: 0.0329 - recall_m: 0.0137\n",
            "Epoch 4/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4228 - acc: 0.8354 - f1_m: 0.0532 - precision_m: 0.0823 - recall_m: 0.0425\n",
            "Epoch 5/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3834 - acc: 0.8457 - f1_m: 0.1015 - precision_m: 0.1440 - recall_m: 0.0857\n",
            "Epoch 6/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3547 - acc: 0.8601 - f1_m: 0.1407 - precision_m: 0.1934 - recall_m: 0.1166\n",
            "Epoch 7/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3240 - acc: 0.8704 - f1_m: 0.2717 - precision_m: 0.3299 - recall_m: 0.2564\n",
            "Epoch 8/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2738 - acc: 0.8992 - f1_m: 0.4209 - precision_m: 0.5021 - recall_m: 0.3909\n",
            "Epoch 9/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2476 - acc: 0.9074 - f1_m: 0.4294 - precision_m: 0.4918 - recall_m: 0.4055\n",
            "Epoch 10/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2116 - acc: 0.9239 - f1_m: 0.4176 - precision_m: 0.4760 - recall_m: 0.4115\n",
            "Epoch 11/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1933 - acc: 0.9156 - f1_m: 0.4487 - precision_m: 0.5432 - recall_m: 0.4115\n",
            "Epoch 12/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1924 - acc: 0.9177 - f1_m: 0.4722 - precision_m: 0.5295 - recall_m: 0.4543\n",
            "Epoch 13/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1734 - acc: 0.9568 - f1_m: 0.6789 - precision_m: 0.7160 - recall_m: 0.6708\n",
            "Epoch 14/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1592 - acc: 0.9568 - f1_m: 0.6147 - precision_m: 0.6790 - recall_m: 0.5846\n",
            "Epoch 15/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1132 - acc: 0.9609 - f1_m: 0.6507 - precision_m: 0.6914 - recall_m: 0.6420\n",
            "Epoch 16/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1427 - acc: 0.9547 - f1_m: 0.5361 - precision_m: 0.5665 - recall_m: 0.5302\n",
            "Epoch 17/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1028 - acc: 0.9712 - f1_m: 0.6997 - precision_m: 0.7449 - recall_m: 0.6804\n",
            "Epoch 18/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0934 - acc: 0.9733 - f1_m: 0.6339 - precision_m: 0.6598 - recall_m: 0.6255\n",
            "Epoch 19/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0908 - acc: 0.9733 - f1_m: 0.6735 - precision_m: 0.7023 - recall_m: 0.6584\n",
            "Epoch 20/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0990 - acc: 0.9650 - f1_m: 0.6582 - precision_m: 0.6955 - recall_m: 0.6379\n",
            "Epoch 21/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0762 - acc: 0.9794 - f1_m: 0.7027 - precision_m: 0.7202 - recall_m: 0.6934\n",
            "Epoch 22/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0845 - acc: 0.9733 - f1_m: 0.7027 - precision_m: 0.7243 - recall_m: 0.6990\n",
            "Epoch 23/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1174 - acc: 0.9671 - f1_m: 0.6372 - precision_m: 0.6872 - recall_m: 0.6118\n",
            "Epoch 24/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0642 - acc: 0.9794 - f1_m: 0.6937 - precision_m: 0.7106 - recall_m: 0.6872\n",
            "Epoch 25/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1218 - acc: 0.9609 - f1_m: 0.6957 - precision_m: 0.7311 - recall_m: 0.6763\n",
            "Epoch 26/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0844 - acc: 0.9691 - f1_m: 0.6756 - precision_m: 0.7202 - recall_m: 0.6612\n",
            "Epoch 27/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0579 - acc: 0.9918 - f1_m: 0.7178 - precision_m: 0.7202 - recall_m: 0.7160\n",
            "Epoch 28/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0575 - acc: 0.9815 - f1_m: 0.6605 - precision_m: 0.6872 - recall_m: 0.6475\n",
            "Epoch 29/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0691 - acc: 0.9794 - f1_m: 0.7167 - precision_m: 0.7229 - recall_m: 0.7188\n",
            "Epoch 30/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0625 - acc: 0.9774 - f1_m: 0.6938 - precision_m: 0.7064 - recall_m: 0.6927\n",
            "Epoch 31/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0807 - acc: 0.9774 - f1_m: 0.6743 - precision_m: 0.6893 - recall_m: 0.6724\n",
            "Epoch 32/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0996 - acc: 0.9712 - f1_m: 0.6254 - precision_m: 0.6584 - recall_m: 0.6077\n",
            "Epoch 33/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0757 - acc: 0.9691 - f1_m: 0.7309 - precision_m: 0.7778 - recall_m: 0.7112\n",
            "Epoch 34/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0545 - acc: 0.9856 - f1_m: 0.7136 - precision_m: 0.7366 - recall_m: 0.7010\n",
            "Epoch 35/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0566 - acc: 0.9835 - f1_m: 0.7580 - precision_m: 0.7723 - recall_m: 0.7586\n",
            "Epoch 36/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0529 - acc: 0.9815 - f1_m: 0.6835 - precision_m: 0.6941 - recall_m: 0.6818\n",
            "Epoch 37/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0605 - acc: 0.9835 - f1_m: 0.7167 - precision_m: 0.7311 - recall_m: 0.7106\n",
            "Epoch 38/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0804 - acc: 0.9815 - f1_m: 0.6256 - precision_m: 0.6461 - recall_m: 0.6173\n",
            "Epoch 39/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0431 - acc: 0.9877 - f1_m: 0.6785 - precision_m: 0.7037 - recall_m: 0.6653\n",
            "Epoch 40/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0495 - acc: 0.9815 - f1_m: 0.7333 - precision_m: 0.7449 - recall_m: 0.7311\n",
            "Epoch 41/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0681 - acc: 0.9794 - f1_m: 0.6938 - precision_m: 0.7147 - recall_m: 0.6845\n",
            "Epoch 42/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0583 - acc: 0.9856 - f1_m: 0.7901 - precision_m: 0.7984 - recall_m: 0.7901\n",
            "Epoch 43/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0487 - acc: 0.9835 - f1_m: 0.7237 - precision_m: 0.7394 - recall_m: 0.7222\n",
            "Epoch 44/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0739 - acc: 0.9794 - f1_m: 0.6757 - precision_m: 0.6955 - recall_m: 0.6708\n",
            "Epoch 45/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0705 - acc: 0.9794 - f1_m: 0.7188 - precision_m: 0.7407 - recall_m: 0.7078\n",
            "Epoch 46/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0534 - acc: 0.9815 - f1_m: 0.7753 - precision_m: 0.7901 - recall_m: 0.7709\n",
            "Epoch 47/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0522 - acc: 0.9856 - f1_m: 0.7364 - precision_m: 0.7572 - recall_m: 0.7243\n",
            "Epoch 48/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0487 - acc: 0.9877 - f1_m: 0.6693 - precision_m: 0.6914 - recall_m: 0.6571\n",
            "Epoch 49/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0455 - acc: 0.9856 - f1_m: 0.7472 - precision_m: 0.7737 - recall_m: 0.7311\n",
            "Epoch 50/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0401 - acc: 0.9897 - f1_m: 0.7723 - precision_m: 0.7778 - recall_m: 0.7695\n",
            "Epoch 51/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0267 - acc: 0.9918 - f1_m: 0.7616 - precision_m: 0.7682 - recall_m: 0.7599\n",
            "Epoch 52/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0517 - acc: 0.9897 - f1_m: 0.7311 - precision_m: 0.7407 - recall_m: 0.7259\n",
            "Epoch 53/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0471 - acc: 0.9835 - f1_m: 0.7754 - precision_m: 0.7942 - recall_m: 0.7709\n",
            "Epoch 54/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0608 - acc: 0.9835 - f1_m: 0.7520 - precision_m: 0.7695 - recall_m: 0.7503\n",
            "Epoch 55/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0630 - acc: 0.9794 - f1_m: 0.7158 - precision_m: 0.7311 - recall_m: 0.7092\n",
            "Epoch 56/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0692 - acc: 0.9815 - f1_m: 0.6559 - precision_m: 0.6749 - recall_m: 0.6447\n",
            "Epoch 57/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0672 - acc: 0.9856 - f1_m: 0.7817 - precision_m: 0.7984 - recall_m: 0.7759\n",
            "Epoch 58/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0445 - acc: 0.9856 - f1_m: 0.7882 - precision_m: 0.7942 - recall_m: 0.7888\n",
            "Epoch 59/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0579 - acc: 0.9856 - f1_m: 0.7561 - precision_m: 0.7682 - recall_m: 0.7517\n",
            "Epoch 60/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0374 - acc: 0.9918 - f1_m: 0.8080 - precision_m: 0.8025 - recall_m: 0.8189\n",
            "Epoch 61/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0145 - acc: 0.9959 - f1_m: 0.6927 - precision_m: 0.7037 - recall_m: 0.6872\n",
            "Epoch 62/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0338 - acc: 0.9877 - f1_m: 0.7617 - precision_m: 0.7778 - recall_m: 0.7572\n",
            "Epoch 63/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0835 - acc: 0.9856 - f1_m: 0.7365 - precision_m: 0.7531 - recall_m: 0.7353\n",
            "Epoch 64/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0571 - acc: 0.9815 - f1_m: 0.7432 - precision_m: 0.7641 - recall_m: 0.7339\n",
            "Epoch 65/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0769 - acc: 0.9774 - f1_m: 0.7112 - precision_m: 0.7284 - recall_m: 0.7051\n",
            "Epoch 66/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0626 - acc: 0.9835 - f1_m: 0.7164 - precision_m: 0.7353 - recall_m: 0.7100\n",
            "Epoch 67/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0361 - acc: 0.9918 - f1_m: 0.7410 - precision_m: 0.7449 - recall_m: 0.7421\n",
            "Epoch 68/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0147 - acc: 0.9979 - f1_m: 0.7682 - precision_m: 0.7737 - recall_m: 0.7654\n",
            "Epoch 69/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0628 - acc: 0.9794 - f1_m: 0.6881 - precision_m: 0.7078 - recall_m: 0.6776\n",
            "Epoch 70/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0316 - acc: 0.9938 - f1_m: 0.7224 - precision_m: 0.7366 - recall_m: 0.7147\n",
            "Epoch 71/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0077 - acc: 1.0000 - f1_m: 0.7243 - precision_m: 0.7243 - recall_m: 0.7243\n",
            "Epoch 72/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0200 - acc: 0.9918 - f1_m: 0.7849 - precision_m: 0.8025 - recall_m: 0.7750\n",
            "Epoch 73/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0285 - acc: 0.9938 - f1_m: 0.7202 - precision_m: 0.7366 - recall_m: 0.7119\n",
            "Epoch 74/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0491 - acc: 0.9877 - f1_m: 0.7694 - precision_m: 0.7778 - recall_m: 0.7682\n",
            "Epoch 75/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0278 - acc: 0.9897 - f1_m: 0.6725 - precision_m: 0.6708 - recall_m: 0.6749\n",
            "Epoch 76/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1012 - acc: 0.9712 - f1_m: 0.7068 - precision_m: 0.7613 - recall_m: 0.6831\n",
            "Epoch 77/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0266 - acc: 0.9918 - f1_m: 0.6912 - precision_m: 0.7023 - recall_m: 0.6872\n",
            "Epoch 78/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0506 - acc: 0.9877 - f1_m: 0.6763 - precision_m: 0.6790 - recall_m: 0.6790\n",
            "Epoch 79/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0261 - acc: 0.9938 - f1_m: 0.6804 - precision_m: 0.6914 - recall_m: 0.6749\n",
            "Epoch 80/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0199 - acc: 0.9959 - f1_m: 0.7915 - precision_m: 0.8025 - recall_m: 0.7860\n",
            "Chunks:4 Tiempo de procesamiento (secs):245.53213143348694\n",
            "Test: \t Accuracy=0.8877805486284289, \n",
            "\t F1 score=0.0775204798824472, \n",
            "\t Precision=0.1596009975062344, \n",
            "\t Recall=0.051870324665174224\n",
            "#####################################################################\n",
            "\n",
            "\n",
            "\n",
            "Chunks:5\n",
            "Max document length: 30000\n",
            "Vocabulary size: 95038\n",
            "Epoch 1/80\n",
            "486/486 [==============================] - 5s 10ms/step - loss: 0.5436 - acc: 0.8004 - f1_m: 0.0607 - precision_m: 0.0636 - recall_m: 0.0919\n",
            "Epoch 2/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4523 - acc: 0.8313 - f1_m: 0.0110 - precision_m: 0.0165 - recall_m: 0.0082\n",
            "Epoch 3/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4479 - acc: 0.8292 - f1_m: 0.0082 - precision_m: 0.0165 - recall_m: 0.0055\n",
            "Epoch 4/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4146 - acc: 0.8374 - f1_m: 0.0532 - precision_m: 0.0823 - recall_m: 0.0425\n",
            "Epoch 5/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3732 - acc: 0.8416 - f1_m: 0.0604 - precision_m: 0.0947 - recall_m: 0.0473\n",
            "Epoch 6/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3532 - acc: 0.8560 - f1_m: 0.1495 - precision_m: 0.2263 - recall_m: 0.1166\n",
            "Epoch 7/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3223 - acc: 0.8663 - f1_m: 0.2526 - precision_m: 0.3272 - recall_m: 0.2226\n",
            "Epoch 8/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2831 - acc: 0.8889 - f1_m: 0.3731 - precision_m: 0.4691 - recall_m: 0.3333\n",
            "Epoch 9/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2383 - acc: 0.9074 - f1_m: 0.4196 - precision_m: 0.4753 - recall_m: 0.3986\n",
            "Epoch 10/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2147 - acc: 0.9280 - f1_m: 0.4313 - precision_m: 0.4883 - recall_m: 0.4143\n",
            "Epoch 11/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1726 - acc: 0.9383 - f1_m: 0.5244 - precision_m: 0.6091 - recall_m: 0.4870\n",
            "Epoch 12/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1824 - acc: 0.9300 - f1_m: 0.5101 - precision_m: 0.5706 - recall_m: 0.4845\n",
            "Epoch 13/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1748 - acc: 0.9465 - f1_m: 0.6214 - precision_m: 0.6680 - recall_m: 0.6104\n",
            "Epoch 14/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1423 - acc: 0.9588 - f1_m: 0.6122 - precision_m: 0.6626 - recall_m: 0.5915\n",
            "Epoch 15/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1154 - acc: 0.9609 - f1_m: 0.6418 - precision_m: 0.6680 - recall_m: 0.6392\n",
            "Epoch 16/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1252 - acc: 0.9630 - f1_m: 0.5411 - precision_m: 0.5706 - recall_m: 0.5336\n",
            "Epoch 17/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1171 - acc: 0.9609 - f1_m: 0.6588 - precision_m: 0.6996 - recall_m: 0.6406\n",
            "Epoch 18/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0894 - acc: 0.9774 - f1_m: 0.6260 - precision_m: 0.6543 - recall_m: 0.6104\n",
            "Epoch 19/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1031 - acc: 0.9671 - f1_m: 0.6517 - precision_m: 0.6831 - recall_m: 0.6379\n",
            "Epoch 20/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0941 - acc: 0.9691 - f1_m: 0.6499 - precision_m: 0.6872 - recall_m: 0.6296\n",
            "Epoch 21/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0822 - acc: 0.9753 - f1_m: 0.7063 - precision_m: 0.7366 - recall_m: 0.6914\n",
            "Epoch 22/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0621 - acc: 0.9774 - f1_m: 0.7082 - precision_m: 0.7325 - recall_m: 0.6990\n",
            "Epoch 23/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0927 - acc: 0.9733 - f1_m: 0.6640 - precision_m: 0.6941 - recall_m: 0.6516\n",
            "Epoch 24/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0739 - acc: 0.9774 - f1_m: 0.6920 - precision_m: 0.7147 - recall_m: 0.6831\n",
            "Epoch 25/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1003 - acc: 0.9630 - f1_m: 0.6673 - precision_m: 0.6927 - recall_m: 0.6557\n",
            "Epoch 26/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0891 - acc: 0.9712 - f1_m: 0.6686 - precision_m: 0.6955 - recall_m: 0.6694\n",
            "Epoch 27/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0420 - acc: 0.9877 - f1_m: 0.6949 - precision_m: 0.7037 - recall_m: 0.6900\n",
            "Epoch 28/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0527 - acc: 0.9774 - f1_m: 0.6584 - precision_m: 0.6804 - recall_m: 0.6502\n",
            "Epoch 29/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0794 - acc: 0.9753 - f1_m: 0.6948 - precision_m: 0.7064 - recall_m: 0.6941\n",
            "Epoch 30/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0710 - acc: 0.9753 - f1_m: 0.7125 - precision_m: 0.7394 - recall_m: 0.7037\n",
            "Epoch 31/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0770 - acc: 0.9856 - f1_m: 0.7323 - precision_m: 0.7531 - recall_m: 0.7196\n",
            "Epoch 32/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0700 - acc: 0.9753 - f1_m: 0.6276 - precision_m: 0.6529 - recall_m: 0.6159\n",
            "Epoch 33/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0715 - acc: 0.9753 - f1_m: 0.7418 - precision_m: 0.7805 - recall_m: 0.7250\n",
            "Epoch 34/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0495 - acc: 0.9856 - f1_m: 0.7064 - precision_m: 0.7202 - recall_m: 0.7010\n",
            "Epoch 35/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0681 - acc: 0.9794 - f1_m: 0.7476 - precision_m: 0.7723 - recall_m: 0.7394\n",
            "Epoch 36/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0374 - acc: 0.9856 - f1_m: 0.7110 - precision_m: 0.7325 - recall_m: 0.7037\n",
            "Epoch 37/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0660 - acc: 0.9815 - f1_m: 0.7359 - precision_m: 0.7558 - recall_m: 0.7325\n",
            "Epoch 38/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0435 - acc: 0.9856 - f1_m: 0.6313 - precision_m: 0.6461 - recall_m: 0.6269\n",
            "Epoch 39/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0487 - acc: 0.9877 - f1_m: 0.6993 - precision_m: 0.7119 - recall_m: 0.6955\n",
            "Epoch 40/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0405 - acc: 0.9877 - f1_m: 0.7684 - precision_m: 0.7860 - recall_m: 0.7586\n",
            "Epoch 41/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0386 - acc: 0.9856 - f1_m: 0.7432 - precision_m: 0.7558 - recall_m: 0.7421\n",
            "Epoch 42/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0542 - acc: 0.9856 - f1_m: 0.7901 - precision_m: 0.7984 - recall_m: 0.7901\n",
            "Epoch 43/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0386 - acc: 0.9877 - f1_m: 0.7597 - precision_m: 0.7860 - recall_m: 0.7449\n",
            "Epoch 44/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0447 - acc: 0.9877 - f1_m: 0.6876 - precision_m: 0.6914 - recall_m: 0.6872\n",
            "Epoch 45/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0346 - acc: 0.9979 - f1_m: 0.8134 - precision_m: 0.8189 - recall_m: 0.8107\n",
            "Epoch 46/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0349 - acc: 0.9877 - f1_m: 0.7923 - precision_m: 0.8066 - recall_m: 0.7846\n",
            "Epoch 47/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0541 - acc: 0.9856 - f1_m: 0.7402 - precision_m: 0.7490 - recall_m: 0.7407\n",
            "Epoch 48/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0456 - acc: 0.9877 - f1_m: 0.6844 - precision_m: 0.6996 - recall_m: 0.6794\n",
            "Epoch 49/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0986 - acc: 0.9650 - f1_m: 0.7110 - precision_m: 0.7435 - recall_m: 0.6982\n",
            "Epoch 50/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0709 - acc: 0.9712 - f1_m: 0.7202 - precision_m: 0.7449 - recall_m: 0.7202\n",
            "Epoch 51/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0154 - acc: 0.9938 - f1_m: 0.7813 - precision_m: 0.7901 - recall_m: 0.7764\n",
            "Epoch 52/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0774 - acc: 0.9753 - f1_m: 0.7064 - precision_m: 0.7243 - recall_m: 0.7067\n",
            "Epoch 53/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0585 - acc: 0.9691 - f1_m: 0.7200 - precision_m: 0.7366 - recall_m: 0.7188\n",
            "Epoch 54/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0473 - acc: 0.9856 - f1_m: 0.7573 - precision_m: 0.7586 - recall_m: 0.7599\n",
            "Epoch 55/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0377 - acc: 0.9897 - f1_m: 0.7580 - precision_m: 0.7613 - recall_m: 0.7558\n",
            "Epoch 56/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0301 - acc: 0.9938 - f1_m: 0.6840 - precision_m: 0.6914 - recall_m: 0.6798\n",
            "Epoch 57/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0288 - acc: 0.9918 - f1_m: 0.7956 - precision_m: 0.8011 - recall_m: 0.7929\n",
            "Epoch 58/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0545 - acc: 0.9856 - f1_m: 0.8133 - precision_m: 0.8313 - recall_m: 0.8052\n",
            "Epoch 59/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0561 - acc: 0.9918 - f1_m: 0.7813 - precision_m: 0.7901 - recall_m: 0.7764\n",
            "Epoch 60/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0499 - acc: 0.9897 - f1_m: 0.8178 - precision_m: 0.8354 - recall_m: 0.8080\n",
            "Epoch 61/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0165 - acc: 0.9979 - f1_m: 0.6872 - precision_m: 0.6872 - recall_m: 0.6872\n",
            "Epoch 62/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0347 - acc: 0.9856 - f1_m: 0.7597 - precision_m: 0.7750 - recall_m: 0.7558\n",
            "Epoch 63/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0280 - acc: 0.9897 - f1_m: 0.7474 - precision_m: 0.7654 - recall_m: 0.7394\n",
            "Epoch 64/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0463 - acc: 0.9856 - f1_m: 0.7750 - precision_m: 0.7860 - recall_m: 0.7723\n",
            "Epoch 65/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0372 - acc: 0.9918 - f1_m: 0.7716 - precision_m: 0.7737 - recall_m: 0.7750\n",
            "Epoch 66/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0496 - acc: 0.9835 - f1_m: 0.7188 - precision_m: 0.7298 - recall_m: 0.7160\n",
            "Epoch 67/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0477 - acc: 0.9856 - f1_m: 0.7167 - precision_m: 0.7243 - recall_m: 0.7174\n",
            "Epoch 68/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0482 - acc: 0.9856 - f1_m: 0.7355 - precision_m: 0.7531 - recall_m: 0.7265\n",
            "Epoch 69/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0138 - acc: 0.9979 - f1_m: 0.7572 - precision_m: 0.7572 - recall_m: 0.7572\n",
            "Epoch 70/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0270 - acc: 0.9918 - f1_m: 0.7224 - precision_m: 0.7284 - recall_m: 0.7229\n",
            "Epoch 71/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0400 - acc: 0.9918 - f1_m: 0.6990 - precision_m: 0.6996 - recall_m: 0.7023\n",
            "Epoch 72/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0221 - acc: 0.9938 - f1_m: 0.7882 - precision_m: 0.7942 - recall_m: 0.7888\n",
            "Epoch 73/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0196 - acc: 0.9918 - f1_m: 0.7074 - precision_m: 0.7202 - recall_m: 0.7004\n",
            "Epoch 74/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0178 - acc: 0.9938 - f1_m: 0.7946 - precision_m: 0.7901 - recall_m: 0.8025\n",
            "Epoch 75/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0419 - acc: 0.9815 - f1_m: 0.6710 - precision_m: 0.6790 - recall_m: 0.6653\n",
            "Epoch 76/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0238 - acc: 0.9959 - f1_m: 0.7641 - precision_m: 0.7695 - recall_m: 0.7613\n",
            "Epoch 77/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0185 - acc: 0.9959 - f1_m: 0.6881 - precision_m: 0.6859 - recall_m: 0.6914\n",
            "Epoch 78/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0343 - acc: 0.9897 - f1_m: 0.7293 - precision_m: 0.7366 - recall_m: 0.7251\n",
            "Epoch 79/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0159 - acc: 0.9959 - f1_m: 0.6927 - precision_m: 0.7037 - recall_m: 0.6872\n",
            "Epoch 80/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0307 - acc: 0.9938 - f1_m: 0.7750 - precision_m: 0.7860 - recall_m: 0.7695\n",
            "Chunks:5 Tiempo de procesamiento (secs):249.92259216308594\n",
            "Test: \t Accuracy=0.8778054862842892, \n",
            "\t F1 score=0.08755540253218273, \n",
            "\t Precision=0.15073427595105254, \n",
            "\t Recall=0.06184538700931387\n",
            "#####################################################################\n",
            "\n",
            "\n",
            "\n",
            "Chunks:6\n",
            "Max document length: 30000\n",
            "Vocabulary size: 95469\n",
            "Epoch 1/80\n",
            "486/486 [==============================] - 5s 11ms/step - loss: 0.5401 - acc: 0.8004 - f1_m: 0.0404 - precision_m: 0.0403 - recall_m: 0.0672\n",
            "Epoch 2/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4443 - acc: 0.8313 - f1_m: 0.0110 - precision_m: 0.0165 - recall_m: 0.0082\n",
            "Epoch 3/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4507 - acc: 0.8292 - f1_m: 0.0082 - precision_m: 0.0165 - recall_m: 0.0055\n",
            "Epoch 4/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4140 - acc: 0.8354 - f1_m: 0.0302 - precision_m: 0.0494 - recall_m: 0.0219\n",
            "Epoch 5/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3809 - acc: 0.8395 - f1_m: 0.0604 - precision_m: 0.0782 - recall_m: 0.0528\n",
            "Epoch 6/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3554 - acc: 0.8539 - f1_m: 0.1490 - precision_m: 0.2181 - recall_m: 0.1166\n",
            "Epoch 7/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3296 - acc: 0.8724 - f1_m: 0.2460 - precision_m: 0.3189 - recall_m: 0.2221\n",
            "Epoch 8/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2815 - acc: 0.8827 - f1_m: 0.3663 - precision_m: 0.4431 - recall_m: 0.3347\n",
            "Epoch 9/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2629 - acc: 0.9053 - f1_m: 0.4115 - precision_m: 0.4691 - recall_m: 0.3882\n",
            "Epoch 10/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2200 - acc: 0.9300 - f1_m: 0.4284 - precision_m: 0.4979 - recall_m: 0.4060\n",
            "Epoch 11/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1878 - acc: 0.9300 - f1_m: 0.5184 - precision_m: 0.6008 - recall_m: 0.4842\n",
            "Epoch 12/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1805 - acc: 0.9342 - f1_m: 0.5303 - precision_m: 0.5871 - recall_m: 0.5070\n",
            "Epoch 13/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1851 - acc: 0.9424 - f1_m: 0.6198 - precision_m: 0.6845 - recall_m: 0.6022\n",
            "Epoch 14/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1580 - acc: 0.9403 - f1_m: 0.5719 - precision_m: 0.6406 - recall_m: 0.5443\n",
            "Epoch 15/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1126 - acc: 0.9712 - f1_m: 0.6686 - precision_m: 0.6982 - recall_m: 0.6598\n",
            "Epoch 16/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1172 - acc: 0.9650 - f1_m: 0.5687 - precision_m: 0.6049 - recall_m: 0.5501\n",
            "Epoch 17/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1018 - acc: 0.9712 - f1_m: 0.6959 - precision_m: 0.7366 - recall_m: 0.6722\n",
            "Epoch 18/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0733 - acc: 0.9753 - f1_m: 0.6187 - precision_m: 0.6337 - recall_m: 0.6104\n",
            "Epoch 19/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0799 - acc: 0.9835 - f1_m: 0.7263 - precision_m: 0.7490 - recall_m: 0.7174\n",
            "Epoch 20/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1046 - acc: 0.9650 - f1_m: 0.6388 - precision_m: 0.6818 - recall_m: 0.6173\n",
            "Epoch 21/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0704 - acc: 0.9794 - f1_m: 0.7355 - precision_m: 0.7531 - recall_m: 0.7257\n",
            "Epoch 22/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0642 - acc: 0.9774 - f1_m: 0.7172 - precision_m: 0.7394 - recall_m: 0.7114\n",
            "Epoch 23/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1124 - acc: 0.9650 - f1_m: 0.6209 - precision_m: 0.6626 - recall_m: 0.6049\n",
            "Epoch 24/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0715 - acc: 0.9753 - f1_m: 0.6749 - precision_m: 0.6941 - recall_m: 0.6667\n",
            "Epoch 25/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1114 - acc: 0.9691 - f1_m: 0.6847 - precision_m: 0.7037 - recall_m: 0.6818\n",
            "Epoch 26/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0790 - acc: 0.9712 - f1_m: 0.6755 - precision_m: 0.7114 - recall_m: 0.6598\n",
            "Epoch 27/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0650 - acc: 0.9753 - f1_m: 0.6695 - precision_m: 0.6818 - recall_m: 0.6639\n",
            "Epoch 28/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0474 - acc: 0.9897 - f1_m: 0.7012 - precision_m: 0.7160 - recall_m: 0.6968\n",
            "Epoch 29/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0477 - acc: 0.9835 - f1_m: 0.7260 - precision_m: 0.7311 - recall_m: 0.7251\n",
            "Epoch 30/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0636 - acc: 0.9774 - f1_m: 0.7158 - precision_m: 0.7394 - recall_m: 0.7092\n",
            "Epoch 31/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0628 - acc: 0.9815 - f1_m: 0.7149 - precision_m: 0.7366 - recall_m: 0.7119\n",
            "Epoch 32/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0873 - acc: 0.9774 - f1_m: 0.6638 - precision_m: 0.6914 - recall_m: 0.6488\n",
            "Epoch 33/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0798 - acc: 0.9794 - f1_m: 0.7528 - precision_m: 0.7682 - recall_m: 0.7462\n",
            "Epoch 34/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0467 - acc: 0.9897 - f1_m: 0.7246 - precision_m: 0.7366 - recall_m: 0.7174\n",
            "Epoch 35/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0616 - acc: 0.9815 - f1_m: 0.7590 - precision_m: 0.7737 - recall_m: 0.7586\n",
            "Epoch 36/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0697 - acc: 0.9774 - f1_m: 0.6720 - precision_m: 0.6996 - recall_m: 0.6626\n",
            "Epoch 37/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0808 - acc: 0.9774 - f1_m: 0.7177 - precision_m: 0.7353 - recall_m: 0.7160\n",
            "Epoch 38/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0989 - acc: 0.9774 - f1_m: 0.6344 - precision_m: 0.6461 - recall_m: 0.6310\n",
            "Epoch 39/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0588 - acc: 0.9753 - f1_m: 0.6472 - precision_m: 0.6708 - recall_m: 0.6379\n",
            "Epoch 40/80\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.0447 - acc: 0.9877 - f1_m: 0.7663 - precision_m: 0.7778 - recall_m: 0.7641\n",
            "Epoch 41/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0443 - acc: 0.9835 - f1_m: 0.7332 - precision_m: 0.7449 - recall_m: 0.7298\n",
            "Epoch 42/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0346 - acc: 0.9959 - f1_m: 0.8395 - precision_m: 0.8395 - recall_m: 0.8395\n",
            "Epoch 43/80\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.0339 - acc: 0.9856 - f1_m: 0.7310 - precision_m: 0.7407 - recall_m: 0.7311\n",
            "Epoch 44/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0287 - acc: 0.9918 - f1_m: 0.7004 - precision_m: 0.7037 - recall_m: 0.6982\n",
            "Epoch 45/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0302 - acc: 0.9938 - f1_m: 0.8080 - precision_m: 0.8189 - recall_m: 0.8025\n",
            "Epoch 46/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0235 - acc: 0.9918 - f1_m: 0.7956 - precision_m: 0.8066 - recall_m: 0.7901\n",
            "Epoch 47/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0408 - acc: 0.9856 - f1_m: 0.7347 - precision_m: 0.7490 - recall_m: 0.7270\n",
            "Epoch 48/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0569 - acc: 0.9815 - f1_m: 0.6757 - precision_m: 0.6955 - recall_m: 0.6698\n",
            "Epoch 49/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0962 - acc: 0.9609 - f1_m: 0.6917 - precision_m: 0.7353 - recall_m: 0.6708\n",
            "Epoch 50/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0711 - acc: 0.9794 - f1_m: 0.7452 - precision_m: 0.7695 - recall_m: 0.7407\n",
            "Epoch 51/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0334 - acc: 0.9918 - f1_m: 0.7616 - precision_m: 0.7737 - recall_m: 0.7545\n",
            "Epoch 52/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0361 - acc: 0.9918 - f1_m: 0.7609 - precision_m: 0.7654 - recall_m: 0.7621\n",
            "Epoch 53/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0522 - acc: 0.9733 - f1_m: 0.7090 - precision_m: 0.7243 - recall_m: 0.7064\n",
            "Epoch 54/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0274 - acc: 0.9938 - f1_m: 0.7860 - precision_m: 0.8025 - recall_m: 0.7778\n",
            "Epoch 55/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0547 - acc: 0.9774 - f1_m: 0.7255 - precision_m: 0.7531 - recall_m: 0.7188\n",
            "Epoch 56/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0407 - acc: 0.9897 - f1_m: 0.6616 - precision_m: 0.6749 - recall_m: 0.6543\n",
            "Epoch 57/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0440 - acc: 0.9856 - f1_m: 0.7890 - precision_m: 0.8066 - recall_m: 0.7874\n",
            "Epoch 58/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0373 - acc: 0.9897 - f1_m: 0.8233 - precision_m: 0.8299 - recall_m: 0.8217\n",
            "Epoch 59/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0316 - acc: 0.9938 - f1_m: 0.7868 - precision_m: 0.7846 - recall_m: 0.7901\n",
            "Epoch 60/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0322 - acc: 0.9877 - f1_m: 0.8056 - precision_m: 0.8107 - recall_m: 0.8066\n",
            "Epoch 61/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0286 - acc: 0.9897 - f1_m: 0.6821 - precision_m: 0.6955 - recall_m: 0.6785\n",
            "Epoch 62/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0224 - acc: 0.9959 - f1_m: 0.7827 - precision_m: 0.7805 - recall_m: 0.7860\n",
            "Epoch 63/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0277 - acc: 0.9918 - f1_m: 0.7553 - precision_m: 0.7695 - recall_m: 0.7476\n",
            "Epoch 64/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0241 - acc: 0.9938 - f1_m: 0.7750 - precision_m: 0.7860 - recall_m: 0.7695\n",
            "Epoch 65/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0840 - acc: 0.9774 - f1_m: 0.7079 - precision_m: 0.7284 - recall_m: 0.6996\n",
            "Epoch 66/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0936 - acc: 0.9691 - f1_m: 0.7257 - precision_m: 0.7668 - recall_m: 0.7073\n",
            "Epoch 67/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0512 - acc: 0.9815 - f1_m: 0.7172 - precision_m: 0.7333 - recall_m: 0.7174\n",
            "Epoch 68/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0588 - acc: 0.9877 - f1_m: 0.7301 - precision_m: 0.7353 - recall_m: 0.7292\n",
            "Epoch 69/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0256 - acc: 0.9938 - f1_m: 0.7462 - precision_m: 0.7490 - recall_m: 0.7490\n",
            "Epoch 70/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0198 - acc: 0.9918 - f1_m: 0.7090 - precision_m: 0.7119 - recall_m: 0.7106\n",
            "Epoch 71/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0198 - acc: 0.9938 - f1_m: 0.7100 - precision_m: 0.7188 - recall_m: 0.7078\n",
            "Epoch 72/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0111 - acc: 0.9959 - f1_m: 0.7915 - precision_m: 0.7942 - recall_m: 0.7942\n",
            "Epoch 73/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0222 - acc: 0.9959 - f1_m: 0.7278 - precision_m: 0.7366 - recall_m: 0.7229\n",
            "Epoch 74/80\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.0218 - acc: 0.9938 - f1_m: 0.7860 - precision_m: 0.7860 - recall_m: 0.7860\n",
            "Epoch 75/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0356 - acc: 0.9897 - f1_m: 0.6938 - precision_m: 0.6982 - recall_m: 0.6927\n",
            "Epoch 76/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0501 - acc: 0.9897 - f1_m: 0.7388 - precision_m: 0.7476 - recall_m: 0.7366\n",
            "Epoch 77/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0319 - acc: 0.9897 - f1_m: 0.6716 - precision_m: 0.6914 - recall_m: 0.6612\n",
            "Epoch 78/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0273 - acc: 0.9918 - f1_m: 0.7333 - precision_m: 0.7449 - recall_m: 0.7311\n",
            "Epoch 79/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0137 - acc: 0.9918 - f1_m: 0.6883 - precision_m: 0.6982 - recall_m: 0.6845\n",
            "Epoch 80/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0307 - acc: 0.9897 - f1_m: 0.7706 - precision_m: 0.7805 - recall_m: 0.7668\n",
            "Chunks:6 Tiempo de procesamiento (secs):254.70487594604492\n",
            "Test: \t Accuracy=0.8802992518703242, \n",
            "\t F1 score=0.040280248161563253, \n",
            "\t Precision=0.1596009975062344, \n",
            "\t Recall=0.0234413967465522\n",
            "#####################################################################\n",
            "\n",
            "\n",
            "\n",
            "Chunks:7\n",
            "Max document length: 30000\n",
            "Vocabulary size: 95466\n",
            "Epoch 1/80\n",
            "486/486 [==============================] - 5s 11ms/step - loss: 0.5444 - acc: 0.7942 - f1_m: 0.0404 - precision_m: 0.0403 - recall_m: 0.0672\n",
            "Epoch 2/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4445 - acc: 0.8313 - f1_m: 0.0110 - precision_m: 0.0165 - recall_m: 0.0082\n",
            "Epoch 3/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4524 - acc: 0.8292 - f1_m: 0.0082 - precision_m: 0.0165 - recall_m: 0.0055\n",
            "Epoch 4/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4169 - acc: 0.8374 - f1_m: 0.0615 - precision_m: 0.0988 - recall_m: 0.0480\n",
            "Epoch 5/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3842 - acc: 0.8374 - f1_m: 0.0521 - precision_m: 0.0658 - recall_m: 0.0466\n",
            "Epoch 6/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3569 - acc: 0.8498 - f1_m: 0.1210 - precision_m: 0.1715 - recall_m: 0.1001\n",
            "Epoch 7/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3194 - acc: 0.8745 - f1_m: 0.2531 - precision_m: 0.3381 - recall_m: 0.2303\n",
            "Epoch 8/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2752 - acc: 0.8909 - f1_m: 0.3704 - precision_m: 0.4527 - recall_m: 0.3361\n",
            "Epoch 9/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2445 - acc: 0.8992 - f1_m: 0.3920 - precision_m: 0.4588 - recall_m: 0.3720\n",
            "Epoch 10/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2150 - acc: 0.9321 - f1_m: 0.4571 - precision_m: 0.5185 - recall_m: 0.4348\n",
            "Epoch 11/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1834 - acc: 0.9444 - f1_m: 0.5694 - precision_m: 0.6337 - recall_m: 0.5418\n",
            "Epoch 12/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1699 - acc: 0.9321 - f1_m: 0.5459 - precision_m: 0.5871 - recall_m: 0.5257\n",
            "Epoch 13/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1604 - acc: 0.9568 - f1_m: 0.6701 - precision_m: 0.7078 - recall_m: 0.6543\n",
            "Epoch 14/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1540 - acc: 0.9527 - f1_m: 0.6377 - precision_m: 0.7064 - recall_m: 0.6071\n",
            "Epoch 15/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1085 - acc: 0.9650 - f1_m: 0.6481 - precision_m: 0.6804 - recall_m: 0.6406\n",
            "Epoch 16/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1182 - acc: 0.9650 - f1_m: 0.5609 - precision_m: 0.5926 - recall_m: 0.5501\n",
            "Epoch 17/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0928 - acc: 0.9712 - f1_m: 0.7001 - precision_m: 0.7243 - recall_m: 0.6886\n",
            "Epoch 18/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0828 - acc: 0.9794 - f1_m: 0.6388 - precision_m: 0.6626 - recall_m: 0.6324\n",
            "Epoch 19/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1001 - acc: 0.9753 - f1_m: 0.6964 - precision_m: 0.7243 - recall_m: 0.6790\n",
            "Epoch 20/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0915 - acc: 0.9733 - f1_m: 0.6695 - precision_m: 0.6982 - recall_m: 0.6557\n",
            "Epoch 21/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0685 - acc: 0.9774 - f1_m: 0.7186 - precision_m: 0.7284 - recall_m: 0.7126\n",
            "Epoch 22/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0496 - acc: 0.9815 - f1_m: 0.7425 - precision_m: 0.7613 - recall_m: 0.7361\n",
            "Epoch 23/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1115 - acc: 0.9774 - f1_m: 0.6735 - precision_m: 0.7037 - recall_m: 0.6598\n",
            "Epoch 24/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0484 - acc: 0.9897 - f1_m: 0.7246 - precision_m: 0.7366 - recall_m: 0.7174\n",
            "Epoch 25/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0644 - acc: 0.9794 - f1_m: 0.7241 - precision_m: 0.7366 - recall_m: 0.7160\n",
            "Epoch 26/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0683 - acc: 0.9712 - f1_m: 0.6591 - precision_m: 0.6922 - recall_m: 0.6461\n",
            "Epoch 27/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0432 - acc: 0.9856 - f1_m: 0.7224 - precision_m: 0.7449 - recall_m: 0.7147\n",
            "Epoch 28/80\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.0510 - acc: 0.9856 - f1_m: 0.6727 - precision_m: 0.6859 - recall_m: 0.6667\n",
            "Epoch 29/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0565 - acc: 0.9877 - f1_m: 0.7278 - precision_m: 0.7366 - recall_m: 0.7229\n",
            "Epoch 30/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0554 - acc: 0.9856 - f1_m: 0.7278 - precision_m: 0.7366 - recall_m: 0.7311\n",
            "Epoch 31/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0598 - acc: 0.9835 - f1_m: 0.7196 - precision_m: 0.7222 - recall_m: 0.7202\n",
            "Epoch 32/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0612 - acc: 0.9815 - f1_m: 0.6561 - precision_m: 0.6749 - recall_m: 0.6461\n",
            "Epoch 33/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0715 - acc: 0.9815 - f1_m: 0.7665 - precision_m: 0.7805 - recall_m: 0.7606\n",
            "Epoch 34/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0508 - acc: 0.9794 - f1_m: 0.7118 - precision_m: 0.7366 - recall_m: 0.6996\n",
            "Epoch 35/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0335 - acc: 0.9897 - f1_m: 0.7672 - precision_m: 0.7695 - recall_m: 0.7737\n",
            "Epoch 36/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0467 - acc: 0.9835 - f1_m: 0.6779 - precision_m: 0.6859 - recall_m: 0.6749\n",
            "Epoch 37/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0520 - acc: 0.9835 - f1_m: 0.7158 - precision_m: 0.7229 - recall_m: 0.7174\n",
            "Epoch 38/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0595 - acc: 0.9753 - f1_m: 0.6343 - precision_m: 0.6543 - recall_m: 0.6214\n",
            "Epoch 39/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0479 - acc: 0.9815 - f1_m: 0.6620 - precision_m: 0.6872 - recall_m: 0.6571\n",
            "Epoch 40/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0741 - acc: 0.9774 - f1_m: 0.7454 - precision_m: 0.7723 - recall_m: 0.7366\n",
            "Epoch 41/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0471 - acc: 0.9877 - f1_m: 0.7325 - precision_m: 0.7449 - recall_m: 0.7305\n",
            "Epoch 42/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0792 - acc: 0.9794 - f1_m: 0.7922 - precision_m: 0.8052 - recall_m: 0.7929\n",
            "Epoch 43/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0514 - acc: 0.9815 - f1_m: 0.7358 - precision_m: 0.7558 - recall_m: 0.7305\n",
            "Epoch 44/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0613 - acc: 0.9856 - f1_m: 0.6838 - precision_m: 0.6941 - recall_m: 0.6818\n",
            "Epoch 45/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0510 - acc: 0.9877 - f1_m: 0.7772 - precision_m: 0.8025 - recall_m: 0.7641\n",
            "Epoch 46/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0482 - acc: 0.9856 - f1_m: 0.7868 - precision_m: 0.8011 - recall_m: 0.7819\n",
            "Epoch 47/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0415 - acc: 0.9877 - f1_m: 0.7605 - precision_m: 0.7737 - recall_m: 0.7517\n",
            "Epoch 48/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0536 - acc: 0.9877 - f1_m: 0.6667 - precision_m: 0.6831 - recall_m: 0.6584\n",
            "Epoch 49/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0442 - acc: 0.9877 - f1_m: 0.7392 - precision_m: 0.7531 - recall_m: 0.7325\n",
            "Epoch 50/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0293 - acc: 0.9877 - f1_m: 0.7694 - precision_m: 0.7805 - recall_m: 0.7654\n",
            "Epoch 51/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0203 - acc: 0.9959 - f1_m: 0.7813 - precision_m: 0.7901 - recall_m: 0.7764\n",
            "Epoch 52/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0341 - acc: 0.9877 - f1_m: 0.7374 - precision_m: 0.7517 - recall_m: 0.7325\n",
            "Epoch 53/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0450 - acc: 0.9794 - f1_m: 0.7778 - precision_m: 0.7942 - recall_m: 0.7833\n",
            "Epoch 54/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0207 - acc: 0.9959 - f1_m: 0.7827 - precision_m: 0.7805 - recall_m: 0.7860\n",
            "Epoch 55/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0400 - acc: 0.9897 - f1_m: 0.7529 - precision_m: 0.7695 - recall_m: 0.7435\n",
            "Epoch 56/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0552 - acc: 0.9856 - f1_m: 0.6817 - precision_m: 0.6914 - recall_m: 0.6757\n",
            "Epoch 57/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0447 - acc: 0.9897 - f1_m: 0.7759 - precision_m: 0.7901 - recall_m: 0.7682\n",
            "Epoch 58/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0710 - acc: 0.9712 - f1_m: 0.7657 - precision_m: 0.7888 - recall_m: 0.7613\n",
            "Epoch 59/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0301 - acc: 0.9938 - f1_m: 0.7846 - precision_m: 0.7901 - recall_m: 0.7819\n",
            "Epoch 60/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0329 - acc: 0.9959 - f1_m: 0.8189 - precision_m: 0.8189 - recall_m: 0.8189\n",
            "Epoch 61/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0193 - acc: 0.9979 - f1_m: 0.7004 - precision_m: 0.7037 - recall_m: 0.6982\n",
            "Epoch 62/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0251 - acc: 0.9918 - f1_m: 0.7827 - precision_m: 0.7942 - recall_m: 0.7805\n",
            "Epoch 63/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0296 - acc: 0.9856 - f1_m: 0.7308 - precision_m: 0.7490 - recall_m: 0.7215\n",
            "Epoch 64/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0386 - acc: 0.9856 - f1_m: 0.7630 - precision_m: 0.7695 - recall_m: 0.7668\n",
            "Epoch 65/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0291 - acc: 0.9877 - f1_m: 0.7365 - precision_m: 0.7449 - recall_m: 0.7353\n",
            "Epoch 66/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0695 - acc: 0.9774 - f1_m: 0.7038 - precision_m: 0.7311 - recall_m: 0.6941\n",
            "Epoch 67/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0618 - acc: 0.9815 - f1_m: 0.7073 - precision_m: 0.7366 - recall_m: 0.6920\n",
            "Epoch 68/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0341 - acc: 0.9918 - f1_m: 0.7554 - precision_m: 0.7737 - recall_m: 0.7457\n",
            "Epoch 69/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0242 - acc: 0.9938 - f1_m: 0.7353 - precision_m: 0.7407 - recall_m: 0.7325\n",
            "Epoch 70/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0325 - acc: 0.9938 - f1_m: 0.7255 - precision_m: 0.7366 - recall_m: 0.7188\n",
            "Epoch 71/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0172 - acc: 0.9959 - f1_m: 0.7155 - precision_m: 0.7243 - recall_m: 0.7106\n",
            "Epoch 72/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0277 - acc: 0.9897 - f1_m: 0.7794 - precision_m: 0.7915 - recall_m: 0.7778\n",
            "Epoch 73/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0245 - acc: 0.9918 - f1_m: 0.7137 - precision_m: 0.7136 - recall_m: 0.7160\n",
            "Epoch 74/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0057 - acc: 1.0000 - f1_m: 0.8189 - precision_m: 0.8189 - recall_m: 0.8189\n",
            "Epoch 75/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0642 - acc: 0.9794 - f1_m: 0.6664 - precision_m: 0.6735 - recall_m: 0.6680\n",
            "Epoch 76/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0683 - acc: 0.9815 - f1_m: 0.7343 - precision_m: 0.7613 - recall_m: 0.7243\n",
            "Epoch 77/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0380 - acc: 0.9856 - f1_m: 0.6583 - precision_m: 0.6694 - recall_m: 0.6543\n",
            "Epoch 78/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0421 - acc: 0.9877 - f1_m: 0.6926 - precision_m: 0.6941 - recall_m: 0.6955\n",
            "Epoch 79/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0145 - acc: 0.9959 - f1_m: 0.6840 - precision_m: 0.6872 - recall_m: 0.6818\n",
            "Epoch 80/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0199 - acc: 0.9959 - f1_m: 0.7929 - precision_m: 0.8025 - recall_m: 0.7881\n",
            "Chunks:7 Tiempo de procesamiento (secs):257.11185359954834\n",
            "Test: \t Accuracy=0.8653366585027548, \n",
            "\t F1 score=0.0764123935651898, \n",
            "\t Precision=0.1596009975062344, \n",
            "\t Recall=0.0503740643622572\n",
            "#####################################################################\n",
            "\n",
            "\n",
            "\n",
            "Chunks:8\n",
            "Max document length: 30000\n",
            "Vocabulary size: 95901\n",
            "Epoch 1/80\n",
            "486/486 [==============================] - 5s 11ms/step - loss: 0.5450 - acc: 0.7922 - f1_m: 0.0404 - precision_m: 0.0403 - recall_m: 0.0672\n",
            "Epoch 2/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4476 - acc: 0.8313 - f1_m: 0.0110 - precision_m: 0.0165 - recall_m: 0.0082\n",
            "Epoch 3/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4516 - acc: 0.8292 - f1_m: 0.0082 - precision_m: 0.0165 - recall_m: 0.0055\n",
            "Epoch 4/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4113 - acc: 0.8272 - f1_m: 0.0192 - precision_m: 0.0329 - recall_m: 0.0137\n",
            "Epoch 5/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3820 - acc: 0.8374 - f1_m: 0.0494 - precision_m: 0.0658 - recall_m: 0.0439\n",
            "Epoch 6/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3431 - acc: 0.8621 - f1_m: 0.1660 - precision_m: 0.2428 - recall_m: 0.1331\n",
            "Epoch 7/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3178 - acc: 0.8765 - f1_m: 0.2597 - precision_m: 0.3189 - recall_m: 0.2377\n",
            "Epoch 8/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2739 - acc: 0.8909 - f1_m: 0.3978 - precision_m: 0.4636 - recall_m: 0.3717\n",
            "Epoch 9/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2412 - acc: 0.9177 - f1_m: 0.4758 - precision_m: 0.5254 - recall_m: 0.4590\n",
            "Epoch 10/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1988 - acc: 0.9383 - f1_m: 0.4840 - precision_m: 0.5391 - recall_m: 0.4678\n",
            "Epoch 11/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1937 - acc: 0.9321 - f1_m: 0.5056 - precision_m: 0.5926 - recall_m: 0.4664\n",
            "Epoch 12/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1869 - acc: 0.9280 - f1_m: 0.5179 - precision_m: 0.5844 - recall_m: 0.4914\n",
            "Epoch 13/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1692 - acc: 0.9547 - f1_m: 0.6779 - precision_m: 0.7421 - recall_m: 0.6516\n",
            "Epoch 14/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1448 - acc: 0.9486 - f1_m: 0.6079 - precision_m: 0.6900 - recall_m: 0.5701\n",
            "Epoch 15/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1222 - acc: 0.9547 - f1_m: 0.6295 - precision_m: 0.6612 - recall_m: 0.6269\n",
            "Epoch 16/80\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.1243 - acc: 0.9650 - f1_m: 0.5779 - precision_m: 0.6337 - recall_m: 0.5528\n",
            "Epoch 17/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0999 - acc: 0.9671 - f1_m: 0.6883 - precision_m: 0.7284 - recall_m: 0.6818\n",
            "Epoch 18/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0748 - acc: 0.9815 - f1_m: 0.6289 - precision_m: 0.6461 - recall_m: 0.6228\n",
            "Epoch 19/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1003 - acc: 0.9691 - f1_m: 0.6625 - precision_m: 0.6859 - recall_m: 0.6502\n",
            "Epoch 20/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0953 - acc: 0.9671 - f1_m: 0.6499 - precision_m: 0.6790 - recall_m: 0.6379\n",
            "Epoch 21/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0862 - acc: 0.9733 - f1_m: 0.7044 - precision_m: 0.7311 - recall_m: 0.6934\n",
            "Epoch 22/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0702 - acc: 0.9733 - f1_m: 0.7150 - precision_m: 0.7394 - recall_m: 0.7081\n",
            "Epoch 23/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1003 - acc: 0.9774 - f1_m: 0.6560 - precision_m: 0.6790 - recall_m: 0.6433\n",
            "Epoch 24/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0547 - acc: 0.9877 - f1_m: 0.7222 - precision_m: 0.7325 - recall_m: 0.7174\n",
            "Epoch 25/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0852 - acc: 0.9712 - f1_m: 0.7067 - precision_m: 0.7243 - recall_m: 0.7023\n",
            "Epoch 26/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0646 - acc: 0.9815 - f1_m: 0.6971 - precision_m: 0.7119 - recall_m: 0.6927\n",
            "Epoch 27/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0399 - acc: 0.9897 - f1_m: 0.7064 - precision_m: 0.7119 - recall_m: 0.7037\n",
            "Epoch 28/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0379 - acc: 0.9918 - f1_m: 0.6936 - precision_m: 0.7078 - recall_m: 0.6859\n",
            "Epoch 29/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0548 - acc: 0.9794 - f1_m: 0.7032 - precision_m: 0.7229 - recall_m: 0.7010\n",
            "Epoch 30/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0662 - acc: 0.9774 - f1_m: 0.7195 - precision_m: 0.7476 - recall_m: 0.7078\n",
            "Epoch 31/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0586 - acc: 0.9897 - f1_m: 0.7387 - precision_m: 0.7531 - recall_m: 0.7292\n",
            "Epoch 32/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0713 - acc: 0.9753 - f1_m: 0.6305 - precision_m: 0.6584 - recall_m: 0.6173\n",
            "Epoch 33/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0757 - acc: 0.9774 - f1_m: 0.7503 - precision_m: 0.7695 - recall_m: 0.7503\n",
            "Epoch 34/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0375 - acc: 0.9835 - f1_m: 0.6892 - precision_m: 0.7037 - recall_m: 0.6804\n",
            "Epoch 35/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0526 - acc: 0.9856 - f1_m: 0.7630 - precision_m: 0.7860 - recall_m: 0.7503\n",
            "Epoch 36/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0497 - acc: 0.9856 - f1_m: 0.7027 - precision_m: 0.7160 - recall_m: 0.7010\n",
            "Epoch 37/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0427 - acc: 0.9877 - f1_m: 0.7439 - precision_m: 0.7407 - recall_m: 0.7531\n",
            "Epoch 38/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0922 - acc: 0.9671 - f1_m: 0.5989 - precision_m: 0.6296 - recall_m: 0.5898\n",
            "Epoch 39/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0419 - acc: 0.9835 - f1_m: 0.6724 - precision_m: 0.6872 - recall_m: 0.6680\n",
            "Epoch 40/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0458 - acc: 0.9877 - f1_m: 0.7695 - precision_m: 0.7860 - recall_m: 0.7613\n",
            "Epoch 41/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0295 - acc: 0.9897 - f1_m: 0.7410 - precision_m: 0.7476 - recall_m: 0.7394\n",
            "Epoch 42/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0572 - acc: 0.9877 - f1_m: 0.7956 - precision_m: 0.8066 - recall_m: 0.7901\n",
            "Epoch 43/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0444 - acc: 0.9856 - f1_m: 0.7512 - precision_m: 0.7778 - recall_m: 0.7414\n",
            "Epoch 44/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0517 - acc: 0.9835 - f1_m: 0.6829 - precision_m: 0.6982 - recall_m: 0.6763\n",
            "Epoch 45/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0764 - acc: 0.9815 - f1_m: 0.7388 - precision_m: 0.7613 - recall_m: 0.7311\n",
            "Epoch 46/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0717 - acc: 0.9691 - f1_m: 0.7373 - precision_m: 0.7613 - recall_m: 0.7353\n",
            "Epoch 47/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0522 - acc: 0.9897 - f1_m: 0.7726 - precision_m: 0.7901 - recall_m: 0.7627\n",
            "Epoch 48/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0440 - acc: 0.9897 - f1_m: 0.6931 - precision_m: 0.7023 - recall_m: 0.6890\n",
            "Epoch 49/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0451 - acc: 0.9877 - f1_m: 0.7483 - precision_m: 0.7572 - recall_m: 0.7503\n",
            "Epoch 50/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0181 - acc: 0.9979 - f1_m: 0.8134 - precision_m: 0.8189 - recall_m: 0.8107\n",
            "Epoch 51/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0496 - acc: 0.9856 - f1_m: 0.7342 - precision_m: 0.7490 - recall_m: 0.7298\n",
            "Epoch 52/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0382 - acc: 0.9877 - f1_m: 0.7351 - precision_m: 0.7449 - recall_m: 0.7353\n",
            "Epoch 53/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0656 - acc: 0.9794 - f1_m: 0.7474 - precision_m: 0.7613 - recall_m: 0.7435\n",
            "Epoch 54/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0554 - acc: 0.9856 - f1_m: 0.7594 - precision_m: 0.7860 - recall_m: 0.7449\n",
            "Epoch 55/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0595 - acc: 0.9815 - f1_m: 0.7365 - precision_m: 0.7695 - recall_m: 0.7188\n",
            "Epoch 56/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0521 - acc: 0.9897 - f1_m: 0.6879 - precision_m: 0.7078 - recall_m: 0.6763\n",
            "Epoch 57/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1113 - acc: 0.9650 - f1_m: 0.7254 - precision_m: 0.7627 - recall_m: 0.7215\n",
            "Epoch 58/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0690 - acc: 0.9815 - f1_m: 0.8019 - precision_m: 0.8299 - recall_m: 0.7915\n",
            "Epoch 59/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0402 - acc: 0.9897 - f1_m: 0.7781 - precision_m: 0.7901 - recall_m: 0.7709\n",
            "Epoch 60/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0421 - acc: 0.9938 - f1_m: 0.8288 - precision_m: 0.8354 - recall_m: 0.8244\n",
            "Epoch 61/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0205 - acc: 0.9938 - f1_m: 0.6785 - precision_m: 0.6872 - recall_m: 0.6735\n",
            "Epoch 62/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0478 - acc: 0.9856 - f1_m: 0.7639 - precision_m: 0.7695 - recall_m: 0.7682\n",
            "Epoch 63/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0414 - acc: 0.9897 - f1_m: 0.7343 - precision_m: 0.7531 - recall_m: 0.7243\n",
            "Epoch 64/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0341 - acc: 0.9959 - f1_m: 0.7937 - precision_m: 0.8025 - recall_m: 0.7888\n",
            "Epoch 65/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1110 - acc: 0.9630 - f1_m: 0.6245 - precision_m: 0.6214 - recall_m: 0.6392\n",
            "Epoch 66/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0776 - acc: 0.9733 - f1_m: 0.6807 - precision_m: 0.6914 - recall_m: 0.6820\n",
            "Epoch 67/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0258 - acc: 0.9938 - f1_m: 0.7443 - precision_m: 0.7531 - recall_m: 0.7394\n",
            "Epoch 68/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0237 - acc: 0.9897 - f1_m: 0.7444 - precision_m: 0.7572 - recall_m: 0.7374\n",
            "Epoch 69/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0422 - acc: 0.9877 - f1_m: 0.7301 - precision_m: 0.7325 - recall_m: 0.7320\n",
            "Epoch 70/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0157 - acc: 0.9959 - f1_m: 0.7333 - precision_m: 0.7311 - recall_m: 0.7366\n",
            "Epoch 71/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0340 - acc: 0.9918 - f1_m: 0.6979 - precision_m: 0.7023 - recall_m: 0.6968\n",
            "Epoch 72/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0222 - acc: 0.9918 - f1_m: 0.7608 - precision_m: 0.7613 - recall_m: 0.7641\n",
            "Epoch 73/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0229 - acc: 0.9897 - f1_m: 0.7014 - precision_m: 0.7078 - recall_m: 0.7037\n",
            "Epoch 74/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0158 - acc: 0.9918 - f1_m: 0.7782 - precision_m: 0.7819 - recall_m: 0.7778\n",
            "Epoch 75/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0157 - acc: 0.9979 - f1_m: 0.7169 - precision_m: 0.7202 - recall_m: 0.7147\n",
            "Epoch 76/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0301 - acc: 0.9959 - f1_m: 0.7750 - precision_m: 0.7860 - recall_m: 0.7695\n",
            "Epoch 77/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0355 - acc: 0.9856 - f1_m: 0.6583 - precision_m: 0.6667 - recall_m: 0.6571\n",
            "Epoch 78/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0258 - acc: 0.9918 - f1_m: 0.7202 - precision_m: 0.7366 - recall_m: 0.7119\n",
            "Epoch 79/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0147 - acc: 0.9959 - f1_m: 0.6749 - precision_m: 0.6749 - recall_m: 0.6749\n",
            "Epoch 80/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0236 - acc: 0.9897 - f1_m: 0.7786 - precision_m: 0.7970 - recall_m: 0.7716\n",
            "Chunks:8 Tiempo de procesamiento (secs):258.2414085865021\n",
            "Test: \t Accuracy=0.8802992518703242, \n",
            "\t F1 score=0.05456444152870083, \n",
            "\t Precision=0.1596009975062344, \n",
            "\t Recall=0.03391521292137089\n",
            "#####################################################################\n",
            "\n",
            "\n",
            "\n",
            "Chunks:9\n",
            "Max document length: 30000\n",
            "Vocabulary size: 95909\n",
            "Epoch 1/80\n",
            "486/486 [==============================] - 6s 11ms/step - loss: 0.5419 - acc: 0.7984 - f1_m: 0.0432 - precision_m: 0.0431 - recall_m: 0.0672\n",
            "Epoch 2/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4474 - acc: 0.8313 - f1_m: 0.0110 - precision_m: 0.0165 - recall_m: 0.0082\n",
            "Epoch 3/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4574 - acc: 0.8292 - f1_m: 0.0082 - precision_m: 0.0165 - recall_m: 0.0055\n",
            "Epoch 4/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4236 - acc: 0.8333 - f1_m: 0.0368 - precision_m: 0.0658 - recall_m: 0.0261\n",
            "Epoch 5/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3819 - acc: 0.8374 - f1_m: 0.0412 - precision_m: 0.0658 - recall_m: 0.0329\n",
            "Epoch 6/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3724 - acc: 0.8457 - f1_m: 0.1084 - precision_m: 0.1605 - recall_m: 0.0864\n",
            "Epoch 7/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3346 - acc: 0.8724 - f1_m: 0.2514 - precision_m: 0.3134 - recall_m: 0.2317\n",
            "Epoch 8/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2870 - acc: 0.8889 - f1_m: 0.3621 - precision_m: 0.4280 - recall_m: 0.3388\n",
            "Epoch 9/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2550 - acc: 0.9012 - f1_m: 0.4237 - precision_m: 0.4815 - recall_m: 0.3986\n",
            "Epoch 10/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2349 - acc: 0.9156 - f1_m: 0.4088 - precision_m: 0.4746 - recall_m: 0.3937\n",
            "Epoch 11/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1970 - acc: 0.9239 - f1_m: 0.4860 - precision_m: 0.5734 - recall_m: 0.4513\n",
            "Epoch 12/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1981 - acc: 0.9218 - f1_m: 0.5135 - precision_m: 0.5514 - recall_m: 0.5160\n",
            "Epoch 13/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1785 - acc: 0.9506 - f1_m: 0.6335 - precision_m: 0.6872 - recall_m: 0.6104\n",
            "Epoch 14/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1337 - acc: 0.9568 - f1_m: 0.6176 - precision_m: 0.6914 - recall_m: 0.5866\n",
            "Epoch 15/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1250 - acc: 0.9568 - f1_m: 0.6039 - precision_m: 0.6433 - recall_m: 0.5953\n",
            "Epoch 16/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1336 - acc: 0.9630 - f1_m: 0.5682 - precision_m: 0.6132 - recall_m: 0.5446\n",
            "Epoch 17/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1033 - acc: 0.9650 - f1_m: 0.6823 - precision_m: 0.7202 - recall_m: 0.6708\n",
            "Epoch 18/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0821 - acc: 0.9794 - f1_m: 0.6430 - precision_m: 0.6708 - recall_m: 0.6269\n",
            "Epoch 19/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0858 - acc: 0.9774 - f1_m: 0.7152 - precision_m: 0.7490 - recall_m: 0.6996\n",
            "Epoch 20/80\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.0942 - acc: 0.9753 - f1_m: 0.6642 - precision_m: 0.6872 - recall_m: 0.6516\n",
            "Epoch 21/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0902 - acc: 0.9774 - f1_m: 0.7122 - precision_m: 0.7284 - recall_m: 0.7030\n",
            "Epoch 22/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0682 - acc: 0.9794 - f1_m: 0.7169 - precision_m: 0.7325 - recall_m: 0.7122\n",
            "Epoch 23/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1006 - acc: 0.9733 - f1_m: 0.6437 - precision_m: 0.6708 - recall_m: 0.6310\n",
            "Epoch 24/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0473 - acc: 0.9877 - f1_m: 0.7112 - precision_m: 0.7147 - recall_m: 0.7106\n",
            "Epoch 25/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0985 - acc: 0.9712 - f1_m: 0.7067 - precision_m: 0.7202 - recall_m: 0.7064\n",
            "Epoch 26/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0851 - acc: 0.9733 - f1_m: 0.6646 - precision_m: 0.6922 - recall_m: 0.6543\n",
            "Epoch 27/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0557 - acc: 0.9794 - f1_m: 0.6697 - precision_m: 0.6818 - recall_m: 0.6653\n",
            "Epoch 28/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0334 - acc: 0.9897 - f1_m: 0.6936 - precision_m: 0.7078 - recall_m: 0.6859\n",
            "Epoch 29/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0649 - acc: 0.9815 - f1_m: 0.6854 - precision_m: 0.7037 - recall_m: 0.6757\n",
            "Epoch 30/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0594 - acc: 0.9815 - f1_m: 0.7213 - precision_m: 0.7449 - recall_m: 0.7119\n",
            "Epoch 31/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0809 - acc: 0.9712 - f1_m: 0.6888 - precision_m: 0.7222 - recall_m: 0.6790\n",
            "Epoch 32/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0693 - acc: 0.9815 - f1_m: 0.6791 - precision_m: 0.7078 - recall_m: 0.6626\n",
            "Epoch 33/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1036 - acc: 0.9630 - f1_m: 0.6914 - precision_m: 0.7243 - recall_m: 0.6831\n",
            "Epoch 34/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0653 - acc: 0.9733 - f1_m: 0.6708 - precision_m: 0.6763 - recall_m: 0.6790\n",
            "Epoch 35/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0526 - acc: 0.9856 - f1_m: 0.7562 - precision_m: 0.7778 - recall_m: 0.7490\n",
            "Epoch 36/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0551 - acc: 0.9774 - f1_m: 0.6990 - precision_m: 0.7298 - recall_m: 0.6914\n",
            "Epoch 37/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0611 - acc: 0.9733 - f1_m: 0.7145 - precision_m: 0.7333 - recall_m: 0.7147\n",
            "Epoch 38/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0741 - acc: 0.9794 - f1_m: 0.6333 - precision_m: 0.6571 - recall_m: 0.6255\n",
            "Epoch 39/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0409 - acc: 0.9897 - f1_m: 0.6993 - precision_m: 0.7147 - recall_m: 0.6927\n",
            "Epoch 40/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0248 - acc: 0.9897 - f1_m: 0.7608 - precision_m: 0.7613 - recall_m: 0.7641\n",
            "Epoch 41/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0439 - acc: 0.9835 - f1_m: 0.7273 - precision_m: 0.7366 - recall_m: 0.7311\n",
            "Epoch 42/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0456 - acc: 0.9897 - f1_m: 0.8252 - precision_m: 0.8313 - recall_m: 0.8258\n",
            "Epoch 43/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0357 - acc: 0.9897 - f1_m: 0.7380 - precision_m: 0.7531 - recall_m: 0.7305\n",
            "Epoch 44/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0549 - acc: 0.9815 - f1_m: 0.6916 - precision_m: 0.7147 - recall_m: 0.6790\n",
            "Epoch 45/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0356 - acc: 0.9918 - f1_m: 0.7860 - precision_m: 0.8025 - recall_m: 0.7778\n",
            "Epoch 46/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0886 - acc: 0.9774 - f1_m: 0.7556 - precision_m: 0.7791 - recall_m: 0.7462\n",
            "Epoch 47/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0956 - acc: 0.9774 - f1_m: 0.7199 - precision_m: 0.7490 - recall_m: 0.7078\n",
            "Epoch 48/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0768 - acc: 0.9794 - f1_m: 0.6547 - precision_m: 0.6667 - recall_m: 0.6506\n",
            "Epoch 49/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0631 - acc: 0.9794 - f1_m: 0.7230 - precision_m: 0.7462 - recall_m: 0.7174\n",
            "Epoch 50/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0522 - acc: 0.9856 - f1_m: 0.7762 - precision_m: 0.7984 - recall_m: 0.7661\n",
            "Epoch 51/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0527 - acc: 0.9794 - f1_m: 0.7099 - precision_m: 0.7311 - recall_m: 0.7023\n",
            "Epoch 52/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0325 - acc: 0.9897 - f1_m: 0.7406 - precision_m: 0.7531 - recall_m: 0.7353\n",
            "Epoch 53/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0497 - acc: 0.9856 - f1_m: 0.7727 - precision_m: 0.7860 - recall_m: 0.7654\n",
            "Epoch 54/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0461 - acc: 0.9856 - f1_m: 0.7562 - precision_m: 0.7778 - recall_m: 0.7490\n",
            "Epoch 55/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0232 - acc: 0.9938 - f1_m: 0.7639 - precision_m: 0.7695 - recall_m: 0.7599\n",
            "Epoch 56/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0468 - acc: 0.9835 - f1_m: 0.6661 - precision_m: 0.6831 - recall_m: 0.6612\n",
            "Epoch 57/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0451 - acc: 0.9856 - f1_m: 0.7927 - precision_m: 0.8066 - recall_m: 0.7923\n",
            "Epoch 58/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0570 - acc: 0.9774 - f1_m: 0.7668 - precision_m: 0.7942 - recall_m: 0.7586\n",
            "Epoch 59/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0381 - acc: 0.9877 - f1_m: 0.7713 - precision_m: 0.7778 - recall_m: 0.7737\n",
            "Epoch 60/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0566 - acc: 0.9815 - f1_m: 0.7913 - precision_m: 0.8107 - recall_m: 0.7846\n",
            "Epoch 61/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0209 - acc: 0.9918 - f1_m: 0.6620 - precision_m: 0.6626 - recall_m: 0.6653\n",
            "Epoch 62/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0353 - acc: 0.9918 - f1_m: 0.7695 - precision_m: 0.7860 - recall_m: 0.7613\n",
            "Epoch 63/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0300 - acc: 0.9918 - f1_m: 0.7551 - precision_m: 0.7641 - recall_m: 0.7517\n",
            "Epoch 64/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0143 - acc: 0.9979 - f1_m: 0.7860 - precision_m: 0.7860 - recall_m: 0.7860\n",
            "Epoch 65/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0295 - acc: 0.9877 - f1_m: 0.7474 - precision_m: 0.7654 - recall_m: 0.7394\n",
            "Epoch 66/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0418 - acc: 0.9835 - f1_m: 0.7056 - precision_m: 0.7188 - recall_m: 0.6996\n",
            "Epoch 67/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0534 - acc: 0.9877 - f1_m: 0.7196 - precision_m: 0.7174 - recall_m: 0.7311\n",
            "Epoch 68/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0312 - acc: 0.9877 - f1_m: 0.7225 - precision_m: 0.7407 - recall_m: 0.7128\n",
            "Epoch 69/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0778 - acc: 0.9794 - f1_m: 0.6990 - precision_m: 0.7078 - recall_m: 0.7023\n",
            "Epoch 70/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0252 - acc: 0.9938 - f1_m: 0.7255 - precision_m: 0.7366 - recall_m: 0.7188\n",
            "Epoch 71/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0141 - acc: 0.9918 - f1_m: 0.7121 - precision_m: 0.7147 - recall_m: 0.7133\n",
            "Epoch 72/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0342 - acc: 0.9835 - f1_m: 0.7624 - precision_m: 0.7723 - recall_m: 0.7641\n",
            "Epoch 73/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0506 - acc: 0.9897 - f1_m: 0.7014 - precision_m: 0.7119 - recall_m: 0.6996\n",
            "Epoch 74/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0284 - acc: 0.9918 - f1_m: 0.7804 - precision_m: 0.7860 - recall_m: 0.7764\n",
            "Epoch 75/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0294 - acc: 0.9918 - f1_m: 0.7026 - precision_m: 0.7147 - recall_m: 0.6982\n",
            "Epoch 76/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0442 - acc: 0.9918 - f1_m: 0.7641 - precision_m: 0.7860 - recall_m: 0.7531\n",
            "Epoch 77/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0505 - acc: 0.9856 - f1_m: 0.6464 - precision_m: 0.6529 - recall_m: 0.6447\n",
            "Epoch 78/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0390 - acc: 0.9897 - f1_m: 0.7073 - precision_m: 0.7147 - recall_m: 0.7058\n",
            "Epoch 79/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0359 - acc: 0.9897 - f1_m: 0.6907 - precision_m: 0.6996 - recall_m: 0.6867\n",
            "Epoch 80/80\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.0205 - acc: 0.9918 - f1_m: 0.7709 - precision_m: 0.7860 - recall_m: 0.7634\n",
            "Chunks:9 Tiempo de procesamiento (secs):266.4510455131531\n",
            "Test: \t Accuracy=0.8902743142144638, \n",
            "\t F1 score=0.0836005175202862, \n",
            "\t Precision=0.1596009975062344, \n",
            "\t Recall=0.05685785583724405\n",
            "#####################################################################\n",
            "\n",
            "\n",
            "\n",
            "Chunks:10\n",
            "Max document length: 30000\n",
            "Vocabulary size: 96334\n",
            "Epoch 1/80\n",
            "486/486 [==============================] - 6s 12ms/step - loss: 0.5433 - acc: 0.8045 - f1_m: 0.0541 - precision_m: 0.0595 - recall_m: 0.0754\n",
            "Epoch 2/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4485 - acc: 0.8292 - f1_m: 0.0110 - precision_m: 0.0165 - recall_m: 0.0082\n",
            "Epoch 3/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4489 - acc: 0.8292 - f1_m: 0.0082 - precision_m: 0.0165 - recall_m: 0.0055\n",
            "Epoch 4/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4119 - acc: 0.8395 - f1_m: 0.0889 - precision_m: 0.1317 - recall_m: 0.0727\n",
            "Epoch 5/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3720 - acc: 0.8457 - f1_m: 0.1097 - precision_m: 0.1481 - recall_m: 0.0960\n",
            "Epoch 6/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3355 - acc: 0.8663 - f1_m: 0.1874 - precision_m: 0.2510 - recall_m: 0.1578\n",
            "Epoch 7/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3212 - acc: 0.8724 - f1_m: 0.2691 - precision_m: 0.3326 - recall_m: 0.2501\n",
            "Epoch 8/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2823 - acc: 0.8889 - f1_m: 0.4033 - precision_m: 0.4554 - recall_m: 0.3909\n",
            "Epoch 9/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2588 - acc: 0.9012 - f1_m: 0.4009 - precision_m: 0.4588 - recall_m: 0.3786\n",
            "Epoch 10/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2090 - acc: 0.9362 - f1_m: 0.4734 - precision_m: 0.5350 - recall_m: 0.4595\n",
            "Epoch 11/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1914 - acc: 0.9465 - f1_m: 0.5396 - precision_m: 0.6255 - recall_m: 0.4993\n",
            "Epoch 12/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1999 - acc: 0.9300 - f1_m: 0.4903 - precision_m: 0.5514 - recall_m: 0.4639\n",
            "Epoch 13/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1820 - acc: 0.9424 - f1_m: 0.5863 - precision_m: 0.6351 - recall_m: 0.5748\n",
            "Epoch 14/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1572 - acc: 0.9444 - f1_m: 0.5540 - precision_m: 0.6241 - recall_m: 0.5229\n",
            "Epoch 15/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1348 - acc: 0.9527 - f1_m: 0.6068 - precision_m: 0.6612 - recall_m: 0.5871\n",
            "Epoch 16/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1471 - acc: 0.9527 - f1_m: 0.5438 - precision_m: 0.5926 - recall_m: 0.5192\n",
            "Epoch 17/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1011 - acc: 0.9650 - f1_m: 0.6745 - precision_m: 0.7284 - recall_m: 0.6502\n",
            "Epoch 18/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0918 - acc: 0.9712 - f1_m: 0.5955 - precision_m: 0.6296 - recall_m: 0.5816\n",
            "Epoch 19/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1213 - acc: 0.9609 - f1_m: 0.6256 - precision_m: 0.6749 - recall_m: 0.5995\n",
            "Epoch 20/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1094 - acc: 0.9650 - f1_m: 0.6203 - precision_m: 0.6461 - recall_m: 0.6104\n",
            "Epoch 21/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1106 - acc: 0.9630 - f1_m: 0.6555 - precision_m: 0.6955 - recall_m: 0.6358\n",
            "Epoch 22/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0724 - acc: 0.9774 - f1_m: 0.7104 - precision_m: 0.7325 - recall_m: 0.7018\n",
            "Epoch 23/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1186 - acc: 0.9691 - f1_m: 0.6304 - precision_m: 0.6667 - recall_m: 0.6145\n",
            "Epoch 24/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0748 - acc: 0.9774 - f1_m: 0.6992 - precision_m: 0.7311 - recall_m: 0.6831\n",
            "Epoch 25/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0858 - acc: 0.9794 - f1_m: 0.7186 - precision_m: 0.7325 - recall_m: 0.7119\n",
            "Epoch 26/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0712 - acc: 0.9753 - f1_m: 0.6607 - precision_m: 0.6818 - recall_m: 0.6502\n",
            "Epoch 27/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0401 - acc: 0.9918 - f1_m: 0.7224 - precision_m: 0.7366 - recall_m: 0.7147\n",
            "Epoch 28/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0417 - acc: 0.9897 - f1_m: 0.6881 - precision_m: 0.7078 - recall_m: 0.6776\n",
            "Epoch 29/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0454 - acc: 0.9815 - f1_m: 0.7246 - precision_m: 0.7476 - recall_m: 0.7147\n",
            "Epoch 30/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0591 - acc: 0.9753 - f1_m: 0.6916 - precision_m: 0.7202 - recall_m: 0.6763\n",
            "Epoch 31/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1067 - acc: 0.9630 - f1_m: 0.6465 - precision_m: 0.6900 - recall_m: 0.6277\n",
            "Epoch 32/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0820 - acc: 0.9753 - f1_m: 0.6522 - precision_m: 0.6914 - recall_m: 0.6324\n",
            "Epoch 33/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0787 - acc: 0.9733 - f1_m: 0.7418 - precision_m: 0.7641 - recall_m: 0.7414\n",
            "Epoch 34/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0513 - acc: 0.9856 - f1_m: 0.6894 - precision_m: 0.7037 - recall_m: 0.6818\n",
            "Epoch 35/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0544 - acc: 0.9835 - f1_m: 0.7449 - precision_m: 0.7613 - recall_m: 0.7421\n",
            "Epoch 36/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0695 - acc: 0.9671 - f1_m: 0.6669 - precision_m: 0.7078 - recall_m: 0.6529\n",
            "Epoch 37/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0792 - acc: 0.9774 - f1_m: 0.7150 - precision_m: 0.7325 - recall_m: 0.7051\n",
            "Epoch 38/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0806 - acc: 0.9774 - f1_m: 0.6212 - precision_m: 0.6379 - recall_m: 0.6118\n",
            "Epoch 39/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0585 - acc: 0.9815 - f1_m: 0.6827 - precision_m: 0.7119 - recall_m: 0.6694\n",
            "Epoch 40/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0618 - acc: 0.9733 - f1_m: 0.7186 - precision_m: 0.7387 - recall_m: 0.7106\n",
            "Epoch 41/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0577 - acc: 0.9815 - f1_m: 0.6971 - precision_m: 0.7119 - recall_m: 0.6927\n",
            "Epoch 42/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0518 - acc: 0.9835 - f1_m: 0.7890 - precision_m: 0.8011 - recall_m: 0.7846\n",
            "Epoch 43/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0557 - acc: 0.9774 - f1_m: 0.7049 - precision_m: 0.7243 - recall_m: 0.7003\n",
            "Epoch 44/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0588 - acc: 0.9753 - f1_m: 0.6532 - precision_m: 0.6626 - recall_m: 0.6598\n",
            "Epoch 45/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0739 - acc: 0.9671 - f1_m: 0.6846 - precision_m: 0.6982 - recall_m: 0.6886\n",
            "Epoch 46/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0460 - acc: 0.9877 - f1_m: 0.7790 - precision_m: 0.7860 - recall_m: 0.7764\n",
            "Epoch 47/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0475 - acc: 0.9856 - f1_m: 0.7638 - precision_m: 0.7901 - recall_m: 0.7490\n",
            "Epoch 48/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0530 - acc: 0.9835 - f1_m: 0.6634 - precision_m: 0.6749 - recall_m: 0.6561\n",
            "Epoch 49/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0632 - acc: 0.9733 - f1_m: 0.7033 - precision_m: 0.7215 - recall_m: 0.7010\n",
            "Epoch 50/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0465 - acc: 0.9918 - f1_m: 0.7915 - precision_m: 0.8025 - recall_m: 0.7860\n",
            "Epoch 51/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0223 - acc: 0.9959 - f1_m: 0.7813 - precision_m: 0.7901 - recall_m: 0.7764\n",
            "Epoch 52/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0418 - acc: 0.9815 - f1_m: 0.7268 - precision_m: 0.7435 - recall_m: 0.7237\n",
            "Epoch 53/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0582 - acc: 0.9794 - f1_m: 0.7606 - precision_m: 0.7723 - recall_m: 0.7599\n",
            "Epoch 54/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0492 - acc: 0.9794 - f1_m: 0.7174 - precision_m: 0.7449 - recall_m: 0.7092\n",
            "Epoch 55/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0395 - acc: 0.9877 - f1_m: 0.7333 - precision_m: 0.7531 - recall_m: 0.7229\n",
            "Epoch 56/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0192 - acc: 0.9959 - f1_m: 0.6881 - precision_m: 0.6914 - recall_m: 0.6859\n",
            "Epoch 57/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0490 - acc: 0.9877 - f1_m: 0.8037 - precision_m: 0.8093 - recall_m: 0.8060\n",
            "Epoch 58/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0279 - acc: 0.9918 - f1_m: 0.8354 - precision_m: 0.8519 - recall_m: 0.8272\n",
            "Epoch 59/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0214 - acc: 0.9959 - f1_m: 0.8011 - precision_m: 0.7984 - recall_m: 0.8066\n",
            "Epoch 60/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0519 - acc: 0.9877 - f1_m: 0.8188 - precision_m: 0.8354 - recall_m: 0.8093\n",
            "Epoch 61/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0281 - acc: 0.9938 - f1_m: 0.6894 - precision_m: 0.7037 - recall_m: 0.6818\n",
            "Epoch 62/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0253 - acc: 0.9918 - f1_m: 0.7859 - precision_m: 0.7970 - recall_m: 0.7819\n",
            "Epoch 63/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0207 - acc: 0.9938 - f1_m: 0.7421 - precision_m: 0.7531 - recall_m: 0.7366\n",
            "Epoch 64/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0432 - acc: 0.9877 - f1_m: 0.7630 - precision_m: 0.7695 - recall_m: 0.7668\n",
            "Epoch 65/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0518 - acc: 0.9794 - f1_m: 0.7252 - precision_m: 0.7394 - recall_m: 0.7215\n",
            "Epoch 66/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0589 - acc: 0.9877 - f1_m: 0.7424 - precision_m: 0.7572 - recall_m: 0.7353\n",
            "Epoch 67/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0318 - acc: 0.9897 - f1_m: 0.7169 - precision_m: 0.7202 - recall_m: 0.7147\n",
            "Epoch 68/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0288 - acc: 0.9918 - f1_m: 0.7586 - precision_m: 0.7737 - recall_m: 0.7506\n",
            "Epoch 69/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0362 - acc: 0.9877 - f1_m: 0.7380 - precision_m: 0.7407 - recall_m: 0.7407\n",
            "Epoch 70/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0365 - acc: 0.9918 - f1_m: 0.7081 - precision_m: 0.7202 - recall_m: 0.7010\n",
            "Epoch 71/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0341 - acc: 0.9918 - f1_m: 0.7067 - precision_m: 0.7188 - recall_m: 0.7023\n",
            "Epoch 72/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0227 - acc: 0.9918 - f1_m: 0.7849 - precision_m: 0.7970 - recall_m: 0.7805\n",
            "Epoch 73/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0218 - acc: 0.9938 - f1_m: 0.7288 - precision_m: 0.7366 - recall_m: 0.7243\n",
            "Epoch 74/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0116 - acc: 0.9959 - f1_m: 0.7970 - precision_m: 0.8025 - recall_m: 0.7942\n",
            "Epoch 75/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0353 - acc: 0.9918 - f1_m: 0.7004 - precision_m: 0.7147 - recall_m: 0.6955\n",
            "Epoch 76/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0311 - acc: 0.9938 - f1_m: 0.7476 - precision_m: 0.7531 - recall_m: 0.7449\n",
            "Epoch 77/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0365 - acc: 0.9938 - f1_m: 0.6826 - precision_m: 0.6859 - recall_m: 0.6831\n",
            "Epoch 78/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0215 - acc: 0.9938 - f1_m: 0.7257 - precision_m: 0.7202 - recall_m: 0.7366\n",
            "Epoch 79/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0155 - acc: 0.9979 - f1_m: 0.7004 - precision_m: 0.7037 - recall_m: 0.6982\n",
            "Epoch 80/80\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0261 - acc: 0.9918 - f1_m: 0.7617 - precision_m: 0.7695 - recall_m: 0.7572\n",
            "Chunks:10 Tiempo de procesamiento (secs):268.48958921432495\n",
            "Test: \t Accuracy=0.8952618453865336, \n",
            "\t F1 score=0.07937826598968886, \n",
            "\t Precision=0.1596009975062344, \n",
            "\t Recall=0.05286782994829211\n",
            "#####################################################################\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqlYxJNGLYDK",
        "colab_type": "code",
        "outputId": "b482f257-0b16-4cbe-b248-a45011f02db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "CNNGlove=pd.DataFrame(CNNGlove_metrics, columns=['Chunks','Acc','F1Score','Precission','Recall'])\n",
        "CNNGlove"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Chunks</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1Score</th>\n",
              "      <th>Precission</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.882793</td>\n",
              "      <td>0.090359</td>\n",
              "      <td>0.159601</td>\n",
              "      <td>0.063342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.890274</td>\n",
              "      <td>0.093059</td>\n",
              "      <td>0.159601</td>\n",
              "      <td>0.065835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.885287</td>\n",
              "      <td>0.076412</td>\n",
              "      <td>0.159601</td>\n",
              "      <td>0.050374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.887781</td>\n",
              "      <td>0.077520</td>\n",
              "      <td>0.159601</td>\n",
              "      <td>0.051870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.877805</td>\n",
              "      <td>0.087555</td>\n",
              "      <td>0.150734</td>\n",
              "      <td>0.061845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.880299</td>\n",
              "      <td>0.040280</td>\n",
              "      <td>0.159601</td>\n",
              "      <td>0.023441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.865337</td>\n",
              "      <td>0.076412</td>\n",
              "      <td>0.159601</td>\n",
              "      <td>0.050374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.880299</td>\n",
              "      <td>0.054564</td>\n",
              "      <td>0.159601</td>\n",
              "      <td>0.033915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.890274</td>\n",
              "      <td>0.083601</td>\n",
              "      <td>0.159601</td>\n",
              "      <td>0.056858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.895262</td>\n",
              "      <td>0.079378</td>\n",
              "      <td>0.159601</td>\n",
              "      <td>0.052868</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Chunks       Acc   F1Score  Precission    Recall\n",
              "0     1.0  0.882793  0.090359    0.159601  0.063342\n",
              "1     2.0  0.890274  0.093059    0.159601  0.065835\n",
              "2     3.0  0.885287  0.076412    0.159601  0.050374\n",
              "3     4.0  0.887781  0.077520    0.159601  0.051870\n",
              "4     5.0  0.877805  0.087555    0.150734  0.061845\n",
              "5     6.0  0.880299  0.040280    0.159601  0.023441\n",
              "6     7.0  0.865337  0.076412    0.159601  0.050374\n",
              "7     8.0  0.880299  0.054564    0.159601  0.033915\n",
              "8     9.0  0.890274  0.083601    0.159601  0.056858\n",
              "9    10.0  0.895262  0.079378    0.159601  0.052868"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejJd-UYfMNi9",
        "colab_type": "code",
        "outputId": "23086dc9-f2ff-4b4e-aa8a-22b160d03312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "# multiple line plot\n",
        "plt.plot( 'Chunks', 'Acc', data=CNNGlove, marker='v', color='cornflowerblue', linewidth=2)\n",
        "plt.plot( 'Chunks', 'F1Score', data=CNNGlove, marker='v', color='darkred', linewidth=2)\n",
        "plt.plot( 'Chunks', 'Recall', data=CNNGlove, marker='v', color='darkorange', linewidth=2)\n",
        "plt.plot( 'Chunks', 'Precission', data=CNNGlove, marker='v', color='darkblue', linewidth=2)\n",
        "plt.xlabel(\"Chunks\")\n",
        "plt.ylabel(\"Rate\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f71707e2ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEDCAYAAAA2k7/eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQiMk8IUQQiP+Pze/iLJ0+5KKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "febbb068-edfb-4157-8bd8-38d3ae698e92",
        "_uuid": "1bf8b52609c0538f619ac4d6efea04b6491a4673",
        "id": "_p3pfOE4d83j",
        "colab_type": "text"
      },
      "source": [
        "**References:**\n",
        "\n",
        "[1] P. Bojanowski, E. Grave, A. Joulin, T. Mikolov, \"Enriching Word Vectors with Subword Information\", arXiv, 2016  \n",
        "[2] FastText Embeddings: https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md  \n",
        "[3] F. Chollet, \"Deep Learning with Python\", Manning Publications, 2017  "
      ]
    }
  ]
}