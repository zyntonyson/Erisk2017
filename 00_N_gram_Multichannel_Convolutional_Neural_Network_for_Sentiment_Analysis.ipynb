{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00. N-gram Multichannel Convolutional Neural Network for Sentiment Analysis",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zyntonyson/Erisk2017/blob/master/00_N_gram_Multichannel_Convolutional_Neural_Network_for_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY1esq_XetOv",
        "colab_type": "code",
        "outputId": "d6fb09ee-6f5e-48bb-951e-d377e737db97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieQMqoCMew9E",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSNhQA8Pe1aD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cargar datos \n",
        "import pandas as pd\n",
        "DATA_PATH='/content/drive/My Drive/MCE/Participaciones/04.Diplomado Deep Learning/proyecto/data/'\n",
        "\n",
        "\n",
        "df_train = pd.read_csv(DATA_PATH + 'train.csv', sep=',', header=0)\n",
        "df_train = df_train[df_train['post'].notnull()]\n",
        "\n",
        "df_test = pd.read_csv(DATA_PATH + 'test.csv', sep=',', header=0)\n",
        "df_test = df_test[df_test['post'].notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNnICdepfN_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Separar datos de entrenamiento\n",
        "corp_train=df_train['post'].tolist()\n",
        "y_train=df_train['Depression'].tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMzCAX7D3aOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Separar datos de prueba\n",
        "corp_test=df_test['post'].tolist()\n",
        "y_test=df_test['Depression'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaF3bVAzV0wC",
        "colab_type": "code",
        "outputId": "09a74206-cd96-4e0b-ce36-6499c42d2234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#MÃ©tricas\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQia7NWekBLP",
        "colab_type": "code",
        "outputId": "ee7b78f1-b1bd-43cb-c7d8-17e77f88cf03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# calculate the maximum document length\n",
        "def max_length(lines):\n",
        "\treturn max([len(s.split()) for s in lines])\n",
        "\n",
        "# encode a list of lines\n",
        "def encode_text(tokenizer, lines, length):\n",
        "\t# integer encode\n",
        "\tencoded = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad encoded sequences\n",
        "\tpadded = pad_sequences(encoded, maxlen=length, padding='post')\n",
        "\treturn padded\n",
        "\n",
        "# define the model\n",
        "def define_model(length, vocab_size):\n",
        "  # channel 1\n",
        "  inputs1 = Input(shape=(length,))\n",
        "  embedding1 = Embedding(vocab_size, 100)(inputs1)\n",
        "  conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "  # channel 2\n",
        "  inputs2 = Input(shape=(length,))\n",
        "  embedding2 = Embedding(vocab_size, 100)(inputs2)\n",
        "  conv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embedding2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "  # channel 3\n",
        "  inputs3 = Input(shape=(length,))\n",
        "  embedding3 = Embedding(vocab_size, 100)(inputs3)\n",
        "  conv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "  # merge\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "  # interpretation\n",
        "  dense1 = Dense(10, activation='relu')(merged)\n",
        "  outputs = Dense(1, activation='sigmoid')(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  # compile\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "  # summarize\n",
        "  print(model.summary())\n",
        "  plot_model(model, show_shapes=True, to_file=DATA_PATH+'multichannel1.png',rankdir='TB')\n",
        "  plot_model(model, show_shapes=True, to_file=DATA_PATH+'multichannel2.png',rankdir='LR')\n",
        "  return model\n",
        "\n",
        "\n",
        "# create tokenizer\n",
        "tokenizer = create_tokenizer(corp_train)\n",
        "# calculate max document length\n",
        "length = max_length(corp_train)\n",
        "# calculate vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Max document length: %d' % length)\n",
        "print('Vocabulary size: %d' % vocab_size)\n",
        "\n",
        "# encode data\n",
        "trainX = encode_text(tokenizer, corp_train, length)\n",
        "print(trainX.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max document length: 54358\n",
            "Vocabulary size: 95525\n",
            "(485, 54358)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGyvfjXTzoz_",
        "colab_type": "code",
        "outputId": "55233fb0-40ba-44d1-da01-705ed8aec135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# define model\n",
        "model = define_model(length, vocab_size)\n",
        "# fit model\n",
        "hist=model.fit([trainX,trainX,trainX], array(y_train), epochs=100, batch_size=16)\n",
        "# save the model\n",
        "#model.save(DATA_PATH+'model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0704 22:30:28.172665 139668277467008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0704 22:30:28.190433 139668277467008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0704 22:30:28.193280 139668277467008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0704 22:30:28.219532 139668277467008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0704 22:30:28.227851 139668277467008 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0704 22:30:28.243085 139668277467008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0704 22:30:28.372596 139668277467008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0704 22:30:28.393292 139668277467008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0704 22:30:28.399445 139668277467008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 54358)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 54358)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 54358)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 54358, 100)   9552500     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 54358, 100)   9552500     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 54358, 100)   9552500     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 54355, 32)    12832       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 54353, 32)    19232       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 54351, 32)    25632       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 54355, 32)    0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 54353, 32)    0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 54351, 32)    0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 27177, 32)    0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 27176, 32)    0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 27175, 32)    0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 869664)       0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 869632)       0           max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 869600)       0           max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 2608896)      0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           26088970    concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            11          dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 54,804,177\n",
            "Trainable params: 54,804,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "485/485 [==============================] - 14s 30ms/step - loss: 2.6483 - acc: 0.8206 - f1_m: 0.0141 - precision_m: 0.0099 - recall_m: 0.0247\n",
            "Epoch 2/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 8/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 9/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 10/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 11/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 12/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 13/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 14/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 15/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 16/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 17/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 18/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 19/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 20/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 21/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 22/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 23/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 24/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 25/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 26/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 27/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 28/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 29/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 30/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 31/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 32/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 33/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 34/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 35/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 36/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 37/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 38/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 39/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 40/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 41/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 42/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 43/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 44/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 45/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 46/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 47/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 48/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 49/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 50/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 51/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 52/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 53/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 54/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 55/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 56/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 57/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 58/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 59/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 60/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 61/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 62/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 63/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 64/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 65/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 66/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 67/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 68/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 69/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 70/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 71/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 72/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 73/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 74/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 75/100\n",
            "485/485 [==============================] - 10s 20ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 76/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 77/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 78/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 79/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 80/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 81/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 82/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 83/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 84/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 85/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 86/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 87/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 88/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 89/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 90/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 91/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 92/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 93/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 94/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 95/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 96/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 97/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 98/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 99/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 100/100\n",
            "485/485 [==============================] - 10s 21ms/step - loss: 2.7584 - acc: 0.8289 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGiIpiY03DgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode data\n",
        "testX = encode_text(tokenizer, corp_test, length)\n",
        "\n",
        "\n",
        "# evaluate model on training dataset\n",
        "#loss, acc = model.evaluate([trainX,trainX,trainX], array(y_train), verbose=0)\n",
        "#print('Train Accuracy: %f' % (acc*100))\n",
        "\n",
        "# evaluate model on test dataset dataset\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate([testX,testX,testX], array(y_test) , verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ure8snUqcIRB",
        "colab_type": "code",
        "outputId": "7a41cc45-5b70-4097-faf7-cc74dbfc00fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Test Accuracy: %f' % (accuracy*100))\n",
        "print('Test Precision: %f' % (precision*100))\n",
        "print('Test F1 Score: %f' % (f1_score*100))\n",
        "print('Test Recall: %f' % (recall*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 87.000000\n",
            "Test Precision: 0.000000\n",
            "Test F1 Score: 0.000000\n",
            "Test Recall: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY3am4m0Ft5h",
        "colab_type": "code",
        "outputId": "11e2d44f-208c-4180-8c56-bb26075a702a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt  \n",
        "import matplotlib as mpl\n",
        "\n",
        "def select_class(x):\n",
        "  if x>0.5:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "predict_prob=model.predict([testX,testX,testX])\n",
        "predict_class=[select_class(prob) for prob in predict_prob]\n",
        "cm = confusion_matrix(y_test, predict_class)\n",
        "\n",
        "\n",
        "# Make an example plot with two subplots...\n",
        "fig2 = plt.figure()\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['no depression', 'depression']); ax.yaxis.set_ticklabels(['no depression', 'depression']);\n",
        "fig2.savefig(DATA_PATH+'mc.png')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOHCbmdUZB24zszrjwG1mVmf+PyyRovQyZpOxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_afh2B69D--",
        "colab_type": "text"
      },
      "source": [
        "## Referencias\n",
        "\n",
        "https://machinelearningmastery.com/what-are-word-embeddings/\n",
        "\n",
        "https://machinelearningmastery.com/prepare-text-data-deep-learning-keras/\n",
        "\n",
        "https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
        "\n",
        "\n",
        "How to Develop an N-gram Multichannel Convolutional Neural Network for Sentiment Analysis (Text Classification)\n",
        "\n",
        "https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA1gmvzLKsoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}