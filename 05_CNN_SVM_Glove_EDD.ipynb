{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05.CNN-SVM Glove EDD",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zyntonyson/Erisk2017/blob/master/05_CNN_SVM_Glove_EDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f169939-93d7-4217-9bda-1ddbbbd19ca6",
        "_uuid": "04b4fb7875d109f67f8af07bb5c05d46c1f913e4",
        "id": "oBbj8vmhd82Q",
        "colab_type": "text"
      },
      "source": [
        "##  CNN with Glove Embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfdYRoOEdJRh",
        "colab_type": "text"
      },
      "source": [
        "### Cargar datos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FfOHcc5gmJv",
        "colab_type": "code",
        "outputId": "8fd4ca10-3232-43a3-df28-ee954362b920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VmHkxDAdZxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "mypath='/content/drive/My Drive/MCE/Participaciones/05.Estancia Jun19/Practicas NLP/Deteccion de depresion/Actualizacion sep 2019'\n",
        "os.chdir( mypath )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxkm-8-ZdeNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_train=pd.read_csv('train_Depression_all_chunks_nosteem.csv')\n",
        "df_train=df_train.replace(np.nan, '', regex=True)\n",
        "df_test=pd.read_csv('test_Depression_all_chunks_nosteem.csv')\n",
        "df_test=df_test.replace(np.nan, '', regex=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OD1wzNRdMFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(df,nchunks=1):\n",
        "  data=df['Chunk_1']\n",
        "  data.rename(columns={'Chunk_1': 'x'})\n",
        "  if nchunks<=1:\n",
        "   pass\n",
        "  else:\n",
        "    for i in range(2,nchunks):\n",
        "      chunk='Chunk_'+str(i)\n",
        "      data+=df[chunk]\n",
        "  return data.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK1Sh0y2dh0V",
        "colab_type": "text"
      },
      "source": [
        "## Cargar Embbeding Pre-entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvNqNarqgrNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#google word2vec pretrained embedding \n",
        "\n",
        "#!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLRgkHVAhI-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fasttext embedding wikipedia\n",
        "\n",
        "#!wget -P /root/input/ -c \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.bin.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8upwDd9DrGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.geeksforgeeks.org/working-zip-files-python/\n",
        "#from zipfile import ZipFile \n",
        "\n",
        "#zipw=ZipFile('/root/input/wiki-news-300d-1M-subword.bin.zip', 'r')\n",
        "\n",
        "#zipw.extract('wiki-news-300d-1M-subword.bin',path=\"/root/input\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bKEhNGWpt9T",
        "colab_type": "code",
        "outputId": "c00899bc-7102-4618-938d-53353a208d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "# Glove\n",
        "!wget -P /root/input/ -c \"http://nlp.stanford.edu/data/glove.6B.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-15 06:05:19--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-10-15 06:05:19--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-10-15 06:05:19--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘/root/input/glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.79MB/s    in 6m 28s  \n",
            "\n",
            "2019-10-15 06:11:48 (2.12 MB/s) - ‘/root/input/glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feJzwxxd-CHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile \n",
        "\n",
        "zip=ZipFile('/root/input/glove.6B.zip', 'r')\n",
        "\n",
        "zip.extract('glove.6B.100d.txt',path=\"/root/input\")\n",
        "del zip\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTUSR-4lsfbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Glove embbeding\n",
        "# Se crea el diccionario de embbeding con glove\n",
        "\n",
        "embeddings_glove = {}\n",
        "f = open('/root/input/glove.6B.100d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_glove[word] = coefs\n",
        "f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcOX7eX6e0eV",
        "colab_type": "text"
      },
      "source": [
        "## Crear secuencias de los textos y capa de embbeding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFDEgICjpKNK",
        "colab_type": "code",
        "outputId": "7ee21b45-08cd-46e8-8125-7f9658fd7e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYlcI4YGmNtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Crear conteo de términos (Bow)\n",
        "def create_tokenizer(corpus_train):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(corpus_train)\n",
        "\treturn tokenizer\n",
        "\n",
        "# calculate the maximum document length se define la dimensión de las secuencias\n",
        "def max_length(corpus_train):\n",
        "\treturn max([len(s.split()) for s in corpus_train])\n",
        "\n",
        "# encode a list of lines  (crear la secuencia de palabras)\n",
        "def encode_text(tokenizer, lines, length):\n",
        "\t# integer encode\n",
        "\tencoded = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad encoded sequences\n",
        "\tpadded = pad_sequences(encoded, maxlen=length, padding='post')\n",
        "\treturn padded\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3b2c9452-5780-4920-8896-0b9dfa7c562b",
        "_uuid": "e8742cc989f4c71a8c401feef5e54c0e7718865a",
        "id": "_sU9G0nzd822",
        "colab_type": "text"
      },
      "source": [
        "Matriz de peso de los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGljIr7MNV_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embbedingLayer(tokenizer,dictembedding):\n",
        "  dim_emb=len(list(dictembedding.values())[0])\n",
        "\n",
        "  # Creamos un diccionario donde las llaves sean los index por palabra\n",
        "  vocabulary_inv = dict((v, k) for k, v in tokenizer.word_index.items())\n",
        "  vocabulary_inv[0] = \"<PAD/>\"\n",
        "\n",
        "  # Creamos los embedding del vocabulario\n",
        "  embedding_weights = {key: dictembedding[word] if word in dictembedding else\n",
        "                            np.random.uniform(-0.25, 0.25, 100)\n",
        "                      for key, word in vocabulary_inv.items()}\n",
        "  # Convertir capa en un np.array\n",
        "  return np.array([embedding_weights[i] for i in range(len(embedding_weights))]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5C6ZoztNMAu",
        "colab_type": "text"
      },
      "source": [
        "## Definiendo modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "29a8d31b-451e-4427-afb3-fd40cd01bc60",
        "_uuid": "887320b9e2d8efaaa27c3f7913debaf53c37ed52",
        "trusted": true,
        "id": "WjCWKTFLd82W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "# CNN for features\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras.layers import Activation\n",
        "from keras.layers import GlobalMaxPooling1D \n",
        "from keras.utils import plot_model\n",
        "from pickle import load\n",
        "from sklearn.utils import class_weight\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "# SVM\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaF3bVAzV0wC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Métricas\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rV4nd6ImLm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the model\n",
        "def define_model(length, weights,seed=1013,num_filters=32):\n",
        "  \n",
        "  #model parameters\n",
        "  vocab_size,embed_dim = weights.shape \n",
        "    \n",
        "  #seed\n",
        "  np.random.seed(seed)\n",
        "  \n",
        "  ### DEFINE LAYERS\n",
        "  \n",
        "  #### Process layers\n",
        "  inputs1 = Input(shape=(length,))\n",
        "  embedding1 = Embedding(vocab_size, embed_dim, weights=[weights], trainable=False)(inputs1)\n",
        "  conv1 = Conv1D(num_filters, 4, activation='relu', padding='same')(embedding1)\n",
        "  maxpool1 = MaxPooling1D(2)(conv1)\n",
        "  conv2 = Conv1D(num_filters, 4, activation='relu', padding='same')(maxpool1)\n",
        "  Gpool1=GlobalMaxPooling1D()(conv2)\n",
        "  drop1 = Dropout(0.5)(Gpool1)\n",
        "  \n",
        "  ### prediction layers\n",
        "  dense1 = Dense(32, activation='relu', name='dense1')(drop1)\n",
        "  outputs = Dense(1, activation='sigmoid',name='dense2')(dense1)\n",
        "  model = Model(inputs=inputs1, outputs=outputs)\n",
        "  \n",
        "  # compile\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "  \n",
        "  # summarize\n",
        "  print(model.summary())\n",
        "  #plot_model(model, show_shapes=True, to_file=DATA_PATH+'onechannel.png')\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVJZI8Zk4p8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modelo completo\n",
        "\n",
        "def CNN_emb_SVM(train,test,dictembedding,nChunks=1,epochs=5,batch_size=16,maxlengthseq=None):\n",
        "  tic=time.time()\n",
        "  # load data\n",
        "  x_train= generate_data(train,nChunks)\n",
        "  y_train=train['Depress'].values\n",
        "  x_test= generate_data(test,nChunks)\n",
        "  y_test=test['Depress'].values\n",
        "\n",
        "  # Initialite tokenizer\n",
        "  tokenizer = create_tokenizer(x_train)\n",
        "\n",
        "  # calculate max document length\n",
        "  if maxlengthseq ==None:\n",
        "    length = max_length(x_train)+1\n",
        "  else:\n",
        "    length= maxlengthseq\n",
        "  \n",
        "  # calculate vocabulary size\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "  \n",
        "  print('Chunks:{}'.format(nChunks))\n",
        "  print('Max document length: %d' % length)\n",
        "  print('Vocabulary size: %d' % vocab_size)\n",
        "\n",
        "  # Make embbeding layer\n",
        "  weights=embbedingLayer(tokenizer,dictembedding)\n",
        "  \n",
        "  # encode data train\n",
        "  trainX = encode_text(tokenizer, x_train, length)\n",
        "\n",
        "  # encode data test\n",
        "  testX = encode_text(tokenizer, x_test, length)\n",
        "  \n",
        "  # Pesos por clases no balanceadas\n",
        "  # Los datos no son balanceados, se da la información la proporción \n",
        "  class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y_train),\n",
        "                                                 y_train)\n",
        "\n",
        "  # Compile model\n",
        "  model=define_model(length, weights)\n",
        "  # fit model\n",
        "  model.fit(trainX, y_train, epochs=epochs, batch_size=batch_size,class_weight=class_weights, verbose=1)\n",
        "\n",
        "  # Feature extraction and new data\n",
        "\n",
        "  feature_extraction= Model(inputs=model.input, outputs=model.get_layer('dense1').output)\n",
        "  \n",
        "  train_svm=feature_extraction.predict(trainX)\n",
        "\n",
        "  test_svm=feature_extraction.predict(testX)\n",
        "  \n",
        "  #  Ajustar clasificador\n",
        "  svm_vectorizer=CountVectorizer( max_features=1000 )\n",
        "  clf = LinearSVC(tol=1e-3,C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
        "         intercept_scaling=1, loss='squared_hinge', max_iter=1000000,\n",
        "         multi_class='ovr', penalty='l2', random_state=1013, verbose=2)\n",
        "  \n",
        "\n",
        "  # Ajustar data y concatenate\n",
        "\n",
        "  bow_train=svm_vectorizer.fit_transform(x_train)\n",
        "  bow_train= bow_train.toarray()\n",
        "  train_svm=np.concatenate((train_svm,bow_train),axis=1)\n",
        "  bow_test=svm_vectorizer.transform(x_test)\n",
        "  bow_test= bow_test.toarray()\n",
        "  test_svm=np.concatenate((test_svm,bow_test),axis=1)\n",
        "\n",
        "  \n",
        "  # Entrenar\n",
        "  clf.fit(train_svm, y_train)\n",
        "\n",
        "  # Predecir para prueba\n",
        "\n",
        "  pred_test=clf.predict(test_svm)\n",
        "\n",
        "  # Metricas\n",
        "  acc=metrics.accuracy_score(y_test,pred_test)\n",
        "  f1_score_w=metrics.f1_score(y_test,pred_test,average='weighted')\n",
        "  recall_score=metrics.recall_score(y_test,pred_test,average='macro')\n",
        "  my_metrics=[nChunks,acc, f1_score_w,recall_score]\n",
        "  print('Acc=',acc)\n",
        "  print('F1 Score=',f1_score_w)\n",
        "  print('Recall=',recall_score)\n",
        "  print('Tiempo de procesamiento (secs):{}'.format(time.time()-tic))\n",
        "  return [round(metric,4) for metric in my_metrics]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoXIlOZBGHOo",
        "colab_type": "text"
      },
      "source": [
        "## Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA3giyTj_lmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Chunks=[i for i in range(1,11)]\n",
        "CNN_emb_SVM_metrics=np.empty((0,4),float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3blFOgp_rA6",
        "colab_type": "code",
        "outputId": "5120d07a-3094-4ebf-9ba0-b7b097c52f13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for chunk in Chunks:\n",
        "  tic=time.time()\n",
        "  metrics_svm=CNN_emb_SVM(df_train,df_test,dictembedding=embeddings_glove,nChunks=chunk,epochs=70,batch_size=32,maxlengthseq=30000)\n",
        "  CNN_emb_SVM_metrics=np.vstack([CNN_emb_SVM_metrics,metrics_svm])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chunks:1\n",
            "Max document length: 30000\n",
            "Vocabulary size: 95886\n",
            "Model: \"model_50\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "embedding_26 (Embedding)     (None, 30000, 100)        9588600   \n",
            "_________________________________________________________________\n",
            "conv1d_51 (Conv1D)           (None, 30000, 32)         12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_26 (MaxPooling (None, 15000, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_52 (Conv1D)           (None, 15000, 32)         4128      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_26 (Glo (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,606,649\n",
            "Trainable params: 18,049\n",
            "Non-trainable params: 9,588,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/70\n",
            "486/486 [==============================] - 6s 12ms/step - loss: 0.5582 - acc: 0.7654 - f1_m: 0.1345 - precision_m: 0.1863 - recall_m: 0.1510\n",
            "Epoch 2/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.5104 - acc: 0.8251 - f1_m: 0.0219 - precision_m: 0.0658 - recall_m: 0.0132\n",
            "Epoch 3/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4653 - acc: 0.8189 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4649 - acc: 0.8292 - f1_m: 0.0263 - precision_m: 0.0658 - recall_m: 0.0165\n",
            "Epoch 5/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4325 - acc: 0.8313 - f1_m: 0.0165 - precision_m: 0.0658 - recall_m: 0.0094\n",
            "Epoch 6/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4063 - acc: 0.8272 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3961 - acc: 0.8333 - f1_m: 0.0383 - precision_m: 0.1317 - recall_m: 0.0230\n",
            "Epoch 8/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3855 - acc: 0.8457 - f1_m: 0.1975 - precision_m: 0.4938 - recall_m: 0.1290\n",
            "Epoch 9/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3863 - acc: 0.8395 - f1_m: 0.0935 - precision_m: 0.2634 - recall_m: 0.0615\n",
            "Epoch 10/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3726 - acc: 0.8416 - f1_m: 0.1288 - precision_m: 0.2963 - recall_m: 0.0858\n",
            "Epoch 11/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3735 - acc: 0.8395 - f1_m: 0.0808 - precision_m: 0.1317 - recall_m: 0.0596\n",
            "Epoch 12/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3407 - acc: 0.8580 - f1_m: 0.2983 - precision_m: 0.7243 - recall_m: 0.2112\n",
            "Epoch 13/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3402 - acc: 0.8560 - f1_m: 0.2556 - precision_m: 0.5597 - recall_m: 0.1744\n",
            "Epoch 14/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2966 - acc: 0.8765 - f1_m: 0.4128 - precision_m: 0.7257 - recall_m: 0.3039\n",
            "Epoch 15/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2759 - acc: 0.9115 - f1_m: 0.6362 - precision_m: 0.8724 - recall_m: 0.5122\n",
            "Epoch 16/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2457 - acc: 0.8889 - f1_m: 0.5583 - precision_m: 0.8881 - recall_m: 0.4266\n",
            "Epoch 17/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2566 - acc: 0.8992 - f1_m: 0.5193 - precision_m: 0.8519 - recall_m: 0.4133\n",
            "Epoch 18/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2142 - acc: 0.9218 - f1_m: 0.7226 - precision_m: 0.9133 - recall_m: 0.6534\n",
            "Epoch 19/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2081 - acc: 0.9300 - f1_m: 0.7316 - precision_m: 0.9531 - recall_m: 0.6345\n",
            "Epoch 20/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2057 - acc: 0.9321 - f1_m: 0.7101 - precision_m: 0.8999 - recall_m: 0.6307\n",
            "Epoch 21/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1742 - acc: 0.9424 - f1_m: 0.7777 - precision_m: 0.9533 - recall_m: 0.6996\n",
            "Epoch 22/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1816 - acc: 0.9424 - f1_m: 0.7577 - precision_m: 0.9590 - recall_m: 0.6698\n",
            "Epoch 23/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1509 - acc: 0.9547 - f1_m: 0.7898 - precision_m: 0.8930 - recall_m: 0.7422\n",
            "Epoch 24/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1448 - acc: 0.9568 - f1_m: 0.8680 - precision_m: 0.9868 - recall_m: 0.7899\n",
            "Epoch 25/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1186 - acc: 0.9630 - f1_m: 0.8838 - precision_m: 0.9786 - recall_m: 0.8232\n",
            "Epoch 26/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1215 - acc: 0.9712 - f1_m: 0.9080 - precision_m: 0.9572 - recall_m: 0.8739\n",
            "Epoch 27/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1098 - acc: 0.9630 - f1_m: 0.8592 - precision_m: 0.9890 - recall_m: 0.7848\n",
            "Epoch 28/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0848 - acc: 0.9877 - f1_m: 0.9506 - precision_m: 0.9877 - recall_m: 0.9222\n",
            "Epoch 29/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0991 - acc: 0.9671 - f1_m: 0.8738 - precision_m: 0.9671 - recall_m: 0.8111\n",
            "Epoch 30/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0962 - acc: 0.9712 - f1_m: 0.8814 - precision_m: 0.9686 - recall_m: 0.8444\n",
            "Epoch 31/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1128 - acc: 0.9712 - f1_m: 0.8909 - precision_m: 0.9616 - recall_m: 0.8490\n",
            "Epoch 32/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0786 - acc: 0.9856 - f1_m: 0.8836 - precision_m: 0.9053 - recall_m: 0.8695\n",
            "Epoch 33/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0805 - acc: 0.9733 - f1_m: 0.9215 - precision_m: 1.0000 - recall_m: 0.8793\n",
            "Epoch 34/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0826 - acc: 0.9815 - f1_m: 0.9465 - precision_m: 0.9671 - recall_m: 0.9393\n",
            "Epoch 35/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0657 - acc: 0.9815 - f1_m: 0.9265 - precision_m: 1.0000 - recall_m: 0.8803\n",
            "Epoch 36/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0537 - acc: 0.9897 - f1_m: 0.9606 - precision_m: 0.9877 - recall_m: 0.9388\n",
            "Epoch 37/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0603 - acc: 0.9815 - f1_m: 0.9500 - precision_m: 0.9918 - recall_m: 0.9245\n",
            "Epoch 38/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0880 - acc: 0.9712 - f1_m: 0.9100 - precision_m: 0.9704 - recall_m: 0.8685\n",
            "Epoch 39/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0590 - acc: 0.9794 - f1_m: 0.9300 - precision_m: 0.9795 - recall_m: 0.8996\n",
            "Epoch 40/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0549 - acc: 0.9877 - f1_m: 0.9519 - precision_m: 1.0000 - recall_m: 0.9155\n",
            "Epoch 41/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0522 - acc: 0.9815 - f1_m: 0.9377 - precision_m: 0.9835 - recall_m: 0.9078\n",
            "Epoch 42/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0791 - acc: 0.9815 - f1_m: 0.9213 - precision_m: 0.9877 - recall_m: 0.8767\n",
            "Epoch 43/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0624 - acc: 0.9877 - f1_m: 0.9534 - precision_m: 0.9671 - recall_m: 0.9517\n",
            "Epoch 44/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0552 - acc: 0.9877 - f1_m: 0.9541 - precision_m: 0.9906 - recall_m: 0.9330\n",
            "Epoch 45/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0491 - acc: 0.9794 - f1_m: 0.9309 - precision_m: 0.9671 - recall_m: 0.9110\n",
            "Epoch 46/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0556 - acc: 0.9794 - f1_m: 0.9158 - precision_m: 0.9547 - recall_m: 0.8937\n",
            "Epoch 47/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0395 - acc: 0.9897 - f1_m: 0.9451 - precision_m: 0.9877 - recall_m: 0.9166\n",
            "Epoch 48/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0449 - acc: 0.9897 - f1_m: 0.9621 - precision_m: 0.9826 - recall_m: 0.9457\n",
            "Epoch 49/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0430 - acc: 0.9856 - f1_m: 0.9430 - precision_m: 0.9782 - recall_m: 0.9179\n",
            "Epoch 50/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0519 - acc: 0.9897 - f1_m: 0.9652 - precision_m: 0.9906 - recall_m: 0.9495\n",
            "Epoch 51/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0641 - acc: 0.9897 - f1_m: 0.9633 - precision_m: 0.9877 - recall_m: 0.9432\n",
            "Epoch 52/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0420 - acc: 0.9918 - f1_m: 0.9670 - precision_m: 0.9877 - recall_m: 0.9504\n",
            "Epoch 53/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0306 - acc: 0.9918 - f1_m: 0.9700 - precision_m: 0.9835 - recall_m: 0.9631\n",
            "Epoch 54/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0329 - acc: 0.9918 - f1_m: 0.9805 - precision_m: 0.9868 - recall_m: 0.9771\n",
            "Epoch 55/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0353 - acc: 0.9897 - f1_m: 0.9713 - precision_m: 1.0000 - recall_m: 0.9488\n",
            "Epoch 56/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0345 - acc: 0.9877 - f1_m: 0.9441 - precision_m: 0.9712 - recall_m: 0.9277\n",
            "Epoch 57/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0343 - acc: 0.9897 - f1_m: 0.9573 - precision_m: 0.9877 - recall_m: 0.9325\n",
            "Epoch 58/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0211 - acc: 0.9959 - f1_m: 0.9915 - precision_m: 1.0000 - recall_m: 0.9840\n",
            "Epoch 59/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0383 - acc: 0.9938 - f1_m: 0.9730 - precision_m: 0.9877 - recall_m: 0.9613\n",
            "Epoch 60/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0516 - acc: 0.9835 - f1_m: 0.9383 - precision_m: 1.0000 - recall_m: 0.8973\n",
            "Epoch 61/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0610 - acc: 0.9794 - f1_m: 0.8661 - precision_m: 0.9122 - recall_m: 0.8387\n",
            "Epoch 62/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0798 - acc: 0.9712 - f1_m: 0.9159 - precision_m: 0.9280 - recall_m: 0.9199\n",
            "Epoch 63/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0397 - acc: 0.9918 - f1_m: 0.9631 - precision_m: 1.0000 - recall_m: 0.9385\n",
            "Epoch 64/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0359 - acc: 0.9918 - f1_m: 0.9636 - precision_m: 1.0000 - recall_m: 0.9412\n",
            "Epoch 65/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0267 - acc: 0.9918 - f1_m: 0.9785 - precision_m: 1.0000 - recall_m: 0.9605\n",
            "Epoch 66/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0456 - acc: 0.9938 - f1_m: 0.9672 - precision_m: 0.9877 - recall_m: 0.9508\n",
            "Epoch 67/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0394 - acc: 0.9877 - f1_m: 0.9532 - precision_m: 0.9906 - recall_m: 0.9314\n",
            "Epoch 68/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0297 - acc: 0.9938 - f1_m: 0.9041 - precision_m: 0.9218 - recall_m: 0.8894\n",
            "Epoch 69/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0290 - acc: 0.9938 - f1_m: 0.9693 - precision_m: 0.9767 - recall_m: 0.9651\n",
            "Epoch 70/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0168 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000\n",
            "[LibLinear]Acc= 0.8403990024937655\n",
            "F1 Score= 0.8482335147363033\n",
            "Recall= 0.7037414591139519\n",
            "Tiempo de procesamiento (secs):212.4961326122284\n",
            "Chunks:2\n",
            "Max document length: 30000\n",
            "Vocabulary size: 95886\n",
            "Model: \"model_52\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_27 (InputLayer)        (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "embedding_27 (Embedding)     (None, 30000, 100)        9588600   \n",
            "_________________________________________________________________\n",
            "conv1d_53 (Conv1D)           (None, 30000, 32)         12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_27 (MaxPooling (None, 15000, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_54 (Conv1D)           (None, 15000, 32)         4128      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_27 (Glo (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,606,649\n",
            "Trainable params: 18,049\n",
            "Non-trainable params: 9,588,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/70\n",
            "486/486 [==============================] - 6s 12ms/step - loss: 0.5681 - acc: 0.7428 - f1_m: 0.1558 - precision_m: 0.2053 - recall_m: 0.1819\n",
            "Epoch 2/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.5128 - acc: 0.8251 - f1_m: 0.0219 - precision_m: 0.0658 - recall_m: 0.0132\n",
            "Epoch 3/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4667 - acc: 0.8189 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4658 - acc: 0.8333 - f1_m: 0.0376 - precision_m: 0.1317 - recall_m: 0.0219\n",
            "Epoch 5/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4323 - acc: 0.8272 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4111 - acc: 0.8292 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4011 - acc: 0.8374 - f1_m: 0.0671 - precision_m: 0.1975 - recall_m: 0.0406\n",
            "Epoch 8/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3889 - acc: 0.8395 - f1_m: 0.1097 - precision_m: 0.3292 - recall_m: 0.0687\n",
            "Epoch 9/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3903 - acc: 0.8436 - f1_m: 0.1217 - precision_m: 0.2634 - recall_m: 0.0834\n",
            "Epoch 10/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3711 - acc: 0.8416 - f1_m: 0.0805 - precision_m: 0.1975 - recall_m: 0.0529\n",
            "Epoch 11/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3701 - acc: 0.8416 - f1_m: 0.1134 - precision_m: 0.2634 - recall_m: 0.0749\n",
            "Epoch 12/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3394 - acc: 0.8539 - f1_m: 0.2698 - precision_m: 0.7243 - recall_m: 0.1772\n",
            "Epoch 13/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3343 - acc: 0.8560 - f1_m: 0.2645 - precision_m: 0.5597 - recall_m: 0.1817\n",
            "Epoch 14/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2962 - acc: 0.8807 - f1_m: 0.4696 - precision_m: 0.8551 - recall_m: 0.3402\n",
            "Epoch 15/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2724 - acc: 0.8992 - f1_m: 0.5465 - precision_m: 0.7970 - recall_m: 0.4363\n",
            "Epoch 16/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2466 - acc: 0.8930 - f1_m: 0.5538 - precision_m: 0.8551 - recall_m: 0.4406\n",
            "Epoch 17/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2538 - acc: 0.8992 - f1_m: 0.5125 - precision_m: 0.7893 - recall_m: 0.3994\n",
            "Epoch 18/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2113 - acc: 0.9300 - f1_m: 0.7499 - precision_m: 0.9276 - recall_m: 0.6567\n",
            "Epoch 19/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2093 - acc: 0.9300 - f1_m: 0.7201 - precision_m: 0.9613 - recall_m: 0.6218\n",
            "Epoch 20/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2150 - acc: 0.9280 - f1_m: 0.6960 - precision_m: 0.9108 - recall_m: 0.6053\n",
            "Epoch 21/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1723 - acc: 0.9362 - f1_m: 0.7458 - precision_m: 0.9478 - recall_m: 0.6607\n",
            "Epoch 22/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1713 - acc: 0.9486 - f1_m: 0.8054 - precision_m: 0.9402 - recall_m: 0.7371\n",
            "Epoch 23/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1438 - acc: 0.9506 - f1_m: 0.7777 - precision_m: 0.8824 - recall_m: 0.7366\n",
            "Epoch 24/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1426 - acc: 0.9506 - f1_m: 0.8059 - precision_m: 0.9116 - recall_m: 0.7408\n",
            "Epoch 25/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1137 - acc: 0.9671 - f1_m: 0.8911 - precision_m: 0.9927 - recall_m: 0.8239\n",
            "Epoch 26/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1309 - acc: 0.9650 - f1_m: 0.8733 - precision_m: 0.9610 - recall_m: 0.8216\n",
            "Epoch 27/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1101 - acc: 0.9753 - f1_m: 0.9038 - precision_m: 0.9759 - recall_m: 0.8680\n",
            "Epoch 28/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0763 - acc: 0.9856 - f1_m: 0.9364 - precision_m: 0.9877 - recall_m: 0.8975\n",
            "Epoch 29/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0997 - acc: 0.9691 - f1_m: 0.8705 - precision_m: 0.9671 - recall_m: 0.8151\n",
            "Epoch 30/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0861 - acc: 0.9712 - f1_m: 0.8939 - precision_m: 0.9671 - recall_m: 0.8526\n",
            "Epoch 31/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1145 - acc: 0.9671 - f1_m: 0.8804 - precision_m: 0.9484 - recall_m: 0.8435\n",
            "Epoch 32/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0807 - acc: 0.9856 - f1_m: 0.8914 - precision_m: 0.9218 - recall_m: 0.8656\n",
            "Epoch 33/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0957 - acc: 0.9650 - f1_m: 0.8876 - precision_m: 0.9741 - recall_m: 0.8271\n",
            "Epoch 34/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0947 - acc: 0.9774 - f1_m: 0.9289 - precision_m: 0.9506 - recall_m: 0.9173\n",
            "Epoch 35/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0639 - acc: 0.9815 - f1_m: 0.9370 - precision_m: 1.0000 - recall_m: 0.8907\n",
            "Epoch 36/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0622 - acc: 0.9877 - f1_m: 0.9365 - precision_m: 0.9877 - recall_m: 0.9026\n",
            "Epoch 37/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0639 - acc: 0.9835 - f1_m: 0.9597 - precision_m: 0.9918 - recall_m: 0.9366\n",
            "Epoch 38/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0826 - acc: 0.9794 - f1_m: 0.9356 - precision_m: 1.0000 - recall_m: 0.8861\n",
            "Epoch 39/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0590 - acc: 0.9856 - f1_m: 0.9505 - precision_m: 0.9868 - recall_m: 0.9270\n",
            "Epoch 40/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0561 - acc: 0.9835 - f1_m: 0.9430 - precision_m: 0.9927 - recall_m: 0.9062\n",
            "Epoch 41/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0504 - acc: 0.9815 - f1_m: 0.9363 - precision_m: 0.9835 - recall_m: 0.9056\n",
            "Epoch 42/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0819 - acc: 0.9753 - f1_m: 0.9045 - precision_m: 0.9709 - recall_m: 0.8602\n",
            "Epoch 43/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0606 - acc: 0.9815 - f1_m: 0.9337 - precision_m: 0.9671 - recall_m: 0.9192\n",
            "Epoch 44/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0431 - acc: 0.9959 - f1_m: 0.9855 - precision_m: 0.9906 - recall_m: 0.9835\n",
            "Epoch 45/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0523 - acc: 0.9835 - f1_m: 0.9391 - precision_m: 0.9671 - recall_m: 0.9291\n",
            "Epoch 46/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0535 - acc: 0.9835 - f1_m: 0.9175 - precision_m: 0.9547 - recall_m: 0.8871\n",
            "Epoch 47/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0407 - acc: 0.9877 - f1_m: 0.9384 - precision_m: 0.9877 - recall_m: 0.9045\n",
            "Epoch 48/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0367 - acc: 0.9897 - f1_m: 0.9600 - precision_m: 0.9826 - recall_m: 0.9442\n",
            "Epoch 49/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0425 - acc: 0.9877 - f1_m: 0.9501 - precision_m: 0.9782 - recall_m: 0.9298\n",
            "Epoch 50/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0449 - acc: 0.9897 - f1_m: 0.9645 - precision_m: 0.9868 - recall_m: 0.9523\n",
            "Epoch 51/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0502 - acc: 0.9856 - f1_m: 0.9526 - precision_m: 0.9701 - recall_m: 0.9395\n",
            "Epoch 52/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0393 - acc: 0.9918 - f1_m: 0.9495 - precision_m: 0.9877 - recall_m: 0.9248\n",
            "Epoch 53/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0303 - acc: 0.9918 - f1_m: 0.9789 - precision_m: 1.0000 - recall_m: 0.9623\n",
            "Epoch 54/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0433 - acc: 0.9835 - f1_m: 0.9591 - precision_m: 0.9774 - recall_m: 0.9506\n",
            "Epoch 55/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0391 - acc: 0.9897 - f1_m: 0.9713 - precision_m: 1.0000 - recall_m: 0.9488\n",
            "Epoch 56/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0369 - acc: 0.9918 - f1_m: 0.9544 - precision_m: 0.9712 - recall_m: 0.9453\n",
            "Epoch 57/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0300 - acc: 0.9959 - f1_m: 0.9778 - precision_m: 0.9877 - recall_m: 0.9694\n",
            "Epoch 58/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0238 - acc: 0.9918 - f1_m: 0.9796 - precision_m: 1.0000 - recall_m: 0.9636\n",
            "Epoch 59/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0375 - acc: 0.9938 - f1_m: 0.9730 - precision_m: 0.9877 - recall_m: 0.9613\n",
            "Epoch 60/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0365 - acc: 0.9918 - f1_m: 0.9719 - precision_m: 1.0000 - recall_m: 0.9504\n",
            "Epoch 61/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0465 - acc: 0.9877 - f1_m: 0.8866 - precision_m: 0.9122 - recall_m: 0.8734\n",
            "Epoch 62/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0572 - acc: 0.9835 - f1_m: 0.9507 - precision_m: 0.9737 - recall_m: 0.9382\n",
            "Epoch 63/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0288 - acc: 0.9938 - f1_m: 0.9722 - precision_m: 1.0000 - recall_m: 0.9517\n",
            "Epoch 64/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0397 - acc: 0.9918 - f1_m: 0.9598 - precision_m: 1.0000 - recall_m: 0.9357\n",
            "Epoch 65/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0346 - acc: 0.9918 - f1_m: 0.9735 - precision_m: 0.9868 - recall_m: 0.9671\n",
            "Epoch 66/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0610 - acc: 0.9835 - f1_m: 0.9435 - precision_m: 0.9745 - recall_m: 0.9224\n",
            "Epoch 67/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0379 - acc: 0.9856 - f1_m: 0.9535 - precision_m: 1.0000 - recall_m: 0.9223\n",
            "Epoch 68/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0303 - acc: 0.9918 - f1_m: 0.8932 - precision_m: 0.9124 - recall_m: 0.8807\n",
            "Epoch 69/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0256 - acc: 0.9918 - f1_m: 0.9492 - precision_m: 0.9712 - recall_m: 0.9383\n",
            "Epoch 70/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0230 - acc: 0.9938 - f1_m: 0.9839 - precision_m: 1.0000 - recall_m: 0.9704\n",
            "[LibLinear]Acc= 0.830423940149626\n",
            "F1 Score= 0.8397398488139378\n",
            "Recall= 0.6898280802292264\n",
            "Tiempo de procesamiento (secs):212.29645895957947\n",
            "Chunks:3\n",
            "Max document length: 30000\n",
            "Vocabulary size: 96309\n",
            "Model: \"model_54\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "embedding_28 (Embedding)     (None, 30000, 100)        9630900   \n",
            "_________________________________________________________________\n",
            "conv1d_55 (Conv1D)           (None, 30000, 32)         12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_28 (MaxPooling (None, 15000, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_56 (Conv1D)           (None, 15000, 32)         4128      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_28 (Glo (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,648,949\n",
            "Trainable params: 18,049\n",
            "Non-trainable params: 9,630,900\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/70\n",
            "486/486 [==============================] - 6s 12ms/step - loss: 0.5691 - acc: 0.7449 - f1_m: 0.1477 - precision_m: 0.1845 - recall_m: 0.1819\n",
            "Epoch 2/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.5126 - acc: 0.8292 - f1_m: 0.0408 - precision_m: 0.1317 - recall_m: 0.0241\n",
            "Epoch 3/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4686 - acc: 0.8210 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4631 - acc: 0.8292 - f1_m: 0.0263 - precision_m: 0.0658 - recall_m: 0.0165\n",
            "Epoch 5/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4318 - acc: 0.8313 - f1_m: 0.0165 - precision_m: 0.0658 - recall_m: 0.0094\n",
            "Epoch 6/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4079 - acc: 0.8292 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3996 - acc: 0.8333 - f1_m: 0.0383 - precision_m: 0.1317 - recall_m: 0.0230\n",
            "Epoch 8/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3863 - acc: 0.8416 - f1_m: 0.1646 - precision_m: 0.4280 - recall_m: 0.1071\n",
            "Epoch 9/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3897 - acc: 0.8436 - f1_m: 0.1339 - precision_m: 0.3292 - recall_m: 0.0889\n",
            "Epoch 10/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3725 - acc: 0.8436 - f1_m: 0.1792 - precision_m: 0.3951 - recall_m: 0.1209\n",
            "Epoch 11/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3704 - acc: 0.8436 - f1_m: 0.1077 - precision_m: 0.2634 - recall_m: 0.0733\n",
            "Epoch 12/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3411 - acc: 0.8498 - f1_m: 0.2356 - precision_m: 0.5267 - recall_m: 0.1767\n",
            "Epoch 13/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3359 - acc: 0.8560 - f1_m: 0.2556 - precision_m: 0.5597 - recall_m: 0.1744\n",
            "Epoch 14/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2943 - acc: 0.8745 - f1_m: 0.4021 - precision_m: 0.7202 - recall_m: 0.2986\n",
            "Epoch 15/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2743 - acc: 0.9053 - f1_m: 0.5807 - precision_m: 0.8779 - recall_m: 0.4504\n",
            "Epoch 16/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2524 - acc: 0.8909 - f1_m: 0.5345 - precision_m: 0.8244 - recall_m: 0.4186\n",
            "Epoch 17/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2654 - acc: 0.8868 - f1_m: 0.4999 - precision_m: 0.9078 - recall_m: 0.3865\n",
            "Epoch 18/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2224 - acc: 0.9239 - f1_m: 0.7142 - precision_m: 0.9243 - recall_m: 0.6095\n",
            "Epoch 19/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2182 - acc: 0.9198 - f1_m: 0.6828 - precision_m: 0.9311 - recall_m: 0.5866\n",
            "Epoch 20/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2178 - acc: 0.9259 - f1_m: 0.6887 - precision_m: 0.9086 - recall_m: 0.5978\n",
            "Epoch 21/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1796 - acc: 0.9383 - f1_m: 0.7460 - precision_m: 0.9774 - recall_m: 0.6516\n",
            "Epoch 22/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1728 - acc: 0.9444 - f1_m: 0.7900 - precision_m: 0.9519 - recall_m: 0.6946\n",
            "Epoch 23/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1515 - acc: 0.9506 - f1_m: 0.7111 - precision_m: 0.8244 - recall_m: 0.6710\n",
            "Epoch 24/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1482 - acc: 0.9506 - f1_m: 0.8316 - precision_m: 0.9868 - recall_m: 0.7455\n",
            "Epoch 25/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1176 - acc: 0.9588 - f1_m: 0.8536 - precision_m: 1.0000 - recall_m: 0.7623\n",
            "Epoch 26/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1278 - acc: 0.9671 - f1_m: 0.8525 - precision_m: 0.9177 - recall_m: 0.8042\n",
            "Epoch 27/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1206 - acc: 0.9691 - f1_m: 0.8839 - precision_m: 0.9812 - recall_m: 0.8278\n",
            "Epoch 28/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0882 - acc: 0.9815 - f1_m: 0.9380 - precision_m: 0.9877 - recall_m: 0.8974\n",
            "Epoch 29/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1025 - acc: 0.9691 - f1_m: 0.8623 - precision_m: 0.9671 - recall_m: 0.8052\n",
            "Epoch 30/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0967 - acc: 0.9671 - f1_m: 0.8712 - precision_m: 0.9737 - recall_m: 0.8240\n",
            "Epoch 31/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1134 - acc: 0.9691 - f1_m: 0.8817 - precision_m: 0.9671 - recall_m: 0.8359\n",
            "Epoch 32/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0848 - acc: 0.9733 - f1_m: 0.8943 - precision_m: 0.9218 - recall_m: 0.8885\n",
            "Epoch 33/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0847 - acc: 0.9733 - f1_m: 0.9158 - precision_m: 0.9890 - recall_m: 0.8699\n",
            "Epoch 34/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0898 - acc: 0.9733 - f1_m: 0.9193 - precision_m: 0.9671 - recall_m: 0.8881\n",
            "Epoch 35/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0638 - acc: 0.9815 - f1_m: 0.9365 - precision_m: 1.0000 - recall_m: 0.8928\n",
            "Epoch 36/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0699 - acc: 0.9815 - f1_m: 0.9159 - precision_m: 0.9712 - recall_m: 0.8821\n",
            "Epoch 37/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0575 - acc: 0.9918 - f1_m: 0.9807 - precision_m: 1.0000 - recall_m: 0.9652\n",
            "Epoch 38/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0860 - acc: 0.9753 - f1_m: 0.9189 - precision_m: 0.9868 - recall_m: 0.8707\n",
            "Epoch 39/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0687 - acc: 0.9815 - f1_m: 0.9387 - precision_m: 0.9927 - recall_m: 0.9017\n",
            "Epoch 40/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0537 - acc: 0.9877 - f1_m: 0.9524 - precision_m: 1.0000 - recall_m: 0.9160\n",
            "Epoch 41/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0571 - acc: 0.9835 - f1_m: 0.9436 - precision_m: 0.9835 - recall_m: 0.9188\n",
            "Epoch 42/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0795 - acc: 0.9733 - f1_m: 0.8974 - precision_m: 0.9673 - recall_m: 0.8492\n",
            "Epoch 43/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0679 - acc: 0.9835 - f1_m: 0.9422 - precision_m: 0.9781 - recall_m: 0.9236\n",
            "Epoch 44/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0564 - acc: 0.9918 - f1_m: 0.9736 - precision_m: 1.0000 - recall_m: 0.9538\n",
            "Epoch 45/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0702 - acc: 0.9794 - f1_m: 0.9199 - precision_m: 0.9598 - recall_m: 0.8873\n",
            "Epoch 46/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0587 - acc: 0.9774 - f1_m: 0.9187 - precision_m: 0.9469 - recall_m: 0.9073\n",
            "Epoch 47/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0461 - acc: 0.9856 - f1_m: 0.9311 - precision_m: 0.9877 - recall_m: 0.8913\n",
            "Epoch 48/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0459 - acc: 0.9856 - f1_m: 0.9473 - precision_m: 0.9877 - recall_m: 0.9160\n",
            "Epoch 49/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0523 - acc: 0.9856 - f1_m: 0.9437 - precision_m: 0.9877 - recall_m: 0.9112\n",
            "Epoch 50/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0485 - acc: 0.9918 - f1_m: 0.9718 - precision_m: 0.9868 - recall_m: 0.9654\n",
            "Epoch 51/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0642 - acc: 0.9774 - f1_m: 0.9363 - precision_m: 0.9651 - recall_m: 0.9154\n",
            "Epoch 52/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0493 - acc: 0.9918 - f1_m: 0.9623 - precision_m: 0.9877 - recall_m: 0.9446\n",
            "Epoch 53/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0271 - acc: 0.9959 - f1_m: 0.9867 - precision_m: 1.0000 - recall_m: 0.9759\n",
            "Epoch 54/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0578 - acc: 0.9815 - f1_m: 0.9564 - precision_m: 0.9720 - recall_m: 0.9497\n",
            "Epoch 55/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0538 - acc: 0.9794 - f1_m: 0.9393 - precision_m: 0.9868 - recall_m: 0.9048\n",
            "Epoch 56/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0438 - acc: 0.9877 - f1_m: 0.9409 - precision_m: 0.9657 - recall_m: 0.9222\n",
            "Epoch 57/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0255 - acc: 0.9959 - f1_m: 0.9723 - precision_m: 0.9877 - recall_m: 0.9602\n",
            "Epoch 58/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0319 - acc: 0.9918 - f1_m: 0.9795 - precision_m: 1.0000 - recall_m: 0.9621\n",
            "Epoch 59/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0406 - acc: 0.9938 - f1_m: 0.9657 - precision_m: 0.9877 - recall_m: 0.9481\n",
            "Epoch 60/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0473 - acc: 0.9918 - f1_m: 0.9807 - precision_m: 1.0000 - recall_m: 0.9641\n",
            "Epoch 61/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0426 - acc: 0.9835 - f1_m: 0.8824 - precision_m: 0.9342 - recall_m: 0.8444\n",
            "Epoch 62/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0498 - acc: 0.9815 - f1_m: 0.9436 - precision_m: 0.9610 - recall_m: 0.9382\n",
            "Epoch 63/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0248 - acc: 0.9918 - f1_m: 0.9631 - precision_m: 1.0000 - recall_m: 0.9385\n",
            "Epoch 64/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0375 - acc: 0.9877 - f1_m: 0.9474 - precision_m: 0.9774 - recall_m: 0.9357\n",
            "Epoch 65/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0374 - acc: 0.9877 - f1_m: 0.9620 - precision_m: 1.0000 - recall_m: 0.9330\n",
            "Epoch 66/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0579 - acc: 0.9877 - f1_m: 0.9443 - precision_m: 0.9794 - recall_m: 0.9234\n",
            "Epoch 67/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0307 - acc: 0.9918 - f1_m: 0.9798 - precision_m: 1.0000 - recall_m: 0.9625\n",
            "Epoch 68/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0302 - acc: 0.9918 - f1_m: 0.8970 - precision_m: 0.9053 - recall_m: 0.8932\n",
            "Epoch 69/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0230 - acc: 0.9938 - f1_m: 0.9672 - precision_m: 0.9877 - recall_m: 0.9508\n",
            "Epoch 70/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0152 - acc: 0.9959 - f1_m: 0.9912 - precision_m: 1.0000 - recall_m: 0.9835\n",
            "[LibLinear]Acc= 0.8154613466334164\n",
            "F1 Score= 0.825599247238697\n",
            "Recall= 0.6566839321137315\n",
            "Tiempo de procesamiento (secs):212.9666142463684\n",
            "Chunks:4\n",
            "Max document length: 30000\n",
            "Vocabulary size: 96319\n",
            "Model: \"model_56\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_29 (InputLayer)        (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "embedding_29 (Embedding)     (None, 30000, 100)        9631900   \n",
            "_________________________________________________________________\n",
            "conv1d_57 (Conv1D)           (None, 30000, 32)         12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_29 (MaxPooling (None, 15000, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_58 (Conv1D)           (None, 15000, 32)         4128      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_29 (Glo (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,649,949\n",
            "Trainable params: 18,049\n",
            "Non-trainable params: 9,631,900\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/70\n",
            "486/486 [==============================] - 6s 13ms/step - loss: 0.5580 - acc: 0.7593 - f1_m: 0.1344 - precision_m: 0.1867 - recall_m: 0.1510\n",
            "Epoch 2/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.5095 - acc: 0.8251 - f1_m: 0.0188 - precision_m: 0.0329 - recall_m: 0.0132\n",
            "Epoch 3/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4661 - acc: 0.8230 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4643 - acc: 0.8292 - f1_m: 0.0188 - precision_m: 0.0658 - recall_m: 0.0110\n",
            "Epoch 5/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4299 - acc: 0.8313 - f1_m: 0.0311 - precision_m: 0.1317 - recall_m: 0.0176\n",
            "Epoch 6/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4060 - acc: 0.8292 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3984 - acc: 0.8333 - f1_m: 0.0383 - precision_m: 0.1317 - recall_m: 0.0230\n",
            "Epoch 8/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3840 - acc: 0.8457 - f1_m: 0.1927 - precision_m: 0.4609 - recall_m: 0.1246\n",
            "Epoch 9/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3822 - acc: 0.8436 - f1_m: 0.1405 - precision_m: 0.3292 - recall_m: 0.0944\n",
            "Epoch 10/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3675 - acc: 0.8477 - f1_m: 0.1836 - precision_m: 0.3951 - recall_m: 0.1242\n",
            "Epoch 11/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3701 - acc: 0.8457 - f1_m: 0.1711 - precision_m: 0.3621 - recall_m: 0.1199\n",
            "Epoch 12/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3369 - acc: 0.8580 - f1_m: 0.3106 - precision_m: 0.7901 - recall_m: 0.2211\n",
            "Epoch 13/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3350 - acc: 0.8601 - f1_m: 0.2792 - precision_m: 0.6255 - recall_m: 0.1899\n",
            "Epoch 14/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2901 - acc: 0.8765 - f1_m: 0.4378 - precision_m: 0.7860 - recall_m: 0.3133\n",
            "Epoch 15/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2719 - acc: 0.9012 - f1_m: 0.5396 - precision_m: 0.7627 - recall_m: 0.4320\n",
            "Epoch 16/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2465 - acc: 0.8909 - f1_m: 0.5484 - precision_m: 0.9012 - recall_m: 0.4108\n",
            "Epoch 17/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2556 - acc: 0.8951 - f1_m: 0.5327 - precision_m: 0.8903 - recall_m: 0.4150\n",
            "Epoch 18/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2146 - acc: 0.9218 - f1_m: 0.7057 - precision_m: 0.9182 - recall_m: 0.6211\n",
            "Epoch 19/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2150 - acc: 0.9198 - f1_m: 0.6985 - precision_m: 0.9070 - recall_m: 0.6109\n",
            "Epoch 20/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2118 - acc: 0.9300 - f1_m: 0.6986 - precision_m: 0.9124 - recall_m: 0.6033\n",
            "Epoch 21/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1788 - acc: 0.9383 - f1_m: 0.7547 - precision_m: 0.9627 - recall_m: 0.6673\n",
            "Epoch 22/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1763 - acc: 0.9527 - f1_m: 0.8079 - precision_m: 0.9730 - recall_m: 0.7249\n",
            "Epoch 23/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1515 - acc: 0.9527 - f1_m: 0.7268 - precision_m: 0.8208 - recall_m: 0.6890\n",
            "Epoch 24/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1501 - acc: 0.9506 - f1_m: 0.8120 - precision_m: 0.8951 - recall_m: 0.7573\n",
            "Epoch 25/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1097 - acc: 0.9609 - f1_m: 0.8825 - precision_m: 0.9774 - recall_m: 0.8183\n",
            "Epoch 26/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1218 - acc: 0.9588 - f1_m: 0.8318 - precision_m: 0.9045 - recall_m: 0.7841\n",
            "Epoch 27/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1115 - acc: 0.9753 - f1_m: 0.9077 - precision_m: 1.0000 - recall_m: 0.8535\n",
            "Epoch 28/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0833 - acc: 0.9856 - f1_m: 0.9446 - precision_m: 0.9877 - recall_m: 0.9116\n",
            "Epoch 29/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0977 - acc: 0.9753 - f1_m: 0.9009 - precision_m: 0.9671 - recall_m: 0.8547\n",
            "Epoch 30/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0815 - acc: 0.9794 - f1_m: 0.9310 - precision_m: 0.9890 - recall_m: 0.8867\n",
            "Epoch 31/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1044 - acc: 0.9753 - f1_m: 0.9135 - precision_m: 0.9835 - recall_m: 0.8782\n",
            "Epoch 32/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0775 - acc: 0.9835 - f1_m: 0.9366 - precision_m: 0.9657 - recall_m: 0.9123\n",
            "Epoch 33/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0830 - acc: 0.9774 - f1_m: 0.9258 - precision_m: 1.0000 - recall_m: 0.8735\n",
            "Epoch 34/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0879 - acc: 0.9753 - f1_m: 0.9245 - precision_m: 0.9835 - recall_m: 0.8859\n",
            "Epoch 35/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0599 - acc: 0.9856 - f1_m: 0.9468 - precision_m: 1.0000 - recall_m: 0.9105\n",
            "Epoch 36/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0648 - acc: 0.9835 - f1_m: 0.9123 - precision_m: 0.9712 - recall_m: 0.8812\n",
            "Epoch 37/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0572 - acc: 0.9877 - f1_m: 0.9603 - precision_m: 1.0000 - recall_m: 0.9312\n",
            "Epoch 38/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0827 - acc: 0.9794 - f1_m: 0.9286 - precision_m: 0.9835 - recall_m: 0.8883\n",
            "Epoch 39/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0660 - acc: 0.9794 - f1_m: 0.9364 - precision_m: 0.9906 - recall_m: 0.8929\n",
            "Epoch 40/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0528 - acc: 0.9877 - f1_m: 0.9584 - precision_m: 0.9927 - recall_m: 0.9336\n",
            "Epoch 41/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0551 - acc: 0.9835 - f1_m: 0.9471 - precision_m: 1.0000 - recall_m: 0.9078\n",
            "Epoch 42/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0745 - acc: 0.9753 - f1_m: 0.9089 - precision_m: 0.9615 - recall_m: 0.8767\n",
            "Epoch 43/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0577 - acc: 0.9918 - f1_m: 0.9760 - precision_m: 1.0000 - recall_m: 0.9609\n",
            "Epoch 44/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0505 - acc: 0.9938 - f1_m: 0.9746 - precision_m: 1.0000 - recall_m: 0.9605\n",
            "Epoch 45/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0533 - acc: 0.9815 - f1_m: 0.9310 - precision_m: 0.9671 - recall_m: 0.9166\n",
            "Epoch 46/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0536 - acc: 0.9856 - f1_m: 0.9294 - precision_m: 0.9359 - recall_m: 0.9249\n",
            "Epoch 47/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0406 - acc: 0.9897 - f1_m: 0.9444 - precision_m: 0.9877 - recall_m: 0.9154\n",
            "Epoch 48/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0339 - acc: 0.9918 - f1_m: 0.9646 - precision_m: 0.9877 - recall_m: 0.9457\n",
            "Epoch 49/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0440 - acc: 0.9856 - f1_m: 0.9446 - precision_m: 0.9811 - recall_m: 0.9183\n",
            "Epoch 50/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0510 - acc: 0.9856 - f1_m: 0.9505 - precision_m: 0.9835 - recall_m: 0.9303\n",
            "Epoch 51/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0620 - acc: 0.9877 - f1_m: 0.9580 - precision_m: 0.9794 - recall_m: 0.9417\n",
            "Epoch 52/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0476 - acc: 0.9938 - f1_m: 0.9714 - precision_m: 0.9877 - recall_m: 0.9578\n",
            "Epoch 53/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0240 - acc: 0.9979 - f1_m: 0.9961 - precision_m: 1.0000 - recall_m: 0.9927\n",
            "Epoch 54/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0544 - acc: 0.9815 - f1_m: 0.9546 - precision_m: 0.9824 - recall_m: 0.9342\n",
            "Epoch 55/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0399 - acc: 0.9877 - f1_m: 0.9649 - precision_m: 1.0000 - recall_m: 0.9356\n",
            "Epoch 56/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0332 - acc: 0.9959 - f1_m: 0.9748 - precision_m: 0.9877 - recall_m: 0.9646\n",
            "Epoch 57/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0352 - acc: 0.9918 - f1_m: 0.9599 - precision_m: 0.9877 - recall_m: 0.9376\n",
            "Epoch 58/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0257 - acc: 0.9938 - f1_m: 0.9803 - precision_m: 1.0000 - recall_m: 0.9643\n",
            "Epoch 59/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0424 - acc: 0.9877 - f1_m: 0.9497 - precision_m: 0.9782 - recall_m: 0.9300\n",
            "Epoch 60/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0396 - acc: 0.9918 - f1_m: 0.9719 - precision_m: 1.0000 - recall_m: 0.9504\n",
            "Epoch 61/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0487 - acc: 0.9856 - f1_m: 0.8916 - precision_m: 0.9268 - recall_m: 0.8656\n",
            "Epoch 62/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0298 - acc: 0.9959 - f1_m: 0.9917 - precision_m: 1.0000 - recall_m: 0.9845\n",
            "Epoch 63/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0214 - acc: 0.9877 - f1_m: 0.9507 - precision_m: 1.0000 - recall_m: 0.9160\n",
            "Epoch 64/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0268 - acc: 0.9897 - f1_m: 0.9629 - precision_m: 0.9918 - recall_m: 0.9428\n",
            "Epoch 65/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0212 - acc: 0.9979 - f1_m: 0.9940 - precision_m: 1.0000 - recall_m: 0.9890\n",
            "Epoch 66/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0478 - acc: 0.9897 - f1_m: 0.9561 - precision_m: 0.9745 - recall_m: 0.9453\n",
            "Epoch 67/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0401 - acc: 0.9877 - f1_m: 0.9588 - precision_m: 1.0000 - recall_m: 0.9323\n",
            "Epoch 68/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0232 - acc: 0.9918 - f1_m: 0.9039 - precision_m: 0.9124 - recall_m: 0.8979\n",
            "Epoch 69/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0401 - acc: 0.9897 - f1_m: 0.9493 - precision_m: 0.9877 - recall_m: 0.9246\n",
            "Epoch 70/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0244 - acc: 0.9938 - f1_m: 0.9839 - precision_m: 1.0000 - recall_m: 0.9704\n",
            "[LibLinear]Acc= 0.8204488778054863\n",
            "F1 Score= 0.8292627040783412\n",
            "Recall= 0.6595492616266255\n",
            "Tiempo de procesamiento (secs):217.69375729560852\n",
            "Chunks:5\n",
            "Max document length: 30000\n",
            "Vocabulary size: 96332\n",
            "Model: \"model_58\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_30 (InputLayer)        (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "embedding_30 (Embedding)     (None, 30000, 100)        9633200   \n",
            "_________________________________________________________________\n",
            "conv1d_59 (Conv1D)           (None, 30000, 32)         12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_30 (MaxPooling (None, 15000, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_60 (Conv1D)           (None, 15000, 32)         4128      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_30 (Glo (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,651,249\n",
            "Trainable params: 18,049\n",
            "Non-trainable params: 9,633,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/70\n",
            "486/486 [==============================] - 6s 13ms/step - loss: 0.5693 - acc: 0.7449 - f1_m: 0.1336 - precision_m: 0.1687 - recall_m: 0.1687\n",
            "Epoch 2/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.5140 - acc: 0.8251 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4655 - acc: 0.8210 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4645 - acc: 0.8292 - f1_m: 0.0188 - precision_m: 0.0658 - recall_m: 0.0110\n",
            "Epoch 5/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4339 - acc: 0.8251 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4090 - acc: 0.8292 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4009 - acc: 0.8354 - f1_m: 0.0483 - precision_m: 0.1317 - recall_m: 0.0296\n",
            "Epoch 8/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3880 - acc: 0.8436 - f1_m: 0.1755 - precision_m: 0.4609 - recall_m: 0.1126\n",
            "Epoch 9/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3860 - acc: 0.8395 - f1_m: 0.1198 - precision_m: 0.3292 - recall_m: 0.0779\n",
            "Epoch 10/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3732 - acc: 0.8457 - f1_m: 0.1397 - precision_m: 0.3292 - recall_m: 0.0913\n",
            "Epoch 11/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3718 - acc: 0.8374 - f1_m: 0.0922 - precision_m: 0.1646 - recall_m: 0.0666\n",
            "Epoch 12/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3389 - acc: 0.8560 - f1_m: 0.2930 - precision_m: 0.7901 - recall_m: 0.2046\n",
            "Epoch 13/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3359 - acc: 0.8580 - f1_m: 0.2694 - precision_m: 0.5597 - recall_m: 0.1864\n",
            "Epoch 14/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2909 - acc: 0.8827 - f1_m: 0.4527 - precision_m: 0.8573 - recall_m: 0.3278\n",
            "Epoch 15/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2745 - acc: 0.8971 - f1_m: 0.5171 - precision_m: 0.8066 - recall_m: 0.3961\n",
            "Epoch 16/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2497 - acc: 0.8909 - f1_m: 0.5536 - precision_m: 0.8387 - recall_m: 0.4302\n",
            "Epoch 17/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2579 - acc: 0.9012 - f1_m: 0.5497 - precision_m: 0.9122 - recall_m: 0.4235\n",
            "Epoch 18/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2162 - acc: 0.9239 - f1_m: 0.7489 - precision_m: 0.8841 - recall_m: 0.6979\n",
            "Epoch 19/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2202 - acc: 0.9136 - f1_m: 0.6744 - precision_m: 0.9108 - recall_m: 0.5784\n",
            "Epoch 20/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2102 - acc: 0.9300 - f1_m: 0.7025 - precision_m: 0.9218 - recall_m: 0.6013\n",
            "Epoch 21/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1755 - acc: 0.9342 - f1_m: 0.7271 - precision_m: 0.9572 - recall_m: 0.6276\n",
            "Epoch 22/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1627 - acc: 0.9486 - f1_m: 0.8082 - precision_m: 0.9774 - recall_m: 0.7069\n",
            "Epoch 23/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1559 - acc: 0.9506 - f1_m: 0.7684 - precision_m: 0.8903 - recall_m: 0.7250\n",
            "Epoch 24/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1525 - acc: 0.9486 - f1_m: 0.8195 - precision_m: 0.9868 - recall_m: 0.7396\n",
            "Epoch 25/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1159 - acc: 0.9671 - f1_m: 0.8955 - precision_m: 0.9868 - recall_m: 0.8342\n",
            "Epoch 26/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1309 - acc: 0.9630 - f1_m: 0.8546 - precision_m: 0.9577 - recall_m: 0.7942\n",
            "Epoch 27/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1088 - acc: 0.9733 - f1_m: 0.9012 - precision_m: 1.0000 - recall_m: 0.8403\n",
            "Epoch 28/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0861 - acc: 0.9835 - f1_m: 0.9432 - precision_m: 0.9877 - recall_m: 0.9084\n",
            "Epoch 29/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0992 - acc: 0.9733 - f1_m: 0.8931 - precision_m: 0.9429 - recall_m: 0.8573\n",
            "Epoch 30/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0995 - acc: 0.9671 - f1_m: 0.8523 - precision_m: 0.9781 - recall_m: 0.8033\n",
            "Epoch 31/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1078 - acc: 0.9733 - f1_m: 0.9037 - precision_m: 0.9835 - recall_m: 0.8578\n",
            "Epoch 32/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0810 - acc: 0.9794 - f1_m: 0.9386 - precision_m: 0.9811 - recall_m: 0.9044\n",
            "Epoch 33/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0805 - acc: 0.9753 - f1_m: 0.9158 - precision_m: 1.0000 - recall_m: 0.8570\n",
            "Epoch 34/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0919 - acc: 0.9753 - f1_m: 0.9284 - precision_m: 0.9671 - recall_m: 0.9100\n",
            "Epoch 35/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0639 - acc: 0.9835 - f1_m: 0.9402 - precision_m: 1.0000 - recall_m: 0.8945\n",
            "Epoch 36/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0740 - acc: 0.9815 - f1_m: 0.9159 - precision_m: 0.9712 - recall_m: 0.8809\n",
            "Epoch 37/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0661 - acc: 0.9835 - f1_m: 0.9549 - precision_m: 0.9835 - recall_m: 0.9351\n",
            "Epoch 38/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0934 - acc: 0.9774 - f1_m: 0.9236 - precision_m: 0.9835 - recall_m: 0.8789\n",
            "Epoch 39/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0686 - acc: 0.9835 - f1_m: 0.9497 - precision_m: 1.0000 - recall_m: 0.9116\n",
            "Epoch 40/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0573 - acc: 0.9794 - f1_m: 0.9321 - precision_m: 0.9927 - recall_m: 0.8897\n",
            "Epoch 41/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0615 - acc: 0.9815 - f1_m: 0.9377 - precision_m: 0.9835 - recall_m: 0.9078\n",
            "Epoch 42/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1009 - acc: 0.9691 - f1_m: 0.8909 - precision_m: 0.9300 - recall_m: 0.8657\n",
            "Epoch 43/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0787 - acc: 0.9856 - f1_m: 0.9463 - precision_m: 0.9781 - recall_m: 0.9346\n",
            "Epoch 44/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0571 - acc: 0.9918 - f1_m: 0.9643 - precision_m: 1.0000 - recall_m: 0.9424\n",
            "Epoch 45/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0573 - acc: 0.9856 - f1_m: 0.9457 - precision_m: 0.9781 - recall_m: 0.9276\n",
            "Epoch 46/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0627 - acc: 0.9712 - f1_m: 0.8813 - precision_m: 0.9218 - recall_m: 0.8563\n",
            "Epoch 47/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0452 - acc: 0.9856 - f1_m: 0.9325 - precision_m: 0.9877 - recall_m: 0.8951\n",
            "Epoch 48/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0419 - acc: 0.9938 - f1_m: 0.9719 - precision_m: 0.9877 - recall_m: 0.9606\n",
            "Epoch 49/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0473 - acc: 0.9897 - f1_m: 0.9547 - precision_m: 0.9877 - recall_m: 0.9304\n",
            "Epoch 50/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0540 - acc: 0.9877 - f1_m: 0.9608 - precision_m: 1.0000 - recall_m: 0.9319\n",
            "Epoch 51/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0603 - acc: 0.9815 - f1_m: 0.9420 - precision_m: 0.9767 - recall_m: 0.9133\n",
            "Epoch 52/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0327 - acc: 0.9959 - f1_m: 0.9787 - precision_m: 0.9877 - recall_m: 0.9709\n",
            "Epoch 53/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0262 - acc: 0.9938 - f1_m: 0.9886 - precision_m: 1.0000 - recall_m: 0.9794\n",
            "Epoch 54/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0486 - acc: 0.9815 - f1_m: 0.9438 - precision_m: 0.9762 - recall_m: 0.9195\n",
            "Epoch 55/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0334 - acc: 0.9938 - f1_m: 0.9823 - precision_m: 1.0000 - recall_m: 0.9676\n",
            "Epoch 56/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0337 - acc: 0.9897 - f1_m: 0.9509 - precision_m: 0.9712 - recall_m: 0.9387\n",
            "Epoch 57/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0298 - acc: 0.9918 - f1_m: 0.9577 - precision_m: 0.9712 - recall_m: 0.9507\n",
            "Epoch 58/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0325 - acc: 0.9897 - f1_m: 0.9723 - precision_m: 1.0000 - recall_m: 0.9505\n",
            "Epoch 59/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0424 - acc: 0.9918 - f1_m: 0.9597 - precision_m: 0.9877 - recall_m: 0.9372\n",
            "Epoch 60/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0398 - acc: 0.9918 - f1_m: 0.9747 - precision_m: 1.0000 - recall_m: 0.9561\n",
            "Epoch 61/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0402 - acc: 0.9897 - f1_m: 0.9086 - precision_m: 0.9248 - recall_m: 0.8990\n",
            "Epoch 62/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0437 - acc: 0.9877 - f1_m: 0.9641 - precision_m: 0.9781 - recall_m: 0.9586\n",
            "Epoch 63/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0309 - acc: 0.9918 - f1_m: 0.9649 - precision_m: 1.0000 - recall_m: 0.9385\n",
            "Epoch 64/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0311 - acc: 0.9877 - f1_m: 0.9453 - precision_m: 0.9906 - recall_m: 0.9193\n",
            "Epoch 65/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0267 - acc: 0.9979 - f1_m: 0.9940 - precision_m: 1.0000 - recall_m: 0.9890\n",
            "Epoch 66/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0401 - acc: 0.9877 - f1_m: 0.9565 - precision_m: 0.9767 - recall_m: 0.9393\n",
            "Epoch 67/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0335 - acc: 0.9897 - f1_m: 0.9713 - precision_m: 0.9906 - recall_m: 0.9570\n",
            "Epoch 68/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0256 - acc: 0.9877 - f1_m: 0.8867 - precision_m: 0.8992 - recall_m: 0.8800\n",
            "Epoch 69/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0230 - acc: 0.9918 - f1_m: 0.9512 - precision_m: 0.9877 - recall_m: 0.9289\n",
            "Epoch 70/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0200 - acc: 0.9979 - f1_m: 0.9927 - precision_m: 1.0000 - recall_m: 0.9868\n",
            "[LibLinear]Acc= 0.8254364089775561\n",
            "F1 Score= 0.8360036504688134\n",
            "Recall= 0.6869627507163324\n",
            "Tiempo de procesamiento (secs):219.83440589904785\n",
            "Chunks:6\n",
            "Max document length: 30000\n",
            "Vocabulary size: 96327\n",
            "Model: \"model_60\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_31 (InputLayer)        (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "embedding_31 (Embedding)     (None, 30000, 100)        9632700   \n",
            "_________________________________________________________________\n",
            "conv1d_61 (Conv1D)           (None, 30000, 32)         12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_31 (MaxPooling (None, 15000, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_62 (Conv1D)           (None, 15000, 32)         4128      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_31 (Glo (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,650,749\n",
            "Trainable params: 18,049\n",
            "Non-trainable params: 9,632,700\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/70\n",
            "486/486 [==============================] - 7s 14ms/step - loss: 0.5705 - acc: 0.7449 - f1_m: 0.1511 - precision_m: 0.1979 - recall_m: 0.1709\n",
            "Epoch 2/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.5147 - acc: 0.8272 - f1_m: 0.0408 - precision_m: 0.1317 - recall_m: 0.0241\n",
            "Epoch 3/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4647 - acc: 0.8210 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4625 - acc: 0.8272 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4292 - acc: 0.8313 - f1_m: 0.0165 - precision_m: 0.0658 - recall_m: 0.0094\n",
            "Epoch 6/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4101 - acc: 0.8292 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4032 - acc: 0.8354 - f1_m: 0.0598 - precision_m: 0.1975 - recall_m: 0.0357\n",
            "Epoch 8/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3875 - acc: 0.8416 - f1_m: 0.1499 - precision_m: 0.3621 - recall_m: 0.0988\n",
            "Epoch 9/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3855 - acc: 0.8416 - f1_m: 0.1198 - precision_m: 0.3292 - recall_m: 0.0779\n",
            "Epoch 10/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3776 - acc: 0.8374 - f1_m: 0.0702 - precision_m: 0.1975 - recall_m: 0.0435\n",
            "Epoch 11/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3738 - acc: 0.8416 - f1_m: 0.1251 - precision_m: 0.2634 - recall_m: 0.0831\n",
            "Epoch 12/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3430 - acc: 0.8477 - f1_m: 0.1886 - precision_m: 0.5267 - recall_m: 0.1388\n",
            "Epoch 13/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3444 - acc: 0.8519 - f1_m: 0.2003 - precision_m: 0.4280 - recall_m: 0.1344\n",
            "Epoch 14/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2969 - acc: 0.8704 - f1_m: 0.3673 - precision_m: 0.6543 - recall_m: 0.2710\n",
            "Epoch 15/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2843 - acc: 0.9012 - f1_m: 0.5168 - precision_m: 0.8560 - recall_m: 0.3867\n",
            "Epoch 16/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2517 - acc: 0.8930 - f1_m: 0.5402 - precision_m: 0.8683 - recall_m: 0.4152\n",
            "Epoch 17/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2692 - acc: 0.8807 - f1_m: 0.4501 - precision_m: 0.7915 - recall_m: 0.3377\n",
            "Epoch 18/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2230 - acc: 0.9300 - f1_m: 0.7369 - precision_m: 0.9781 - recall_m: 0.6370\n",
            "Epoch 19/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2238 - acc: 0.9136 - f1_m: 0.6644 - precision_m: 0.9311 - recall_m: 0.5699\n",
            "Epoch 20/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2092 - acc: 0.9342 - f1_m: 0.7146 - precision_m: 0.9136 - recall_m: 0.6187\n",
            "Epoch 21/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1766 - acc: 0.9424 - f1_m: 0.7657 - precision_m: 0.9890 - recall_m: 0.6651\n",
            "Epoch 22/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1667 - acc: 0.9527 - f1_m: 0.8134 - precision_m: 0.9630 - recall_m: 0.7266\n",
            "Epoch 23/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1584 - acc: 0.9465 - f1_m: 0.7532 - precision_m: 0.8824 - recall_m: 0.7140\n",
            "Epoch 24/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1516 - acc: 0.9568 - f1_m: 0.8524 - precision_m: 0.9737 - recall_m: 0.7924\n",
            "Epoch 25/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1117 - acc: 0.9712 - f1_m: 0.9120 - precision_m: 0.9927 - recall_m: 0.8595\n",
            "Epoch 26/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1259 - acc: 0.9588 - f1_m: 0.8413 - precision_m: 0.9868 - recall_m: 0.7541\n",
            "Epoch 27/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1224 - acc: 0.9568 - f1_m: 0.8423 - precision_m: 0.9890 - recall_m: 0.7628\n",
            "Epoch 28/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0853 - acc: 0.9877 - f1_m: 0.9483 - precision_m: 0.9877 - recall_m: 0.9173\n",
            "Epoch 29/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1023 - acc: 0.9712 - f1_m: 0.8797 - precision_m: 0.9671 - recall_m: 0.8195\n",
            "Epoch 30/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0875 - acc: 0.9753 - f1_m: 0.9112 - precision_m: 1.0000 - recall_m: 0.8511\n",
            "Epoch 31/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1186 - acc: 0.9733 - f1_m: 0.9082 - precision_m: 0.9835 - recall_m: 0.8655\n",
            "Epoch 32/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0868 - acc: 0.9815 - f1_m: 0.9340 - precision_m: 0.9712 - recall_m: 0.9117\n",
            "Epoch 33/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0717 - acc: 0.9794 - f1_m: 0.9345 - precision_m: 0.9741 - recall_m: 0.9050\n",
            "Epoch 34/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0905 - acc: 0.9835 - f1_m: 0.9576 - precision_m: 0.9835 - recall_m: 0.9437\n",
            "Epoch 35/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0625 - acc: 0.9835 - f1_m: 0.9412 - precision_m: 1.0000 - recall_m: 0.8952\n",
            "Epoch 36/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0687 - acc: 0.9856 - f1_m: 0.9293 - precision_m: 0.9877 - recall_m: 0.8905\n",
            "Epoch 37/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0531 - acc: 0.9918 - f1_m: 0.9726 - precision_m: 1.0000 - recall_m: 0.9515\n",
            "Epoch 38/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0822 - acc: 0.9815 - f1_m: 0.9404 - precision_m: 0.9835 - recall_m: 0.9065\n",
            "Epoch 39/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0700 - acc: 0.9856 - f1_m: 0.9568 - precision_m: 1.0000 - recall_m: 0.9226\n",
            "Epoch 40/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0582 - acc: 0.9856 - f1_m: 0.9490 - precision_m: 1.0000 - recall_m: 0.9106\n",
            "Epoch 41/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0643 - acc: 0.9815 - f1_m: 0.9467 - precision_m: 0.9835 - recall_m: 0.9236\n",
            "Epoch 42/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0997 - acc: 0.9753 - f1_m: 0.8951 - precision_m: 0.9584 - recall_m: 0.8531\n",
            "Epoch 43/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0841 - acc: 0.9856 - f1_m: 0.9476 - precision_m: 0.9671 - recall_m: 0.9429\n",
            "Epoch 44/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0735 - acc: 0.9856 - f1_m: 0.9498 - precision_m: 1.0000 - recall_m: 0.9166\n",
            "Epoch 45/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0671 - acc: 0.9856 - f1_m: 0.9483 - precision_m: 0.9781 - recall_m: 0.9298\n",
            "Epoch 46/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0611 - acc: 0.9794 - f1_m: 0.9118 - precision_m: 0.9684 - recall_m: 0.8739\n",
            "Epoch 47/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0457 - acc: 0.9856 - f1_m: 0.9458 - precision_m: 0.9877 - recall_m: 0.9126\n",
            "Epoch 48/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0414 - acc: 0.9897 - f1_m: 0.9572 - precision_m: 0.9877 - recall_m: 0.9326\n",
            "Epoch 49/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0525 - acc: 0.9877 - f1_m: 0.9521 - precision_m: 0.9811 - recall_m: 0.9304\n",
            "Epoch 50/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0596 - acc: 0.9877 - f1_m: 0.9599 - precision_m: 0.9927 - recall_m: 0.9380\n",
            "Epoch 51/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0709 - acc: 0.9753 - f1_m: 0.9288 - precision_m: 0.9490 - recall_m: 0.9176\n",
            "Epoch 52/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0549 - acc: 0.9835 - f1_m: 0.9453 - precision_m: 0.9757 - recall_m: 0.9215\n",
            "Epoch 53/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0304 - acc: 0.9938 - f1_m: 0.9836 - precision_m: 1.0000 - recall_m: 0.9702\n",
            "Epoch 54/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0523 - acc: 0.9835 - f1_m: 0.9485 - precision_m: 0.9868 - recall_m: 0.9241\n",
            "Epoch 55/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0409 - acc: 0.9918 - f1_m: 0.9750 - precision_m: 1.0000 - recall_m: 0.9545\n",
            "Epoch 56/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0385 - acc: 0.9918 - f1_m: 0.9527 - precision_m: 0.9745 - recall_m: 0.9398\n",
            "Epoch 57/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0506 - acc: 0.9835 - f1_m: 0.9202 - precision_m: 0.9767 - recall_m: 0.8889\n",
            "Epoch 58/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0268 - acc: 0.9979 - f1_m: 0.9949 - precision_m: 1.0000 - recall_m: 0.9906\n",
            "Epoch 59/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0454 - acc: 0.9877 - f1_m: 0.9490 - precision_m: 0.9745 - recall_m: 0.9317\n",
            "Epoch 60/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0418 - acc: 0.9897 - f1_m: 0.9680 - precision_m: 1.0000 - recall_m: 0.9430\n",
            "Epoch 61/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0388 - acc: 0.9897 - f1_m: 0.9126 - precision_m: 0.9248 - recall_m: 0.9040\n",
            "Epoch 62/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0360 - acc: 0.9897 - f1_m: 0.9773 - precision_m: 1.0000 - recall_m: 0.9583\n",
            "Epoch 63/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0286 - acc: 0.9877 - f1_m: 0.9507 - precision_m: 1.0000 - recall_m: 0.9160\n",
            "Epoch 64/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0320 - acc: 0.9938 - f1_m: 0.9761 - precision_m: 1.0000 - recall_m: 0.9577\n",
            "Epoch 65/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0247 - acc: 0.9938 - f1_m: 0.9818 - precision_m: 1.0000 - recall_m: 0.9686\n",
            "Epoch 66/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0521 - acc: 0.9835 - f1_m: 0.9378 - precision_m: 0.9651 - recall_m: 0.9212\n",
            "Epoch 67/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0298 - acc: 0.9959 - f1_m: 0.9862 - precision_m: 1.0000 - recall_m: 0.9753\n",
            "Epoch 68/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0287 - acc: 0.9959 - f1_m: 0.9124 - precision_m: 0.9218 - recall_m: 0.9053\n",
            "Epoch 69/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0323 - acc: 0.9877 - f1_m: 0.9512 - precision_m: 0.9767 - recall_m: 0.9304\n",
            "Epoch 70/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0257 - acc: 0.9938 - f1_m: 0.9839 - precision_m: 1.0000 - recall_m: 0.9704\n",
            "[LibLinear]Acc= 0.8154613466334164\n",
            "F1 Score= 0.825599247238697\n",
            "Recall= 0.6566839321137315\n",
            "Tiempo de procesamiento (secs):225.46923875808716\n",
            "Chunks:7\n",
            "Max document length: 30000\n",
            "Vocabulary size: 96325\n",
            "Model: \"model_62\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_32 (InputLayer)        (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "embedding_32 (Embedding)     (None, 30000, 100)        9632500   \n",
            "_________________________________________________________________\n",
            "conv1d_63 (Conv1D)           (None, 30000, 32)         12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_32 (MaxPooling (None, 15000, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_64 (Conv1D)           (None, 15000, 32)         4128      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_32 (Glo (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,650,549\n",
            "Trainable params: 18,049\n",
            "Non-trainable params: 9,632,500\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/70\n",
            "486/486 [==============================] - 7s 14ms/step - loss: 0.5584 - acc: 0.7593 - f1_m: 0.1276 - precision_m: 0.1919 - recall_m: 0.1318\n",
            "Epoch 2/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.5113 - acc: 0.8251 - f1_m: 0.0219 - precision_m: 0.0658 - recall_m: 0.0132\n",
            "Epoch 3/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4650 - acc: 0.8169 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4632 - acc: 0.8292 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4294 - acc: 0.8313 - f1_m: 0.0165 - precision_m: 0.0658 - recall_m: 0.0094\n",
            "Epoch 6/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4081 - acc: 0.8292 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3961 - acc: 0.8333 - f1_m: 0.0383 - precision_m: 0.1317 - recall_m: 0.0230\n",
            "Epoch 8/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3853 - acc: 0.8498 - f1_m: 0.2311 - precision_m: 0.5597 - recall_m: 0.1504\n",
            "Epoch 9/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3856 - acc: 0.8374 - f1_m: 0.0900 - precision_m: 0.2634 - recall_m: 0.0560\n",
            "Epoch 10/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3666 - acc: 0.8436 - f1_m: 0.1212 - precision_m: 0.2963 - recall_m: 0.0803\n",
            "Epoch 11/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3597 - acc: 0.8436 - f1_m: 0.1340 - precision_m: 0.2963 - recall_m: 0.0952\n",
            "Epoch 12/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3306 - acc: 0.8539 - f1_m: 0.2393 - precision_m: 0.6584 - recall_m: 0.1563\n",
            "Epoch 13/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3313 - acc: 0.8580 - f1_m: 0.2618 - precision_m: 0.5926 - recall_m: 0.1756\n",
            "Epoch 14/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2887 - acc: 0.8724 - f1_m: 0.4002 - precision_m: 0.7860 - recall_m: 0.2820\n",
            "Epoch 15/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2688 - acc: 0.9156 - f1_m: 0.6238 - precision_m: 0.9124 - recall_m: 0.4934\n",
            "Epoch 16/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2379 - acc: 0.9012 - f1_m: 0.6065 - precision_m: 0.8859 - recall_m: 0.4913\n",
            "Epoch 17/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2519 - acc: 0.8971 - f1_m: 0.5350 - precision_m: 0.8848 - recall_m: 0.4232\n",
            "Epoch 18/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2094 - acc: 0.9280 - f1_m: 0.7490 - precision_m: 0.9298 - recall_m: 0.6726\n",
            "Epoch 19/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2038 - acc: 0.9280 - f1_m: 0.7255 - precision_m: 0.9284 - recall_m: 0.6351\n",
            "Epoch 20/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1919 - acc: 0.9300 - f1_m: 0.7245 - precision_m: 0.9767 - recall_m: 0.6170\n",
            "Epoch 21/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1667 - acc: 0.9486 - f1_m: 0.7882 - precision_m: 0.9868 - recall_m: 0.6967\n",
            "Epoch 22/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1593 - acc: 0.9568 - f1_m: 0.8147 - precision_m: 0.9794 - recall_m: 0.7284\n",
            "Epoch 23/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1416 - acc: 0.9506 - f1_m: 0.7618 - precision_m: 0.8793 - recall_m: 0.7344\n",
            "Epoch 24/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1403 - acc: 0.9465 - f1_m: 0.8184 - precision_m: 0.9572 - recall_m: 0.7467\n",
            "Epoch 25/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1125 - acc: 0.9630 - f1_m: 0.8839 - precision_m: 1.0000 - recall_m: 0.8046\n",
            "Epoch 26/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1179 - acc: 0.9568 - f1_m: 0.8261 - precision_m: 0.9320 - recall_m: 0.7564\n",
            "Epoch 27/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1172 - acc: 0.9691 - f1_m: 0.8740 - precision_m: 1.0000 - recall_m: 0.8015\n",
            "Epoch 28/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0753 - acc: 0.9897 - f1_m: 0.9556 - precision_m: 0.9877 - recall_m: 0.9304\n",
            "Epoch 29/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0916 - acc: 0.9733 - f1_m: 0.8961 - precision_m: 0.9506 - recall_m: 0.8524\n",
            "Epoch 30/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0745 - acc: 0.9877 - f1_m: 0.9563 - precision_m: 1.0000 - recall_m: 0.9220\n",
            "Epoch 31/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1004 - acc: 0.9733 - f1_m: 0.9093 - precision_m: 0.9737 - recall_m: 0.8780\n",
            "Epoch 32/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0687 - acc: 0.9856 - f1_m: 0.9443 - precision_m: 0.9877 - recall_m: 0.9111\n",
            "Epoch 33/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0769 - acc: 0.9794 - f1_m: 0.9274 - precision_m: 0.9835 - recall_m: 0.8881\n",
            "Epoch 34/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0870 - acc: 0.9794 - f1_m: 0.9334 - precision_m: 0.9835 - recall_m: 0.9020\n",
            "Epoch 35/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0591 - acc: 0.9774 - f1_m: 0.9198 - precision_m: 1.0000 - recall_m: 0.8627\n",
            "Epoch 36/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0674 - acc: 0.9794 - f1_m: 0.8978 - precision_m: 0.9712 - recall_m: 0.8571\n",
            "Epoch 37/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0566 - acc: 0.9856 - f1_m: 0.9500 - precision_m: 1.0000 - recall_m: 0.9129\n",
            "Epoch 38/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0876 - acc: 0.9712 - f1_m: 0.9190 - precision_m: 0.9607 - recall_m: 0.8888\n",
            "Epoch 39/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0641 - acc: 0.9835 - f1_m: 0.9499 - precision_m: 0.9786 - recall_m: 0.9314\n",
            "Epoch 40/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0501 - acc: 0.9877 - f1_m: 0.9585 - precision_m: 1.0000 - recall_m: 0.9281\n",
            "Epoch 41/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0584 - acc: 0.9877 - f1_m: 0.9622 - precision_m: 1.0000 - recall_m: 0.9368\n",
            "Epoch 42/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0891 - acc: 0.9753 - f1_m: 0.9081 - precision_m: 0.9700 - recall_m: 0.8669\n",
            "Epoch 43/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0576 - acc: 0.9856 - f1_m: 0.9528 - precision_m: 0.9890 - recall_m: 0.9302\n",
            "Epoch 44/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0499 - acc: 0.9938 - f1_m: 0.9773 - precision_m: 1.0000 - recall_m: 0.9594\n",
            "Epoch 45/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0650 - acc: 0.9815 - f1_m: 0.9369 - precision_m: 0.9781 - recall_m: 0.9110\n",
            "Epoch 46/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0614 - acc: 0.9815 - f1_m: 0.9286 - precision_m: 0.9547 - recall_m: 0.9140\n",
            "Epoch 47/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0435 - acc: 0.9835 - f1_m: 0.9224 - precision_m: 0.9712 - recall_m: 0.8925\n",
            "Epoch 48/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0371 - acc: 0.9877 - f1_m: 0.9522 - precision_m: 0.9877 - recall_m: 0.9232\n",
            "Epoch 49/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0472 - acc: 0.9877 - f1_m: 0.9505 - precision_m: 0.9688 - recall_m: 0.9398\n",
            "Epoch 50/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0424 - acc: 0.9897 - f1_m: 0.9608 - precision_m: 0.9704 - recall_m: 0.9627\n",
            "Epoch 51/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0658 - acc: 0.9856 - f1_m: 0.9521 - precision_m: 0.9794 - recall_m: 0.9301\n",
            "Epoch 52/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0476 - acc: 0.9897 - f1_m: 0.9569 - precision_m: 0.9877 - recall_m: 0.9319\n",
            "Epoch 53/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0289 - acc: 0.9918 - f1_m: 0.9759 - precision_m: 1.0000 - recall_m: 0.9565\n",
            "Epoch 54/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0644 - acc: 0.9815 - f1_m: 0.9551 - precision_m: 0.9685 - recall_m: 0.9470\n",
            "Epoch 55/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0452 - acc: 0.9877 - f1_m: 0.9639 - precision_m: 1.0000 - recall_m: 0.9341\n",
            "Epoch 56/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0419 - acc: 0.9897 - f1_m: 0.9527 - precision_m: 0.9877 - recall_m: 0.9267\n",
            "Epoch 57/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0359 - acc: 0.9897 - f1_m: 0.9561 - precision_m: 0.9877 - recall_m: 0.9325\n",
            "Epoch 58/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0260 - acc: 0.9938 - f1_m: 0.9795 - precision_m: 0.9890 - recall_m: 0.9741\n",
            "Epoch 59/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0359 - acc: 0.9897 - f1_m: 0.9576 - precision_m: 0.9877 - recall_m: 0.9339\n",
            "Epoch 60/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0365 - acc: 0.9918 - f1_m: 0.9812 - precision_m: 1.0000 - recall_m: 0.9650\n",
            "Epoch 61/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0475 - acc: 0.9835 - f1_m: 0.8876 - precision_m: 0.9342 - recall_m: 0.8552\n",
            "Epoch 62/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0453 - acc: 0.9897 - f1_m: 0.9731 - precision_m: 0.9774 - recall_m: 0.9730\n",
            "Epoch 63/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0230 - acc: 0.9918 - f1_m: 0.9631 - precision_m: 0.9781 - recall_m: 0.9605\n",
            "Epoch 64/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0221 - acc: 0.9918 - f1_m: 0.9569 - precision_m: 1.0000 - recall_m: 0.9373\n",
            "Epoch 65/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0213 - acc: 0.9938 - f1_m: 0.9818 - precision_m: 1.0000 - recall_m: 0.9686\n",
            "Epoch 66/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0440 - acc: 0.9856 - f1_m: 0.9472 - precision_m: 0.9635 - recall_m: 0.9359\n",
            "Epoch 67/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0338 - acc: 0.9877 - f1_m: 0.9588 - precision_m: 1.0000 - recall_m: 0.9323\n",
            "Epoch 68/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0286 - acc: 0.9938 - f1_m: 0.8948 - precision_m: 0.9053 - recall_m: 0.8916\n",
            "Epoch 69/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0314 - acc: 0.9897 - f1_m: 0.9452 - precision_m: 0.9767 - recall_m: 0.9289\n",
            "Epoch 70/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0200 - acc: 0.9959 - f1_m: 0.9912 - precision_m: 1.0000 - recall_m: 0.9835\n",
            "[LibLinear]Acc= 0.8129675810473815\n",
            "F1 Score= 0.8267171092391505\n",
            "Recall= 0.6797994269340975\n",
            "Tiempo de procesamiento (secs):232.16450142860413\n",
            "Chunks:8\n",
            "Max document length: 30000\n",
            "Vocabulary size: 96328\n",
            "Model: \"model_64\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_33 (InputLayer)        (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "embedding_33 (Embedding)     (None, 30000, 100)        9632800   \n",
            "_________________________________________________________________\n",
            "conv1d_65 (Conv1D)           (None, 30000, 32)         12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_33 (MaxPooling (None, 15000, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_66 (Conv1D)           (None, 15000, 32)         4128      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_33 (Glo (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,650,849\n",
            "Trainable params: 18,049\n",
            "Non-trainable params: 9,632,800\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/70\n",
            "486/486 [==============================] - 7s 14ms/step - loss: 0.5589 - acc: 0.7551 - f1_m: 0.1267 - precision_m: 0.1912 - recall_m: 0.1318\n",
            "Epoch 2/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.5102 - acc: 0.8251 - f1_m: 0.0376 - precision_m: 0.0988 - recall_m: 0.0241\n",
            "Epoch 3/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4636 - acc: 0.8210 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4617 - acc: 0.8292 - f1_m: 0.0188 - precision_m: 0.0658 - recall_m: 0.0110\n",
            "Epoch 5/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4300 - acc: 0.8313 - f1_m: 0.0165 - precision_m: 0.0658 - recall_m: 0.0094\n",
            "Epoch 6/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4056 - acc: 0.8292 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3981 - acc: 0.8354 - f1_m: 0.0483 - precision_m: 0.1317 - recall_m: 0.0296\n",
            "Epoch 8/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3861 - acc: 0.8374 - f1_m: 0.1097 - precision_m: 0.3292 - recall_m: 0.0687\n",
            "Epoch 9/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3876 - acc: 0.8416 - f1_m: 0.1164 - precision_m: 0.3292 - recall_m: 0.0724\n",
            "Epoch 10/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3711 - acc: 0.8395 - f1_m: 0.0702 - precision_m: 0.1975 - recall_m: 0.0435\n",
            "Epoch 11/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3708 - acc: 0.8416 - f1_m: 0.1286 - precision_m: 0.3292 - recall_m: 0.0819\n",
            "Epoch 12/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3342 - acc: 0.8539 - f1_m: 0.2695 - precision_m: 0.6584 - recall_m: 0.1920\n",
            "Epoch 13/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3368 - acc: 0.8560 - f1_m: 0.2788 - precision_m: 0.5926 - recall_m: 0.1908\n",
            "Epoch 14/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2894 - acc: 0.8765 - f1_m: 0.4419 - precision_m: 0.8519 - recall_m: 0.3171\n",
            "Epoch 15/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2766 - acc: 0.8971 - f1_m: 0.5171 - precision_m: 0.8099 - recall_m: 0.3926\n",
            "Epoch 16/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2411 - acc: 0.8992 - f1_m: 0.5620 - precision_m: 0.8260 - recall_m: 0.4506\n",
            "Epoch 17/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2575 - acc: 0.8971 - f1_m: 0.5267 - precision_m: 0.8771 - recall_m: 0.4202\n",
            "Epoch 18/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2127 - acc: 0.9218 - f1_m: 0.7280 - precision_m: 0.8868 - recall_m: 0.6671\n",
            "Epoch 19/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2127 - acc: 0.9280 - f1_m: 0.7343 - precision_m: 0.9217 - recall_m: 0.6509\n",
            "Epoch 20/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2011 - acc: 0.9342 - f1_m: 0.7182 - precision_m: 0.9877 - recall_m: 0.6049\n",
            "Epoch 21/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1732 - acc: 0.9486 - f1_m: 0.8099 - precision_m: 0.9737 - recall_m: 0.7186\n",
            "Epoch 22/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1691 - acc: 0.9444 - f1_m: 0.7868 - precision_m: 0.9663 - recall_m: 0.6835\n",
            "Epoch 23/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1552 - acc: 0.9465 - f1_m: 0.7625 - precision_m: 0.8824 - recall_m: 0.7346\n",
            "Epoch 24/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1514 - acc: 0.9424 - f1_m: 0.7879 - precision_m: 0.9737 - recall_m: 0.6934\n",
            "Epoch 25/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1174 - acc: 0.9630 - f1_m: 0.8881 - precision_m: 1.0000 - recall_m: 0.8095\n",
            "Epoch 26/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1198 - acc: 0.9691 - f1_m: 0.8877 - precision_m: 0.9671 - recall_m: 0.8409\n",
            "Epoch 27/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1109 - acc: 0.9712 - f1_m: 0.8910 - precision_m: 0.9890 - recall_m: 0.8354\n",
            "Epoch 28/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0815 - acc: 0.9918 - f1_m: 0.9606 - precision_m: 0.9877 - recall_m: 0.9398\n",
            "Epoch 29/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0975 - acc: 0.9691 - f1_m: 0.8797 - precision_m: 0.9671 - recall_m: 0.8199\n",
            "Epoch 30/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0842 - acc: 0.9774 - f1_m: 0.9146 - precision_m: 0.9781 - recall_m: 0.8785\n",
            "Epoch 31/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1131 - acc: 0.9753 - f1_m: 0.9152 - precision_m: 0.9737 - recall_m: 0.8874\n",
            "Epoch 32/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0775 - acc: 0.9856 - f1_m: 0.9445 - precision_m: 0.9877 - recall_m: 0.9123\n",
            "Epoch 33/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0772 - acc: 0.9671 - f1_m: 0.8955 - precision_m: 0.9630 - recall_m: 0.8527\n",
            "Epoch 34/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0933 - acc: 0.9774 - f1_m: 0.9324 - precision_m: 0.9781 - recall_m: 0.8990\n",
            "Epoch 35/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0620 - acc: 0.9856 - f1_m: 0.9475 - precision_m: 0.9918 - recall_m: 0.9199\n",
            "Epoch 36/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0606 - acc: 0.9835 - f1_m: 0.9357 - precision_m: 0.9712 - recall_m: 0.9102\n",
            "Epoch 37/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0560 - acc: 0.9877 - f1_m: 0.9610 - precision_m: 0.9918 - recall_m: 0.9406\n",
            "Epoch 38/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0841 - acc: 0.9794 - f1_m: 0.9344 - precision_m: 0.9835 - recall_m: 0.8955\n",
            "Epoch 39/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0659 - acc: 0.9794 - f1_m: 0.9365 - precision_m: 0.9906 - recall_m: 0.8951\n",
            "Epoch 40/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0528 - acc: 0.9856 - f1_m: 0.9548 - precision_m: 0.9927 - recall_m: 0.9259\n",
            "Epoch 41/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0597 - acc: 0.9835 - f1_m: 0.9471 - precision_m: 1.0000 - recall_m: 0.9078\n",
            "Epoch 42/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0801 - acc: 0.9712 - f1_m: 0.8937 - precision_m: 0.9700 - recall_m: 0.8422\n",
            "Epoch 43/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0586 - acc: 0.9856 - f1_m: 0.9424 - precision_m: 0.9781 - recall_m: 0.9232\n",
            "Epoch 44/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0497 - acc: 0.9897 - f1_m: 0.9563 - precision_m: 0.9835 - recall_m: 0.9445\n",
            "Epoch 45/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0653 - acc: 0.9774 - f1_m: 0.9194 - precision_m: 0.9484 - recall_m: 0.9072\n",
            "Epoch 46/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0513 - acc: 0.9856 - f1_m: 0.9169 - precision_m: 0.9547 - recall_m: 0.8900\n",
            "Epoch 47/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0414 - acc: 0.9856 - f1_m: 0.9356 - precision_m: 0.9877 - recall_m: 0.8999\n",
            "Epoch 48/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0454 - acc: 0.9877 - f1_m: 0.9441 - precision_m: 0.9877 - recall_m: 0.9106\n",
            "Epoch 49/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0463 - acc: 0.9835 - f1_m: 0.9387 - precision_m: 0.9811 - recall_m: 0.9085\n",
            "Epoch 50/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0464 - acc: 0.9918 - f1_m: 0.9748 - precision_m: 1.0000 - recall_m: 0.9572\n",
            "Epoch 51/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0613 - acc: 0.9835 - f1_m: 0.9451 - precision_m: 0.9877 - recall_m: 0.9133\n",
            "Epoch 52/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0373 - acc: 0.9938 - f1_m: 0.9756 - precision_m: 0.9817 - recall_m: 0.9709\n",
            "Epoch 53/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0261 - acc: 0.9959 - f1_m: 0.9867 - precision_m: 1.0000 - recall_m: 0.9762\n",
            "Epoch 54/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0373 - acc: 0.9877 - f1_m: 0.9675 - precision_m: 1.0000 - recall_m: 0.9415\n",
            "Epoch 55/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0375 - acc: 0.9877 - f1_m: 0.9624 - precision_m: 1.0000 - recall_m: 0.9329\n",
            "Epoch 56/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0321 - acc: 0.9938 - f1_m: 0.9563 - precision_m: 0.9657 - recall_m: 0.9492\n",
            "Epoch 57/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0353 - acc: 0.9877 - f1_m: 0.9412 - precision_m: 0.9877 - recall_m: 0.9101\n",
            "Epoch 58/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0295 - acc: 0.9959 - f1_m: 0.9855 - precision_m: 1.0000 - recall_m: 0.9741\n",
            "Epoch 59/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0368 - acc: 0.9897 - f1_m: 0.9606 - precision_m: 0.9782 - recall_m: 0.9481\n",
            "Epoch 60/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0446 - acc: 0.9856 - f1_m: 0.9614 - precision_m: 1.0000 - recall_m: 0.9293\n",
            "Epoch 61/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0574 - acc: 0.9733 - f1_m: 0.8544 - precision_m: 0.9092 - recall_m: 0.8223\n",
            "Epoch 62/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0494 - acc: 0.9877 - f1_m: 0.9662 - precision_m: 1.0000 - recall_m: 0.9382\n",
            "Epoch 63/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0303 - acc: 0.9877 - f1_m: 0.9448 - precision_m: 0.9781 - recall_m: 0.9291\n",
            "Epoch 64/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0372 - acc: 0.9897 - f1_m: 0.9665 - precision_m: 0.9835 - recall_m: 0.9592\n",
            "Epoch 65/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0295 - acc: 0.9918 - f1_m: 0.9722 - precision_m: 0.9868 - recall_m: 0.9632\n",
            "Epoch 66/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0510 - acc: 0.9877 - f1_m: 0.9542 - precision_m: 0.9745 - recall_m: 0.9393\n",
            "Epoch 67/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0449 - acc: 0.9815 - f1_m: 0.9462 - precision_m: 0.9812 - recall_m: 0.9298\n",
            "Epoch 68/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0727 - acc: 0.9733 - f1_m: 0.8402 - precision_m: 0.8959 - recall_m: 0.8078\n",
            "Epoch 69/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0501 - acc: 0.9835 - f1_m: 0.9425 - precision_m: 0.9584 - recall_m: 0.9380\n",
            "Epoch 70/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0399 - acc: 0.9856 - f1_m: 0.9548 - precision_m: 0.9704 - recall_m: 0.9478\n",
            "[LibLinear]Acc= 0.8354114713216958\n",
            "F1 Score= 0.8434908120718128\n",
            "Recall= 0.6926934097421203\n",
            "Tiempo de procesamiento (secs):237.1847174167633\n",
            "Chunks:9\n",
            "Max document length: 30000\n",
            "Vocabulary size: 96336\n",
            "Model: \"model_66\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_34 (InputLayer)        (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "embedding_34 (Embedding)     (None, 30000, 100)        9633600   \n",
            "_________________________________________________________________\n",
            "conv1d_67 (Conv1D)           (None, 30000, 32)         12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_34 (MaxPooling (None, 15000, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_68 (Conv1D)           (None, 15000, 32)         4128      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_34 (Glo (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,651,649\n",
            "Trainable params: 18,049\n",
            "Non-trainable params: 9,633,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/70\n",
            "486/486 [==============================] - 7s 15ms/step - loss: 0.5580 - acc: 0.7551 - f1_m: 0.1312 - precision_m: 0.1820 - recall_m: 0.1510\n",
            "Epoch 2/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.5117 - acc: 0.8272 - f1_m: 0.0219 - precision_m: 0.0658 - recall_m: 0.0132\n",
            "Epoch 3/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4671 - acc: 0.8210 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4657 - acc: 0.8292 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4325 - acc: 0.8333 - f1_m: 0.0293 - precision_m: 0.0658 - recall_m: 0.0188\n",
            "Epoch 6/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4067 - acc: 0.8292 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3976 - acc: 0.8354 - f1_m: 0.0483 - precision_m: 0.1317 - recall_m: 0.0296\n",
            "Epoch 8/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3893 - acc: 0.8457 - f1_m: 0.1865 - precision_m: 0.4938 - recall_m: 0.1202\n",
            "Epoch 9/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3892 - acc: 0.8416 - f1_m: 0.1198 - precision_m: 0.3292 - recall_m: 0.0779\n",
            "Epoch 10/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3698 - acc: 0.8436 - f1_m: 0.1690 - precision_m: 0.3951 - recall_m: 0.1115\n",
            "Epoch 11/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3698 - acc: 0.8436 - f1_m: 0.1340 - precision_m: 0.2963 - recall_m: 0.0952\n",
            "Epoch 12/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3367 - acc: 0.8539 - f1_m: 0.2764 - precision_m: 0.6584 - recall_m: 0.1877\n",
            "Epoch 13/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3355 - acc: 0.8580 - f1_m: 0.2645 - precision_m: 0.5597 - recall_m: 0.1817\n",
            "Epoch 14/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2955 - acc: 0.8765 - f1_m: 0.3874 - precision_m: 0.7235 - recall_m: 0.2834\n",
            "Epoch 15/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2774 - acc: 0.8992 - f1_m: 0.5259 - precision_m: 0.7956 - recall_m: 0.4093\n",
            "Epoch 16/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2479 - acc: 0.8889 - f1_m: 0.5488 - precision_m: 0.8716 - recall_m: 0.4204\n",
            "Epoch 17/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2630 - acc: 0.8848 - f1_m: 0.4876 - precision_m: 0.8450 - recall_m: 0.3633\n",
            "Epoch 18/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2228 - acc: 0.9218 - f1_m: 0.7281 - precision_m: 0.9254 - recall_m: 0.6491\n",
            "Epoch 19/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2193 - acc: 0.9177 - f1_m: 0.6600 - precision_m: 0.8708 - recall_m: 0.5757\n",
            "Epoch 20/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2069 - acc: 0.9300 - f1_m: 0.6904 - precision_m: 0.9218 - recall_m: 0.5753\n",
            "Epoch 21/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1804 - acc: 0.9383 - f1_m: 0.7463 - precision_m: 0.9868 - recall_m: 0.6447\n",
            "Epoch 22/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1750 - acc: 0.9465 - f1_m: 0.8020 - precision_m: 0.9774 - recall_m: 0.7041\n",
            "Epoch 23/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1492 - acc: 0.9465 - f1_m: 0.7799 - precision_m: 0.9232 - recall_m: 0.7541\n",
            "Epoch 24/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1539 - acc: 0.9527 - f1_m: 0.8424 - precision_m: 0.9631 - recall_m: 0.7744\n",
            "Epoch 25/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1116 - acc: 0.9671 - f1_m: 0.8904 - precision_m: 1.0000 - recall_m: 0.8228\n",
            "Epoch 26/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1244 - acc: 0.9712 - f1_m: 0.8674 - precision_m: 0.9342 - recall_m: 0.8196\n",
            "Epoch 27/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1151 - acc: 0.9712 - f1_m: 0.8805 - precision_m: 0.9835 - recall_m: 0.8186\n",
            "Epoch 28/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0795 - acc: 0.9897 - f1_m: 0.9556 - precision_m: 0.9877 - recall_m: 0.9304\n",
            "Epoch 29/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0952 - acc: 0.9691 - f1_m: 0.8729 - precision_m: 0.9671 - recall_m: 0.8107\n",
            "Epoch 30/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0897 - acc: 0.9733 - f1_m: 0.8984 - precision_m: 0.9657 - recall_m: 0.8556\n",
            "Epoch 31/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1211 - acc: 0.9671 - f1_m: 0.8889 - precision_m: 0.9610 - recall_m: 0.8517\n",
            "Epoch 32/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0958 - acc: 0.9815 - f1_m: 0.9385 - precision_m: 0.9877 - recall_m: 0.8998\n",
            "Epoch 33/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0990 - acc: 0.9650 - f1_m: 0.8897 - precision_m: 0.9918 - recall_m: 0.8198\n",
            "Epoch 34/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0845 - acc: 0.9733 - f1_m: 0.9190 - precision_m: 0.9835 - recall_m: 0.8807\n",
            "Epoch 35/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0595 - acc: 0.9877 - f1_m: 0.9540 - precision_m: 1.0000 - recall_m: 0.9243\n",
            "Epoch 36/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0660 - acc: 0.9794 - f1_m: 0.9066 - precision_m: 0.9877 - recall_m: 0.8553\n",
            "Epoch 37/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0505 - acc: 0.9918 - f1_m: 0.9726 - precision_m: 1.0000 - recall_m: 0.9515\n",
            "Epoch 38/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0760 - acc: 0.9774 - f1_m: 0.9291 - precision_m: 1.0000 - recall_m: 0.8729\n",
            "Epoch 39/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0626 - acc: 0.9835 - f1_m: 0.9465 - precision_m: 0.9918 - recall_m: 0.9128\n",
            "Epoch 40/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0496 - acc: 0.9856 - f1_m: 0.9430 - precision_m: 1.0000 - recall_m: 0.8996\n",
            "Epoch 41/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0549 - acc: 0.9794 - f1_m: 0.9335 - precision_m: 0.9835 - recall_m: 0.9016\n",
            "Epoch 42/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0956 - acc: 0.9753 - f1_m: 0.9071 - precision_m: 0.9627 - recall_m: 0.8778\n",
            "Epoch 43/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0766 - acc: 0.9794 - f1_m: 0.9181 - precision_m: 0.9781 - recall_m: 0.8903\n",
            "Epoch 44/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0545 - acc: 0.9979 - f1_m: 0.9906 - precision_m: 1.0000 - recall_m: 0.9835\n",
            "Epoch 45/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0671 - acc: 0.9753 - f1_m: 0.9192 - precision_m: 0.9649 - recall_m: 0.8906\n",
            "Epoch 46/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0650 - acc: 0.9794 - f1_m: 0.9234 - precision_m: 0.9359 - recall_m: 0.9239\n",
            "Epoch 47/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0563 - acc: 0.9835 - f1_m: 0.9238 - precision_m: 0.9767 - recall_m: 0.8891\n",
            "Epoch 48/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0463 - acc: 0.9918 - f1_m: 0.9646 - precision_m: 0.9877 - recall_m: 0.9457\n",
            "Epoch 49/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0483 - acc: 0.9897 - f1_m: 0.9549 - precision_m: 0.9782 - recall_m: 0.9398\n",
            "Epoch 50/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0463 - acc: 0.9877 - f1_m: 0.9608 - precision_m: 0.9868 - recall_m: 0.9451\n",
            "Epoch 51/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0591 - acc: 0.9835 - f1_m: 0.9480 - precision_m: 0.9782 - recall_m: 0.9249\n",
            "Epoch 52/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0448 - acc: 0.9897 - f1_m: 0.9629 - precision_m: 0.9877 - recall_m: 0.9418\n",
            "Epoch 53/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0314 - acc: 0.9918 - f1_m: 0.9620 - precision_m: 1.0000 - recall_m: 0.9380\n",
            "Epoch 54/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0422 - acc: 0.9856 - f1_m: 0.9555 - precision_m: 0.9835 - recall_m: 0.9332\n",
            "Epoch 55/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0318 - acc: 0.9918 - f1_m: 0.9750 - precision_m: 1.0000 - recall_m: 0.9545\n",
            "Epoch 56/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0358 - acc: 0.9897 - f1_m: 0.9543 - precision_m: 0.9712 - recall_m: 0.9442\n",
            "Epoch 57/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0309 - acc: 0.9918 - f1_m: 0.9612 - precision_m: 0.9877 - recall_m: 0.9398\n",
            "Epoch 58/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0258 - acc: 0.9938 - f1_m: 0.9855 - precision_m: 1.0000 - recall_m: 0.9730\n",
            "Epoch 59/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0420 - acc: 0.9897 - f1_m: 0.9583 - precision_m: 0.9794 - recall_m: 0.9421\n",
            "Epoch 60/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0364 - acc: 0.9897 - f1_m: 0.9646 - precision_m: 1.0000 - recall_m: 0.9376\n",
            "Epoch 61/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0404 - acc: 0.9856 - f1_m: 0.8893 - precision_m: 0.9122 - recall_m: 0.8790\n",
            "Epoch 62/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0428 - acc: 0.9856 - f1_m: 0.9564 - precision_m: 0.9643 - recall_m: 0.9565\n",
            "Epoch 63/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0251 - acc: 0.9938 - f1_m: 0.9785 - precision_m: 1.0000 - recall_m: 0.9643\n",
            "Epoch 64/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0228 - acc: 0.9938 - f1_m: 0.9767 - precision_m: 0.9906 - recall_m: 0.9686\n",
            "Epoch 65/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0169 - acc: 0.9959 - f1_m: 0.9890 - precision_m: 1.0000 - recall_m: 0.9812\n",
            "Epoch 66/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0556 - acc: 0.9897 - f1_m: 0.9574 - precision_m: 0.9877 - recall_m: 0.9344\n",
            "Epoch 67/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0316 - acc: 0.9918 - f1_m: 0.9763 - precision_m: 1.0000 - recall_m: 0.9570\n",
            "Epoch 68/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0333 - acc: 0.9897 - f1_m: 0.8947 - precision_m: 0.9030 - recall_m: 0.8920\n",
            "Epoch 69/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0335 - acc: 0.9897 - f1_m: 0.9503 - precision_m: 0.9877 - recall_m: 0.9261\n",
            "Epoch 70/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0214 - acc: 0.9959 - f1_m: 0.9912 - precision_m: 1.0000 - recall_m: 0.9835\n",
            "[LibLinear]Acc= 0.8229426433915212\n",
            "F1 Score= 0.8341405666599095\n",
            "Recall= 0.6855300859598854\n",
            "Tiempo de procesamiento (secs):244.38478469848633\n",
            "Chunks:10\n",
            "Max document length: 30000\n",
            "Vocabulary size: 96330\n",
            "Model: \"model_68\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_35 (InputLayer)        (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "embedding_35 (Embedding)     (None, 30000, 100)        9633000   \n",
            "_________________________________________________________________\n",
            "conv1d_69 (Conv1D)           (None, 30000, 32)         12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_35 (MaxPooling (None, 15000, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_70 (Conv1D)           (None, 15000, 32)         4128      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_35 (Glo (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,651,049\n",
            "Trainable params: 18,049\n",
            "Non-trainable params: 9,633,000\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/70\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5592 - acc: 0.7593 - f1_m: 0.1365 - precision_m: 0.1886 - recall_m: 0.1522\n",
            "Epoch 2/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.5100 - acc: 0.8251 - f1_m: 0.0188 - precision_m: 0.0329 - recall_m: 0.0132\n",
            "Epoch 3/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4678 - acc: 0.8189 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4649 - acc: 0.8292 - f1_m: 0.0263 - precision_m: 0.0658 - recall_m: 0.0165\n",
            "Epoch 5/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4323 - acc: 0.8313 - f1_m: 0.0165 - precision_m: 0.0658 - recall_m: 0.0094\n",
            "Epoch 6/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.4089 - acc: 0.8292 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3966 - acc: 0.8333 - f1_m: 0.0383 - precision_m: 0.1317 - recall_m: 0.0230\n",
            "Epoch 8/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3934 - acc: 0.8395 - f1_m: 0.1678 - precision_m: 0.3951 - recall_m: 0.1163\n",
            "Epoch 9/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3905 - acc: 0.8395 - f1_m: 0.1010 - precision_m: 0.2634 - recall_m: 0.0669\n",
            "Epoch 10/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3773 - acc: 0.8395 - f1_m: 0.0658 - precision_m: 0.1317 - recall_m: 0.0447\n",
            "Epoch 11/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3694 - acc: 0.8395 - f1_m: 0.1073 - precision_m: 0.2634 - recall_m: 0.0682\n",
            "Epoch 12/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3413 - acc: 0.8539 - f1_m: 0.2578 - precision_m: 0.6584 - recall_m: 0.1838\n",
            "Epoch 13/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.3346 - acc: 0.8621 - f1_m: 0.2990 - precision_m: 0.6255 - recall_m: 0.2058\n",
            "Epoch 14/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2927 - acc: 0.8827 - f1_m: 0.4694 - precision_m: 0.7860 - recall_m: 0.3526\n",
            "Epoch 15/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2797 - acc: 0.9033 - f1_m: 0.5784 - precision_m: 0.8757 - recall_m: 0.4410\n",
            "Epoch 16/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2478 - acc: 0.9012 - f1_m: 0.5907 - precision_m: 0.8699 - recall_m: 0.4753\n",
            "Epoch 17/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2576 - acc: 0.8971 - f1_m: 0.5183 - precision_m: 0.8519 - recall_m: 0.4136\n",
            "Epoch 18/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2177 - acc: 0.9321 - f1_m: 0.7357 - precision_m: 0.9390 - recall_m: 0.6408\n",
            "Epoch 19/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2154 - acc: 0.9198 - f1_m: 0.7068 - precision_m: 0.9021 - recall_m: 0.6212\n",
            "Epoch 20/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.2057 - acc: 0.9239 - f1_m: 0.6619 - precision_m: 0.9108 - recall_m: 0.5582\n",
            "Epoch 21/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1786 - acc: 0.9424 - f1_m: 0.7781 - precision_m: 1.0000 - recall_m: 0.6641\n",
            "Epoch 22/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1741 - acc: 0.9465 - f1_m: 0.7903 - precision_m: 0.9575 - recall_m: 0.6908\n",
            "Epoch 23/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1485 - acc: 0.9527 - f1_m: 0.7429 - precision_m: 0.8573 - recall_m: 0.6759\n",
            "Epoch 24/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1557 - acc: 0.9506 - f1_m: 0.8060 - precision_m: 0.9210 - recall_m: 0.7336\n",
            "Epoch 25/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1165 - acc: 0.9588 - f1_m: 0.8707 - precision_m: 0.9906 - recall_m: 0.8001\n",
            "Epoch 26/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1287 - acc: 0.9650 - f1_m: 0.8370 - precision_m: 0.9045 - recall_m: 0.7861\n",
            "Epoch 27/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1077 - acc: 0.9691 - f1_m: 0.8815 - precision_m: 0.9906 - recall_m: 0.8206\n",
            "Epoch 28/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0848 - acc: 0.9877 - f1_m: 0.9497 - precision_m: 0.9877 - recall_m: 0.9210\n",
            "Epoch 29/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1066 - acc: 0.9691 - f1_m: 0.8710 - precision_m: 0.9671 - recall_m: 0.8107\n",
            "Epoch 30/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0986 - acc: 0.9630 - f1_m: 0.8397 - precision_m: 0.9657 - recall_m: 0.7777\n",
            "Epoch 31/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.1322 - acc: 0.9609 - f1_m: 0.8633 - precision_m: 0.9533 - recall_m: 0.8297\n",
            "Epoch 32/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0892 - acc: 0.9877 - f1_m: 0.9573 - precision_m: 0.9877 - recall_m: 0.9330\n",
            "Epoch 33/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0921 - acc: 0.9753 - f1_m: 0.9201 - precision_m: 1.0000 - recall_m: 0.8641\n",
            "Epoch 34/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0902 - acc: 0.9753 - f1_m: 0.9263 - precision_m: 0.9835 - recall_m: 0.8925\n",
            "Epoch 35/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0620 - acc: 0.9774 - f1_m: 0.9201 - precision_m: 1.0000 - recall_m: 0.8677\n",
            "Epoch 36/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0646 - acc: 0.9815 - f1_m: 0.9073 - precision_m: 0.9712 - recall_m: 0.8730\n",
            "Epoch 37/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0629 - acc: 0.9835 - f1_m: 0.9472 - precision_m: 0.9918 - recall_m: 0.9202\n",
            "Epoch 38/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0845 - acc: 0.9815 - f1_m: 0.9424 - precision_m: 1.0000 - recall_m: 0.8971\n",
            "Epoch 39/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0680 - acc: 0.9835 - f1_m: 0.9519 - precision_m: 0.9906 - recall_m: 0.9226\n",
            "Epoch 40/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0529 - acc: 0.9877 - f1_m: 0.9545 - precision_m: 0.9927 - recall_m: 0.9270\n",
            "Epoch 41/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0576 - acc: 0.9815 - f1_m: 0.9379 - precision_m: 1.0000 - recall_m: 0.8947\n",
            "Epoch 42/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0700 - acc: 0.9815 - f1_m: 0.9228 - precision_m: 0.9794 - recall_m: 0.8861\n",
            "Epoch 43/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0691 - acc: 0.9856 - f1_m: 0.9476 - precision_m: 0.9781 - recall_m: 0.9320\n",
            "Epoch 44/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0558 - acc: 0.9897 - f1_m: 0.9636 - precision_m: 1.0000 - recall_m: 0.9417\n",
            "Epoch 45/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0652 - acc: 0.9815 - f1_m: 0.9347 - precision_m: 0.9781 - recall_m: 0.9072\n",
            "Epoch 46/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0553 - acc: 0.9856 - f1_m: 0.9286 - precision_m: 0.9767 - recall_m: 0.8965\n",
            "Epoch 47/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0405 - acc: 0.9877 - f1_m: 0.9499 - precision_m: 0.9877 - recall_m: 0.9220\n",
            "Epoch 48/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0436 - acc: 0.9918 - f1_m: 0.9667 - precision_m: 0.9877 - recall_m: 0.9490\n",
            "Epoch 49/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0474 - acc: 0.9856 - f1_m: 0.9411 - precision_m: 0.9877 - recall_m: 0.9089\n",
            "Epoch 50/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0420 - acc: 0.9959 - f1_m: 0.9835 - precision_m: 1.0000 - recall_m: 0.9737\n",
            "Epoch 51/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0416 - acc: 0.9897 - f1_m: 0.9624 - precision_m: 0.9782 - recall_m: 0.9490\n",
            "Epoch 52/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0517 - acc: 0.9897 - f1_m: 0.9576 - precision_m: 0.9877 - recall_m: 0.9340\n",
            "Epoch 53/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0308 - acc: 0.9918 - f1_m: 0.9738 - precision_m: 1.0000 - recall_m: 0.9532\n",
            "Epoch 54/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0465 - acc: 0.9815 - f1_m: 0.9456 - precision_m: 0.9835 - recall_m: 0.9177\n",
            "Epoch 55/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0413 - acc: 0.9877 - f1_m: 0.9642 - precision_m: 1.0000 - recall_m: 0.9378\n",
            "Epoch 56/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0441 - acc: 0.9856 - f1_m: 0.9227 - precision_m: 0.9492 - recall_m: 0.9069\n",
            "Epoch 57/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0346 - acc: 0.9897 - f1_m: 0.9560 - precision_m: 0.9877 - recall_m: 0.9303\n",
            "Epoch 58/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0249 - acc: 0.9959 - f1_m: 0.9855 - precision_m: 1.0000 - recall_m: 0.9741\n",
            "Epoch 59/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0401 - acc: 0.9897 - f1_m: 0.9597 - precision_m: 0.9877 - recall_m: 0.9372\n",
            "Epoch 60/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0314 - acc: 0.9897 - f1_m: 0.9768 - precision_m: 1.0000 - recall_m: 0.9577\n",
            "Epoch 61/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0530 - acc: 0.9794 - f1_m: 0.8679 - precision_m: 0.9342 - recall_m: 0.8197\n",
            "Epoch 62/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0575 - acc: 0.9835 - f1_m: 0.9586 - precision_m: 0.9707 - recall_m: 0.9547\n",
            "Epoch 63/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0311 - acc: 0.9897 - f1_m: 0.9580 - precision_m: 1.0000 - recall_m: 0.9291\n",
            "Epoch 64/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0321 - acc: 0.9877 - f1_m: 0.9526 - precision_m: 0.9906 - recall_m: 0.9318\n",
            "Epoch 65/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0222 - acc: 0.9959 - f1_m: 0.9889 - precision_m: 1.0000 - recall_m: 0.9796\n",
            "Epoch 66/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0587 - acc: 0.9794 - f1_m: 0.9366 - precision_m: 0.9568 - recall_m: 0.9224\n",
            "Epoch 67/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0427 - acc: 0.9877 - f1_m: 0.9506 - precision_m: 1.0000 - recall_m: 0.9186\n",
            "Epoch 68/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0284 - acc: 0.9938 - f1_m: 0.9064 - precision_m: 0.9124 - recall_m: 0.9026\n",
            "Epoch 69/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0162 - acc: 0.9979 - f1_m: 0.9782 - precision_m: 0.9877 - recall_m: 0.9712\n",
            "Epoch 70/70\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0172 - acc: 0.9959 - f1_m: 0.9883 - precision_m: 0.9918 - recall_m: 0.9868\n",
            "[LibLinear]Acc= 0.8154613466334164\n",
            "F1 Score= 0.825599247238697\n",
            "Recall= 0.6566839321137315\n",
            "Tiempo de procesamiento (secs):256.3755233287811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsKOvgMFAKqc",
        "colab_type": "code",
        "outputId": "06cc8829-5810-4324-fb06-8275c5ad01d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "CNNSVM=pd.DataFrame(CNN_emb_SVM_metrics, columns=['Chunks','Acc','F1Score','Recall'])\n",
        "CNNSVM"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Chunks</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1Score</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8404</td>\n",
              "      <td>0.8482</td>\n",
              "      <td>0.7037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.8304</td>\n",
              "      <td>0.8397</td>\n",
              "      <td>0.6898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.8155</td>\n",
              "      <td>0.8256</td>\n",
              "      <td>0.6567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.8204</td>\n",
              "      <td>0.8293</td>\n",
              "      <td>0.6595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.8254</td>\n",
              "      <td>0.8360</td>\n",
              "      <td>0.6870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.8155</td>\n",
              "      <td>0.8256</td>\n",
              "      <td>0.6567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.8130</td>\n",
              "      <td>0.8267</td>\n",
              "      <td>0.6798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.8354</td>\n",
              "      <td>0.8435</td>\n",
              "      <td>0.6927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.8229</td>\n",
              "      <td>0.8341</td>\n",
              "      <td>0.6855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.8155</td>\n",
              "      <td>0.8256</td>\n",
              "      <td>0.6567</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Chunks     Acc  F1Score  Recall\n",
              "0     1.0  0.8404   0.8482  0.7037\n",
              "1     2.0  0.8304   0.8397  0.6898\n",
              "2     3.0  0.8155   0.8256  0.6567\n",
              "3     4.0  0.8204   0.8293  0.6595\n",
              "4     5.0  0.8254   0.8360  0.6870\n",
              "5     6.0  0.8155   0.8256  0.6567\n",
              "6     7.0  0.8130   0.8267  0.6798\n",
              "7     8.0  0.8354   0.8435  0.6927\n",
              "8     9.0  0.8229   0.8341  0.6855\n",
              "9    10.0  0.8155   0.8256  0.6567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGgjb-RKAcxb",
        "colab_type": "code",
        "outputId": "6531dca4-5796-4883-b325-1db8c407facf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "# multiple line plot\n",
        "plt.plot( 'Chunks', 'Acc', data=CNNSVM, marker='v', color='cornflowerblue', linewidth=2)\n",
        "plt.plot( 'Chunks', 'F1Score', data=CNNSVM, marker='v', color='darkred', linewidth=2)\n",
        "plt.plot( 'Chunks', 'Recall', data=CNNSVM, marker='v', color='darkorange', linewidth=2)\n",
        "plt.xlabel(\"Chunks\")\n",
        "plt.ylabel(\"Rate\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4d922e2be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEDCAYAAADeP8iwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}